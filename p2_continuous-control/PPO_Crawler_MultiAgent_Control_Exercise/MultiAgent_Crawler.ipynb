{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Crawler\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **actor network** receives his own state space and outputs an action, the log probability of that action (to be used later in calculating the advantage ratio) and the entropy of the probability distribution. Higher entropy indicates more uncertainty in the probabilities. For example, when the probability of the goalie choosing any actions is roughly equal, this would be maximum entropy. When one of those actions has 100% probability and the other 3 actions have 0% probability, the agent is absolutely certain and entropy will be zero. **Action space for this environment is continuous**. \n",
    "\n",
    "We use **entropy as noise** in the loss function to force the agent to try more random actions early on and not get fixated on a solution which is not optimal in the long run (stuck in a local minima.). Since we are performing gradient descent on the negative of entropy, we are maximizing it. However, the decaying beta value will continuously shrink the contribution of entropy in the loss function, leading to more optimization to minimize policy and value loss. Hence, we will notice a dip in entropy with entropy with time as the agent's policy and critic nets becomes increasingly confident of their predictions.\n",
    "\n",
    "The **critic network** receives the state space for each individual agent on the field and outputs the expected average value (total reward) for an action taken given that state. It learns in a supervised learning fashion by optimizing the MSE loss between future cumulative reward vs state-value estimation. State-value estimates converges with sufficient exploration. \n",
    "\n",
    "The **advantage function** is used in computing policy loss to indicate how much better an agent is performing relative to a baseline. This baseline is the state-value prediction from the critic network on how much rewards an agent ought to receive given a state. Hence, as an agent improves (make better actions and more accurately predict value of states), it is forced to make even better actions that yield higher rewards than what is thought to be the 'averaged' reward for being in that particular state. In simple terms, an R=+30 may be good at the start, but not as desirable in later training phases. Here, we use **either A3C or GAE Value Estimation**. \n",
    "\n",
    "**A note on the distributions function:**\n",
    "It is not possible to have the actor simply output a softmax distribution of action probabilities and then choose an action  off a random sampling of those probabilities. Neural networks cannot directly backpropagate through random samples. PyTorch and Tensorflow offer a distribution function to solve this that makes the action selection differentiable. The actor passes the softmax output through this distribution function to select the action and then backpropagation can occur.\n",
    "https://pytorch.org/docs/stable/distributions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'scripts/')  # TODO: insert at 1, 0 is the script path (or '' in REPL)\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import shutil\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'  # BUG WITH MATLIBPLOT KERNAL HANG (https://github.com/dmlc/xgboost/issues/1715)\n",
    "import pprint \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ppo_agent import PPO_Agent\n",
    "from params import Params\n",
    "from logger import Logger\n",
    "from CustomSummaryWriter import CustomSummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time related Utilities\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def get_time(format):\n",
    "    utc_now = pytz.utc.localize(datetime.utcnow())\n",
    "    pst_now = utc_now.astimezone(pytz.timezone(\"Asia/Singapore\"))   # Set to your own timezone: pytz.all_timezones\n",
    "    return pst_now.strftime(format)\n",
    "\n",
    "def total_train_duration(start_time, end_time):\n",
    "    duration = end_time - start_time              # For build-in functions\n",
    "    duration_in_s = duration.total_seconds()      # Total number of seconds between dates\n",
    "    days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)\n",
    "    hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours\n",
    "    minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes\n",
    "    seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds\n",
    "    print(\"TOTAL TRAINING DURATION: %d days, %d hours, %d minutes and %d seconds\" % (days[0], hours[0], minutes[0], seconds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARN: SLOWS DOWN TRAINING ALOT..\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe', worker_id=109)\n",
    "# env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe', no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "# states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "# scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "# while True:\n",
    "#     actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#     actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#     next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#     rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     dones = env_info.local_done                        # see if episode finished\n",
    "#     scores += env_info.rewards                         # update the score (for each agent)\n",
    "#     states = next_states                               # roll over states to next time step\n",
    "#     if np.any(dones):                                  # exit loop if episode finished\n",
    "#         break\n",
    "# print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "\n",
    "While training is taking place, statistics on agent performance are available from Tensorboard. To launch it use:\n",
    "```python\n",
    "cd <PROJECT_DIR>\n",
    "tensorboard --logdir=runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  1\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ppo(params=Params(), logger=Logger()):\n",
    "\n",
    "    print (\"***STARTED TRAINING AT {} \\n\".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "    start_time  = datetime.now() \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    action_size = brain.vector_action_space_size\n",
    "    state_size = env_info.vector_observations.shape[1]\n",
    "    logger.initialize(agent, state_size, action_size)\n",
    "    \n",
    "    try:\n",
    "        start_eps = params.eps_to_resume_from if not params.restart_training else 1        \n",
    "        for i_episode in range(start_eps, params.n_episodes+1):\n",
    "            env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "            states = env_info.vector_observations              # get the current state\n",
    "            score = np.zeros(len(env_info.agents))\n",
    "            hasNaN = False\n",
    "\n",
    "            for t in range(params.max_t):                             \n",
    "\n",
    "                # REPORT NAN STATES\n",
    "                if np.isnan(states).any():\n",
    "                    print('\\nNaN found in states. Skipping this episode.')\n",
    "                    hasNaN = True\n",
    "                    break\n",
    "\n",
    "                # Perform actions from each agent's policy network (clipped actions [0, -1])  \n",
    "                actions, log_probs, _, values = agent.act(states, agent.std_scale)\n",
    "                env_info = env.step(actions)[brain_name]      \n",
    "                next_states, rewards, dones = env_info.vector_observations, env_info.rewards, env_info.local_done\n",
    "\n",
    "                # REPORT NAN ACTIONS\n",
    "                if np.isnan(next_states).any():\n",
    "                    print(\"NaN next_states Found! Skipping this episode.\")\n",
    "                    hasNaN = True\n",
    "                    break\n",
    "\n",
    "                if np.isnan(actions).any():\n",
    "                    print('NaN found in actions. Skipping this episode.')\n",
    "                    hasNaN = True\n",
    "                    break\n",
    "\n",
    "                if np.isnan(rewards).any():\n",
    "                    print(\"NaN Reward Found! Skipping this episode.\")\n",
    "                    hasNaN = True\n",
    "                    break\n",
    "\n",
    "                # Only collect and learn from subset of data from episode (representative enough)\n",
    "                if t < params.num_steps_collect_data:\n",
    "                    agent.step(states, actions, rewards, log_probs, values, dones)\n",
    "                    last_states = next_states\n",
    "\n",
    "                # Allow crawler to keep resetting if fall (score -> 0)\n",
    "                # Continue to accumulate score over entire duration max_t to maxmimize observable score\n",
    "                states = next_states\n",
    "                score += np.array(rewards)             \n",
    "                for i in range(len(dones)):\n",
    "                    if dones[i]:\n",
    "                        logger.log_score(score[i])\n",
    "                        score[i] = 0\n",
    "\n",
    "                # Break if all agents are done (auto @ step=1000)\n",
    "                if all(dones):   # any()\n",
    "                    break \n",
    "\n",
    "            if not hasNaN:\n",
    "                # Learn from episode (add last state if using GAE)\n",
    "                agent.add_last_state(last_states)\n",
    "                agent.learn()\n",
    "\n",
    "                # Print crucial results for progress tracking\n",
    "                logger.log_stats(i_episode, agent.actor_loss, agent.critic_loss, agent.entropy_loss)\n",
    "                logger.log_decaying_hparams(i_episode, agent.lr, agent.eps, agent.beta, agent.std_scale)\n",
    "                print('\\rEpisode {}\\t Score [This Eps]: {:.2f} \\t Steps: {}'.format(i_episode, logger.scores_list[-1], t), end=\"\")\n",
    "\n",
    "                if i_episode % params.save_every == 0:\n",
    "                    logger.save_weights(i_episode)\n",
    "\n",
    "                if i_episode % params.print_every == 0:\n",
    "                    print('\\rEpisode {}: \\tActor Loss: {:.2f} \\tCritic Loss: {:.2f} \\n\\t\\tAvg Score [100eps]: {:.2f} \\t Steps: {}\\n'\n",
    "                          .format(i_episode, np.mean(logger.actor_loss_deque), np.mean(logger.critic_loss_deque), logger.scores_list[-1], t))\n",
    "\n",
    "                    if logger.scores_list[-1] >= params.target_score:\n",
    "                        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'\n",
    "                              .format(i_episode, logger.scores_list[-1]))\n",
    "                        if params.terminate_on_target_score:\n",
    "                            break\n",
    "\n",
    "        # Plot graphs & save final weights\n",
    "        logger.save_weights(i_episode)\n",
    "        if params.plot_stats:\n",
    "            logger.plot_stats()\n",
    "        logger.log_overall_perf_tb()\n",
    "        total_train_duration(start_time=start_time, end_time=datetime.now())\n",
    "        print (\"***TRAINING STOPPED AT {} \".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "\n",
    "    # Catch any exceptions (Esp with keyboard interrupts)\n",
    "    except BaseException as error:\n",
    "        print('\\n\\n==== An exception occurred: {}'.format(error))\n",
    "        #logger.print_weights()\n",
    "        logger.save_weights(i_episode)\n",
    "        #if params.plot_stats:\n",
    "        #    logger.plot_stats()\n",
    "        logger.log_overall_perf_tb()\n",
    "        total_train_duration(start_time=start_time, end_time=datetime.now())\n",
    "        print (\"***TRAINING STOPPED AT {} \".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "    \n",
    "    return logger.scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# QUICK TEST\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10\n",
    "params.max_t = 100\n",
    "params.print_every = 2\n",
    "params.save_every = 2\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "logger = Logger(params)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***STARTED TRAINING AT 2022-05-18--22:52:02 \n",
      "\n",
      "Episode 390: \tActor Loss: 0.09 \tCritic Loss: 6.62 287\n",
      "\t\tAvg Score [100eps]: 2556.73 \t Steps: 12287\n",
      "\n",
      "Episode 400: \tActor Loss: 0.09 \tCritic Loss: 6.63 007\n",
      "\t\tAvg Score [100eps]: 2686.28 \t Steps: 1000\n",
      "\n",
      "Episode 410: \tActor Loss: 0.09 \tCritic Loss: 6.71 287\n",
      "\t\tAvg Score [100eps]: 2593.49 \t Steps: 12287\n",
      "\n",
      "Episode 420: \tActor Loss: 0.09 \tCritic Loss: 6.77 007\n",
      "\t\tAvg Score [100eps]: 2557.67 \t Steps: 1000\n",
      "\n",
      "Episode 430: \tActor Loss: 0.09 \tCritic Loss: 6.89 007\n",
      "\t\tAvg Score [100eps]: 2590.65 \t Steps: 1000\n",
      "\n",
      "Episode 440: \tActor Loss: 0.09 \tCritic Loss: 6.95 287\n",
      "\t\tAvg Score [100eps]: 2675.36 \t Steps: 12287\n",
      "\n",
      "Episode 450: \tActor Loss: 0.06 \tCritic Loss: 7.03 007\n",
      "\t\tAvg Score [100eps]: 2720.36 \t Steps: 1000\n",
      "\n",
      "Episode 460: \tActor Loss: 0.07 \tCritic Loss: 7.25 007\n",
      "\t\tAvg Score [100eps]: 2526.71 \t Steps: 1000\n",
      "\n",
      "Episode 470: \tActor Loss: 0.07 \tCritic Loss: 7.33 287\n",
      "\t\tAvg Score [100eps]: 2537.49 \t Steps: 12287\n",
      "\n",
      "Episode 480: \tActor Loss: 0.07 \tCritic Loss: 7.38 287\n",
      "\t\tAvg Score [100eps]: 2559.48 \t Steps: 12287\n",
      "\n",
      "Episode 490: \tActor Loss: 0.07 \tCritic Loss: 7.41 007\n",
      "\t\tAvg Score [100eps]: 2564.50 \t Steps: 1000\n",
      "\n",
      "Episode 496\t Score [This Eps]: 2793.90 \t Steps: 12287\n",
      "\n",
      "==== An exception occurred: \n",
      "TOTAL TRAINING DURATION: 0 days, 1 hours, 59 minutes and 25 seconds\n",
      "***TRAINING STOPPED AT 2022-05-19--00:51:28 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.228633048500487,\n",
       " 18.2400571974312,\n",
       " 24.426406205771926,\n",
       " 32.114061766864396,\n",
       " 33.867889540622784,\n",
       " 47.08185033435089,\n",
       " 54.167440284388725,\n",
       " 77.18986785085536,\n",
       " 92.22983648030315,\n",
       " 99.22707708837866,\n",
       " 125.40842171340584,\n",
       " 156.54453393317206,\n",
       " 207.45800414092315,\n",
       " 259.7891941688425,\n",
       " 295.39381791518247,\n",
       " 305.8545136635646,\n",
       " 314.5883460867545,\n",
       " 361.2121475716651,\n",
       " 357.89009277331354,\n",
       " 387.97947297153473,\n",
       " 413.6871236642619,\n",
       " 456.59463547520454,\n",
       " 442.6844489344547,\n",
       " 489.6083101134561,\n",
       " 464.2861266209092,\n",
       " 482.30296573986067,\n",
       " 532.6328981057089,\n",
       " 559.0751754086122,\n",
       " 584.4922287626797,\n",
       " 604.2494776579458,\n",
       " 607.4389519320265,\n",
       " 644.4733045543428,\n",
       " 638.763207841852,\n",
       " 651.3402172196679,\n",
       " 652.0868699570746,\n",
       " 701.6065872943705,\n",
       " 652.0409366027952,\n",
       " 634.8897413625405,\n",
       " 666.2061302200658,\n",
       " 666.3577879690519,\n",
       " 677.4928146288544,\n",
       " 693.936379568025,\n",
       " 747.6300698652351,\n",
       " 713.4604572404464,\n",
       " 748.1226031283196,\n",
       " 810.0025660614785,\n",
       " 798.8040839688213,\n",
       " 834.6446635873941,\n",
       " 810.9427482020761,\n",
       " 791.1580052096956,\n",
       " 839.1510038139298,\n",
       " 899.3676615241112,\n",
       " 858.3767466101236,\n",
       " 901.7162096593343,\n",
       " 908.8911379248789,\n",
       " 853.0711043333076,\n",
       " 816.0357208924298,\n",
       " 888.6448356741062,\n",
       " 908.6777064590389,\n",
       " 903.2865352040949,\n",
       " 838.5091553831427,\n",
       " 899.9060046438873,\n",
       " 857.2823024633806,\n",
       " 925.658266314147,\n",
       " 898.3101211241353,\n",
       " 897.5723055160081,\n",
       " 863.5534995814343,\n",
       " 883.2782005147985,\n",
       " 960.9471410131222,\n",
       " 1011.1571040207846,\n",
       " 1013.1436691697547,\n",
       " 1038.2255761755118,\n",
       " 1005.8053072812711,\n",
       " 993.7238483159174,\n",
       " 1034.2584986741165,\n",
       " 979.1306011563261,\n",
       " 993.1881148038793,\n",
       " 1026.109597970717,\n",
       " 1060.681900047562,\n",
       " 975.922915552415,\n",
       " 979.1623660641536,\n",
       " 1021.4660717618104,\n",
       " 1067.166012124957,\n",
       " 1092.9318154144123,\n",
       " 1046.675300021083,\n",
       " 1074.0975093496288,\n",
       " 1089.5016902616806,\n",
       " 1109.3501852269144,\n",
       " 1144.2687057816238,\n",
       " 1164.737725497919,\n",
       " 1132.4873883803584,\n",
       " 1091.195157835742,\n",
       " 1133.0377916441066,\n",
       " 1208.3534805194556,\n",
       " 1247.289379821429,\n",
       " 1139.4310317622032,\n",
       " 1144.8170947804394,\n",
       " 1120.892786014867,\n",
       " 1171.4018486516213,\n",
       " 1206.11794689978,\n",
       " 1103.1503155239857,\n",
       " 1126.6881213642982,\n",
       " 1191.8378350556245,\n",
       " 1166.3589686350035,\n",
       " 1220.3394408103218,\n",
       " 1192.808359958646,\n",
       " 1227.5250391054328,\n",
       " 1180.2712511795432,\n",
       " 1198.959281867626,\n",
       " 1245.9587275795172,\n",
       " 1315.0697923921327,\n",
       " 1227.3281314976002,\n",
       " 1295.71571126458,\n",
       " 1298.5597538312757,\n",
       " 1285.9406544365106,\n",
       " 1300.305484697651,\n",
       " 1317.633532966529,\n",
       " 1297.4027612372256,\n",
       " 1327.3534782000863,\n",
       " 1312.9803848699387,\n",
       " 1346.8692365932138,\n",
       " 1396.988475525682,\n",
       " 1394.8600255593867,\n",
       " 1422.8092669556522,\n",
       " 1292.4009609115053,\n",
       " 1331.0962521219276,\n",
       " 1293.9320014841546,\n",
       " 1313.5024005570938,\n",
       " 1457.8109937008423,\n",
       " 1352.2803409548221,\n",
       " 1392.918389013752,\n",
       " 1414.4367242870574,\n",
       " 1457.662156406577,\n",
       " 1407.8186139089476,\n",
       " 1574.0479719812329,\n",
       " 1499.4228173744166,\n",
       " 1451.784956399994,\n",
       " 1500.9598920202698,\n",
       " 1496.1958583596838,\n",
       " 1548.3627980507165,\n",
       " 1444.127403471095,\n",
       " 1581.1458472924423,\n",
       " 1523.5778759777675,\n",
       " 1550.746111523878,\n",
       " 1485.6819974008529,\n",
       " 1586.8128602945735,\n",
       " 1618.5936973250612,\n",
       " 1617.9360006627114,\n",
       " 1622.1004237415782,\n",
       " 1597.851724299509,\n",
       " 1678.1087633120246,\n",
       " 1705.6414038352855,\n",
       " 1702.386831310615,\n",
       " 1620.2978483121085,\n",
       " 1615.907239380381,\n",
       " 1616.789496607955,\n",
       " 1647.208970122952,\n",
       " 1711.9871243715659,\n",
       " 1712.0694346159837,\n",
       " 1722.577842042317,\n",
       " 1736.1442598527542,\n",
       " 1707.7085225741705,\n",
       " 1728.5562157440559,\n",
       " 1742.308853961574,\n",
       " 1684.2506146314774,\n",
       " 1687.4152677978332,\n",
       " 1707.4403223598085,\n",
       " 1711.9666136242763,\n",
       " 1717.9164908360865,\n",
       " 1709.4865316232201,\n",
       " 1735.8108327029972,\n",
       " 1737.6151660396997,\n",
       " 1754.6133565445164,\n",
       " 1773.0731661560153,\n",
       " 1778.682156972217,\n",
       " 1776.910351911334,\n",
       " 1787.296138612576,\n",
       " 1755.743767361939,\n",
       " 1721.2500719397012,\n",
       " 1767.133815374407,\n",
       " 1826.1419130315119,\n",
       " 1806.1881696087307,\n",
       " 1805.2575106646725,\n",
       " 1811.6254613627773,\n",
       " 1779.9274094321706,\n",
       " 1772.21436881367,\n",
       " 1779.0521605210658,\n",
       " 1776.2394486160856,\n",
       " 1803.3348977850937,\n",
       " 1810.028609700133,\n",
       " 1785.3206520389695,\n",
       " 1785.6113698973204,\n",
       " 1798.797284911978,\n",
       " 1762.2934157444513,\n",
       " 1733.3180732393196,\n",
       " 1766.9441199672735,\n",
       " 1730.6664104893152,\n",
       " 1780.762341562634,\n",
       " 1787.8163022583303,\n",
       " 1802.1872820262872,\n",
       " 1767.0800071310346,\n",
       " 1777.3853163088672,\n",
       " 1788.1463444849617,\n",
       " 1887.191440299116,\n",
       " 1889.5865837170359,\n",
       " 1819.2937254876701,\n",
       " 1846.4694778265477,\n",
       " 1853.263225102853,\n",
       " 1862.8673680733004,\n",
       " 1866.8123694551177,\n",
       " 1888.120525447335,\n",
       " 1892.497676416291,\n",
       " 1891.5610810505877,\n",
       " 1862.5423761267098,\n",
       " 1890.871049959045,\n",
       " 1915.667036075024,\n",
       " 1896.5497384184534,\n",
       " 1880.1308729448472,\n",
       " 1886.0087716857017,\n",
       " 1898.6309702592157,\n",
       " 1845.4491654047783,\n",
       " 1863.3439797304798,\n",
       " 1942.1694253728865,\n",
       " 1918.2533787490568,\n",
       " 1944.4646950255194,\n",
       " 1885.2229119099397,\n",
       " 1878.18681517025,\n",
       " 1907.398441697075,\n",
       " 1852.3889875410077,\n",
       " 1904.6900554741871,\n",
       " 1890.224891685671,\n",
       " 1905.640445209397,\n",
       " 1949.3897336181021,\n",
       " 1845.026416757838,\n",
       " 1868.3698323164601,\n",
       " 1885.4985487391846,\n",
       " 1833.9915030175773,\n",
       " 1810.2899115034518,\n",
       " 1886.7931603785325,\n",
       " 1913.4368980965764,\n",
       " 1877.8154410689137,\n",
       " 1940.4435487853502,\n",
       " 1873.4291974648554,\n",
       " 1812.0537159183993,\n",
       " 1888.1938520265883,\n",
       " 1909.3760409896402,\n",
       " 1933.8399635977437,\n",
       " 1848.5539607093972,\n",
       " 1925.2316434511124,\n",
       " 1947.550480206418,\n",
       " 1910.3852198995323,\n",
       " 1945.7297509140196,\n",
       " 1961.037926830789,\n",
       " 1908.3379551410326,\n",
       " 1945.359163646819,\n",
       " 1950.7320785023971,\n",
       " 1964.1585267304863,\n",
       " 1965.5214407844917,\n",
       " 1972.1629560737108,\n",
       " 1897.5081676480615,\n",
       " 1887.116466674488,\n",
       " 1857.1275922330283,\n",
       " 1948.1584639607813,\n",
       " 1870.845584698224,\n",
       " 1868.7830945502408,\n",
       " 1966.9075659257965,\n",
       " 1924.6984876257786,\n",
       " 1953.0336343233148,\n",
       " 2005.174317764407,\n",
       " 2038.0897939519723,\n",
       " 2043.3775322990864,\n",
       " 2068.7064646021554,\n",
       " 2069.0816130137955,\n",
       " 2090.3490617015214,\n",
       " 2058.7769020978176,\n",
       " 2015.8783696054086,\n",
       " 2048.518208361957,\n",
       " 2016.5813216493325,\n",
       " 2010.7536479641847,\n",
       " 2023.9395493677025,\n",
       " 2014.3352156460658,\n",
       " 1924.2297837230494,\n",
       " 2027.027199352137,\n",
       " 2036.5175532879168,\n",
       " 2033.8983328560855,\n",
       " 2104.9389590902465,\n",
       " 2026.0852011763748,\n",
       " 2070.8619476118474,\n",
       " 2127.6467462959445,\n",
       " 2122.177345440062,\n",
       " 2093.7413823512175,\n",
       " 2121.5406957061773,\n",
       " 2023.4768629897433,\n",
       " 2038.0325410084217,\n",
       " 2109.5563320645783,\n",
       " 2126.773051354932,\n",
       " 2156.0505365356594,\n",
       " 2055.5402302838,\n",
       " 2119.294771578051,\n",
       " 2100.814010170787,\n",
       " 2115.2718135150894,\n",
       " 2081.2690427577636,\n",
       " 2121.5469781783877,\n",
       " 2176.6822191989004,\n",
       " 2218.228341610143,\n",
       " 2208.8328793616965,\n",
       " 2177.847353358455,\n",
       " 2266.3782188791038,\n",
       " 2182.250062245936,\n",
       " 2208.5267106401175,\n",
       " 2237.1688812167267,\n",
       " 2258.4092102160957,\n",
       " 2179.7369723948464,\n",
       " 2221.4550300797914,\n",
       " 2339.154179669069,\n",
       " 2331.325797587526,\n",
       " 2325.0529390771735,\n",
       " 2281.5660612596594,\n",
       " 2281.22795279423,\n",
       " 2274.407966887739,\n",
       " 2242.360340272654,\n",
       " 2288.157864157432,\n",
       " 2269.566438192206,\n",
       " 2300.4641775306895,\n",
       " 2310.4682724212457,\n",
       " 2333.6467233396065,\n",
       " 2337.077786166121,\n",
       " 2355.2198425550223,\n",
       " 2341.19470394732,\n",
       " 2343.7612184391496,\n",
       " 2195.097286301092,\n",
       " 2157.7614045734936,\n",
       " 2312.9933134142425,\n",
       " 2307.677580182266,\n",
       " 2310.2807288127883,\n",
       " 2370.548544306547,\n",
       " 2314.074122528529,\n",
       " 2316.20936130977,\n",
       " 2335.1776385692206,\n",
       " 2367.552193319281,\n",
       " 2374.7087131965486,\n",
       " 2391.3223392655095,\n",
       " 2400.603824431258,\n",
       " 2420.542700011558,\n",
       " 2426.4948070358437,\n",
       " 2438.220763848955,\n",
       " 2375.025378590287,\n",
       " 2404.912974692043,\n",
       " 2404.161935286601,\n",
       " 2411.377251175805,\n",
       " 2455.1325711741833,\n",
       " 2452.4003203109164,\n",
       " 2446.373807603973,\n",
       " 2464.9058299050666,\n",
       " 2467.6764817746775,\n",
       " 2428.0396927704755,\n",
       " 2448.409207779933,\n",
       " 2460.8409059329388,\n",
       " 2335.2922923299157,\n",
       " 2385.055145223369,\n",
       " 2404.143539079847,\n",
       " 2384.4352821241414,\n",
       " 2386.286999072405,\n",
       " 2391.528459462626,\n",
       " 2450.860064810747,\n",
       " 2448.68454601733,\n",
       " 2506.7497942365985,\n",
       " 2479.8203934375288,\n",
       " 2462.794845099533,\n",
       " 2425.679967752723,\n",
       " 2478.8460348835447,\n",
       " 2478.7182511690353,\n",
       " 2476.3132773742823,\n",
       " 2495.9318461216008,\n",
       " 2483.2778350560648,\n",
       " 2510.185154243661,\n",
       " 2465.6448041100193,\n",
       " 2511.5522065722707,\n",
       " 2552.9679371423367,\n",
       " 2558.388384244987,\n",
       " 2561.640430257707,\n",
       " 2587.826299739024,\n",
       " 2588.11083836515,\n",
       " 2581.866972812591,\n",
       " 2578.0502339449527,\n",
       " 2565.702004806367,\n",
       " 2561.5149305601462,\n",
       " 2503.0349256319228,\n",
       " 2552.1909329307427,\n",
       " 2572.7058160057454,\n",
       " 2579.605649974542,\n",
       " 2597.224444091534,\n",
       " 2601.4673858285973,\n",
       " 2605.9749543638013,\n",
       " 2466.475137407528,\n",
       " 2481.249743097979,\n",
       " 2490.4484907125216,\n",
       " 2496.353266944103,\n",
       " 2567.1275771000887,\n",
       " 2533.1860054139374,\n",
       " 2600.549078909946,\n",
       " 2557.0046567774752,\n",
       " 2559.4148739113007,\n",
       " 2567.9845709805704,\n",
       " 2579.8123540425067,\n",
       " 2604.0621115201247,\n",
       " 2633.5284797148315,\n",
       " 2636.303211371838,\n",
       " 2635.9039556162643,\n",
       " 2605.3773210347817,\n",
       " 2536.9363359108615,\n",
       " 2505.2705559601077,\n",
       " 2515.4119947191143,\n",
       " 2550.9740121477425,\n",
       " 2572.980957821924,\n",
       " 2569.802114725551,\n",
       " 2676.4521319993214,\n",
       " 2667.1989894194344,\n",
       " 2556.732848136062,\n",
       " 2576.9899020269468,\n",
       " 2638.4078487696406,\n",
       " 2668.961888041068,\n",
       " 2666.6923484171834,\n",
       " 2657.4036181741208,\n",
       " 2657.2586571049737,\n",
       " 2660.217367340694,\n",
       " 2661.204224841073,\n",
       " 2680.2131967177475,\n",
       " 2686.2772077453646,\n",
       " 2609.3168523474133,\n",
       " 2652.0774011264975,\n",
       " 2641.2595150756533,\n",
       " 2643.952502883449,\n",
       " 2571.1330061782105,\n",
       " 2572.7084159539595,\n",
       " 2595.646555017652,\n",
       " 2618.1727029900835,\n",
       " 2615.3690788162385,\n",
       " 2593.4851216558436,\n",
       " 2598.2679030095856,\n",
       " 2599.124166741518,\n",
       " 2622.6344130649486,\n",
       " 2476.173799126623,\n",
       " 2508.453752515754,\n",
       " 2488.783901356426,\n",
       " 2506.3762617786647,\n",
       " 2519.2795989705205,\n",
       " 2566.559950886783,\n",
       " 2557.672246908322,\n",
       " 2685.317550062854,\n",
       " 2691.407236352081,\n",
       " 2685.136948505321,\n",
       " 2685.7944266150544,\n",
       " 2691.0452732888793,\n",
       " 2698.786992636593,\n",
       " 2651.082280478935,\n",
       " 2639.4065079692346,\n",
       " 2552.8470772320265,\n",
       " 2590.6479178194886,\n",
       " 2637.2472047150786,\n",
       " 2651.1668291189244,\n",
       " 2656.548067895423,\n",
       " 2695.2189740833196,\n",
       " 2682.7264393225614,\n",
       " 2619.3759278366065,\n",
       " 2679.8696052817327,\n",
       " 2600.3885183153347,\n",
       " 2601.6678201276227,\n",
       " 2675.361595852184,\n",
       " 2602.606948528632,\n",
       " 2585.2110215372313,\n",
       " 2660.665594005911,\n",
       " 2665.564381893389,\n",
       " 2629.5966550728167,\n",
       " 2635.4860538348134,\n",
       " 2639.611348533332,\n",
       " 2666.766081528491,\n",
       " 2668.4695327941236,\n",
       " 2720.3605815076035,\n",
       " 2762.1795966975997,\n",
       " 2759.0771311678086,\n",
       " 2753.600512057459,\n",
       " 2725.9595659881925,\n",
       " 2549.3251468859426,\n",
       " 2561.5360969172557,\n",
       " 2566.131224021674,\n",
       " 2472.4561558518185,\n",
       " 2477.9799512371105,\n",
       " 2526.7102009384253,\n",
       " 2543.606128671932,\n",
       " 2562.135773690826,\n",
       " 2585.151855942876,\n",
       " 2760.3307101337705,\n",
       " 2757.680839018109,\n",
       " 2671.1333505886096,\n",
       " 2647.6854689370257,\n",
       " 2487.4206592170895,\n",
       " 2628.2835341450664,\n",
       " 2537.4889256195493,\n",
       " 2567.5005319752404,\n",
       " 2645.323368282621,\n",
       " 2660.991516689155,\n",
       " 2525.249357939097,\n",
       " 2742.2657346722904,\n",
       " 2669.271788397068,\n",
       " 2726.773186191679,\n",
       " 2755.233923991998,\n",
       " 2672.0888307414575,\n",
       " 2559.481020585098,\n",
       " 2568.0570986461735,\n",
       " 2754.974366437658,\n",
       " 2760.60239217801,\n",
       " 2760.4552112801744,\n",
       " 2758.603973205229,\n",
       " 2797.9314068276108,\n",
       " 2793.8818781192226,\n",
       " 2623.1290090122698,\n",
       " 2535.256494284214,\n",
       " 2564.5036928995537,\n",
       " 2601.4652691975284,\n",
       " 2698.1158960255257,\n",
       " 2643.5691152135055,\n",
       " 2779.6323496460823,\n",
       " 2817.8381095027926,\n",
       " 2793.904847363089]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume Training to push agent to learn more...\n",
    "\n",
    "# Restart training params (if restart training is false)\n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/final_alt'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/final_alt'\n",
    "params.restart_training = False\n",
    "params.eps_to_resume_from = 381\n",
    "params.actor_weights_filename_to_resume = 'checkpoint_actor_ep380.pth'\n",
    "params.critic_weights_filename_to_resume = 'checkpoint_critic_ep380.pth'\n",
    "params.terminate_on_target_score = False\n",
    "params.target_score = 9999.0\n",
    "\n",
    "#### MAIN #####\n",
    "#tb=CustomSummaryWriter()\n",
    "#logger = Logger(params, tb=tb)\n",
    "#agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graph(logger):\n",
    "    \n",
    "    score_arr  = np.array(logger.scores_list)\n",
    "    #score_arr[score_arr < 0] = 0\n",
    "    _, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    # Scores\n",
    "    axs[0].plot(np.arange(1, len(logger.scores_list)+1), score_arr)\n",
    "    axs[0].set(xlabel='Episode #', ylabel='Score')\n",
    "    axs[0].set_title('Rewards')\n",
    "        \n",
    "    # Actor Loss\n",
    "    axs[1].plot(np.arange(1, len(logger.actor_loss_list)+1), logger.actor_loss_list)\n",
    "    axs[1].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[1].set_title('Actor Loss')\n",
    "    \n",
    "    # Critic Loss\n",
    "    axs[2].plot(np.arange(1, len(logger.critic_loss_list)+1), logger.critic_loss_list)\n",
    "    axs[2].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[2].set_title('Critic Loss')\n",
    "    \n",
    "    # Entropy Loss\n",
    "    axs[3].plot(np.arange(1, len(logger.entropy_loss_list)+1), logger.entropy_loss_list)\n",
    "    axs[3].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[3].set_title('Entropy Loss')\n",
    "    plt.show()\n",
    "    \n",
    "plot_graph(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***STARTED TRAINING AT 2022-05-19--00:51:54 \n",
      "\n",
      "Episode 500: \tActor Loss: 0.07 \tCritic Loss: 7.46 007\n",
      "\t\tAvg Score [100eps]: 2627.22 \t Steps: 1000\n",
      "\n",
      "Episode 510: \tActor Loss: 0.07 \tCritic Loss: 7.55 007\n",
      "\t\tAvg Score [100eps]: 2734.98 \t Steps: 1000\n",
      "\n",
      "Episode 520: \tActor Loss: 0.07 \tCritic Loss: 7.63 007\n",
      "\t\tAvg Score [100eps]: 2770.43 \t Steps: 1000\n",
      "\n",
      "Episode 530: \tActor Loss: 0.07 \tCritic Loss: 7.60 287\n",
      "\t\tAvg Score [100eps]: 2822.03 \t Steps: 12287\n",
      "\n",
      "Episode 540: \tActor Loss: 0.07 \tCritic Loss: 7.65 007\n",
      "\t\tAvg Score [100eps]: 2777.22 \t Steps: 1000\n",
      "\n",
      "Episode 550: \tActor Loss: 0.07 \tCritic Loss: 7.45 287\n",
      "\t\tAvg Score [100eps]: 2770.37 \t Steps: 12287\n",
      "\n",
      "Episode 560: \tActor Loss: 0.07 \tCritic Loss: 7.38 287\n",
      "\t\tAvg Score [100eps]: 2538.79 \t Steps: 12287\n",
      "\n",
      "Episode 563\t Score [This Eps]: 2596.90 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 570: \tActor Loss: 0.07 \tCritic Loss: 7.36 287\n",
      "\t\tAvg Score [100eps]: 2686.83 \t Steps: 12287\n",
      "\n",
      "Episode 580: \tActor Loss: 0.07 \tCritic Loss: 7.42 287\n",
      "\t\tAvg Score [100eps]: 2697.68 \t Steps: 12287\n",
      "\n",
      "Episode 590: \tActor Loss: 0.07 \tCritic Loss: 7.37 287\n",
      "\t\tAvg Score [100eps]: 2740.72 \t Steps: 12287\n",
      "\n",
      "Episode 600: \tActor Loss: 0.07 \tCritic Loss: 7.35 287\n",
      "\t\tAvg Score [100eps]: 2671.11 \t Steps: 12287\n",
      "\n",
      "Episode 610: \tActor Loss: 0.07 \tCritic Loss: 7.21 287\n",
      "\t\tAvg Score [100eps]: 2715.49 \t Steps: 12287\n",
      "\n",
      "Episode 620: \tActor Loss: 0.07 \tCritic Loss: 7.12 287\n",
      "\t\tAvg Score [100eps]: 2634.77 \t Steps: 12287\n",
      "\n",
      "Episode 630: \tActor Loss: 0.08 \tCritic Loss: 7.06 287\n",
      "\t\tAvg Score [100eps]: 2651.46 \t Steps: 12287\n",
      "\n",
      "Episode 640: \tActor Loss: 0.08 \tCritic Loss: 6.97 287\n",
      "\t\tAvg Score [100eps]: 2664.31 \t Steps: 12287\n",
      "\n",
      "Episode 650: \tActor Loss: 0.08 \tCritic Loss: 6.92 287\n",
      "\t\tAvg Score [100eps]: 2714.50 \t Steps: 12287\n",
      "\n",
      "Episode 660: \tActor Loss: 0.08 \tCritic Loss: 6.89 287\n",
      "\t\tAvg Score [100eps]: 2711.27 \t Steps: 12287\n",
      "\n",
      "Episode 670: \tActor Loss: 0.08 \tCritic Loss: 6.88 287\n",
      "\t\tAvg Score [100eps]: 2632.12 \t Steps: 12287\n",
      "\n",
      "Episode 680: \tActor Loss: 0.08 \tCritic Loss: 6.77 287\n",
      "\t\tAvg Score [100eps]: 2691.10 \t Steps: 12287\n",
      "\n",
      "Episode 690: \tActor Loss: 0.08 \tCritic Loss: 6.72 287\n",
      "\t\tAvg Score [100eps]: 2665.90 \t Steps: 12287\n",
      "\n",
      "Episode 700: \tActor Loss: 0.08 \tCritic Loss: 6.67 287\n",
      "\t\tAvg Score [100eps]: 2764.30 \t Steps: 12287\n",
      "\n",
      "Episode 710: \tActor Loss: 0.08 \tCritic Loss: 6.68 287\n",
      "\t\tAvg Score [100eps]: 2728.65 \t Steps: 12287\n",
      "\n",
      "Episode 720: \tActor Loss: 0.08 \tCritic Loss: 6.67 287\n",
      "\t\tAvg Score [100eps]: 2810.49 \t Steps: 12287\n",
      "\n",
      "Episode 730: \tActor Loss: 0.08 \tCritic Loss: 6.64 287\n",
      "\t\tAvg Score [100eps]: 2789.70 \t Steps: 12287\n",
      "\n",
      "Episode 740: \tActor Loss: 0.09 \tCritic Loss: 6.59 287\n",
      "\t\tAvg Score [100eps]: 2792.12 \t Steps: 12287\n",
      "\n",
      "Episode 750: \tActor Loss: 0.09 \tCritic Loss: 6.55 287\n",
      "\t\tAvg Score [100eps]: 2852.87 \t Steps: 12287\n",
      "\n",
      "Episode 760: \tActor Loss: 0.09 \tCritic Loss: 6.62 287\n",
      "\t\tAvg Score [100eps]: 2768.61 \t Steps: 12287\n",
      "\n",
      "Episode 770: \tActor Loss: 0.09 \tCritic Loss: 6.68 287\n",
      "\t\tAvg Score [100eps]: 2850.65 \t Steps: 12287\n",
      "\n",
      "Episode 780: \tActor Loss: 0.10 \tCritic Loss: 6.74 287\n",
      "\t\tAvg Score [100eps]: 2754.03 \t Steps: 12287\n",
      "\n",
      "Episode 790: \tActor Loss: 0.10 \tCritic Loss: 6.85 287\n",
      "\t\tAvg Score [100eps]: 2702.82 \t Steps: 12287\n",
      "\n",
      "Episode 800: \tActor Loss: 0.11 \tCritic Loss: 17.62 77\n",
      "\t\tAvg Score [100eps]: 232.24 \t Steps: 12287\n",
      "\n",
      "Episode 802\t Score [This Eps]: 240.74 \t Steps: 12287\n",
      "\n",
      "==== An exception occurred: \n",
      "TOTAL TRAINING DURATION: 0 days, 7 hours, 55 minutes and 1 seconds\n",
      "***TRAINING STOPPED AT 2022-05-19--08:46:56 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.228633048500487,\n",
       " 18.2400571974312,\n",
       " 24.426406205771926,\n",
       " 32.114061766864396,\n",
       " 33.867889540622784,\n",
       " 47.08185033435089,\n",
       " 54.167440284388725,\n",
       " 77.18986785085536,\n",
       " 92.22983648030315,\n",
       " 99.22707708837866,\n",
       " 125.40842171340584,\n",
       " 156.54453393317206,\n",
       " 207.45800414092315,\n",
       " 259.7891941688425,\n",
       " 295.39381791518247,\n",
       " 305.8545136635646,\n",
       " 314.5883460867545,\n",
       " 361.2121475716651,\n",
       " 357.89009277331354,\n",
       " 387.97947297153473,\n",
       " 413.6871236642619,\n",
       " 456.59463547520454,\n",
       " 442.6844489344547,\n",
       " 489.6083101134561,\n",
       " 464.2861266209092,\n",
       " 482.30296573986067,\n",
       " 532.6328981057089,\n",
       " 559.0751754086122,\n",
       " 584.4922287626797,\n",
       " 604.2494776579458,\n",
       " 607.4389519320265,\n",
       " 644.4733045543428,\n",
       " 638.763207841852,\n",
       " 651.3402172196679,\n",
       " 652.0868699570746,\n",
       " 701.6065872943705,\n",
       " 652.0409366027952,\n",
       " 634.8897413625405,\n",
       " 666.2061302200658,\n",
       " 666.3577879690519,\n",
       " 677.4928146288544,\n",
       " 693.936379568025,\n",
       " 747.6300698652351,\n",
       " 713.4604572404464,\n",
       " 748.1226031283196,\n",
       " 810.0025660614785,\n",
       " 798.8040839688213,\n",
       " 834.6446635873941,\n",
       " 810.9427482020761,\n",
       " 791.1580052096956,\n",
       " 839.1510038139298,\n",
       " 899.3676615241112,\n",
       " 858.3767466101236,\n",
       " 901.7162096593343,\n",
       " 908.8911379248789,\n",
       " 853.0711043333076,\n",
       " 816.0357208924298,\n",
       " 888.6448356741062,\n",
       " 908.6777064590389,\n",
       " 903.2865352040949,\n",
       " 838.5091553831427,\n",
       " 899.9060046438873,\n",
       " 857.2823024633806,\n",
       " 925.658266314147,\n",
       " 898.3101211241353,\n",
       " 897.5723055160081,\n",
       " 863.5534995814343,\n",
       " 883.2782005147985,\n",
       " 960.9471410131222,\n",
       " 1011.1571040207846,\n",
       " 1013.1436691697547,\n",
       " 1038.2255761755118,\n",
       " 1005.8053072812711,\n",
       " 993.7238483159174,\n",
       " 1034.2584986741165,\n",
       " 979.1306011563261,\n",
       " 993.1881148038793,\n",
       " 1026.109597970717,\n",
       " 1060.681900047562,\n",
       " 975.922915552415,\n",
       " 979.1623660641536,\n",
       " 1021.4660717618104,\n",
       " 1067.166012124957,\n",
       " 1092.9318154144123,\n",
       " 1046.675300021083,\n",
       " 1074.0975093496288,\n",
       " 1089.5016902616806,\n",
       " 1109.3501852269144,\n",
       " 1144.2687057816238,\n",
       " 1164.737725497919,\n",
       " 1132.4873883803584,\n",
       " 1091.195157835742,\n",
       " 1133.0377916441066,\n",
       " 1208.3534805194556,\n",
       " 1247.289379821429,\n",
       " 1139.4310317622032,\n",
       " 1144.8170947804394,\n",
       " 1120.892786014867,\n",
       " 1171.4018486516213,\n",
       " 1206.11794689978,\n",
       " 1103.1503155239857,\n",
       " 1126.6881213642982,\n",
       " 1191.8378350556245,\n",
       " 1166.3589686350035,\n",
       " 1220.3394408103218,\n",
       " 1192.808359958646,\n",
       " 1227.5250391054328,\n",
       " 1180.2712511795432,\n",
       " 1198.959281867626,\n",
       " 1245.9587275795172,\n",
       " 1315.0697923921327,\n",
       " 1227.3281314976002,\n",
       " 1295.71571126458,\n",
       " 1298.5597538312757,\n",
       " 1285.9406544365106,\n",
       " 1300.305484697651,\n",
       " 1317.633532966529,\n",
       " 1297.4027612372256,\n",
       " 1327.3534782000863,\n",
       " 1312.9803848699387,\n",
       " 1346.8692365932138,\n",
       " 1396.988475525682,\n",
       " 1394.8600255593867,\n",
       " 1422.8092669556522,\n",
       " 1292.4009609115053,\n",
       " 1331.0962521219276,\n",
       " 1293.9320014841546,\n",
       " 1313.5024005570938,\n",
       " 1457.8109937008423,\n",
       " 1352.2803409548221,\n",
       " 1392.918389013752,\n",
       " 1414.4367242870574,\n",
       " 1457.662156406577,\n",
       " 1407.8186139089476,\n",
       " 1574.0479719812329,\n",
       " 1499.4228173744166,\n",
       " 1451.784956399994,\n",
       " 1500.9598920202698,\n",
       " 1496.1958583596838,\n",
       " 1548.3627980507165,\n",
       " 1444.127403471095,\n",
       " 1581.1458472924423,\n",
       " 1523.5778759777675,\n",
       " 1550.746111523878,\n",
       " 1485.6819974008529,\n",
       " 1586.8128602945735,\n",
       " 1618.5936973250612,\n",
       " 1617.9360006627114,\n",
       " 1622.1004237415782,\n",
       " 1597.851724299509,\n",
       " 1678.1087633120246,\n",
       " 1705.6414038352855,\n",
       " 1702.386831310615,\n",
       " 1620.2978483121085,\n",
       " 1615.907239380381,\n",
       " 1616.789496607955,\n",
       " 1647.208970122952,\n",
       " 1711.9871243715659,\n",
       " 1712.0694346159837,\n",
       " 1722.577842042317,\n",
       " 1736.1442598527542,\n",
       " 1707.7085225741705,\n",
       " 1728.5562157440559,\n",
       " 1742.308853961574,\n",
       " 1684.2506146314774,\n",
       " 1687.4152677978332,\n",
       " 1707.4403223598085,\n",
       " 1711.9666136242763,\n",
       " 1717.9164908360865,\n",
       " 1709.4865316232201,\n",
       " 1735.8108327029972,\n",
       " 1737.6151660396997,\n",
       " 1754.6133565445164,\n",
       " 1773.0731661560153,\n",
       " 1778.682156972217,\n",
       " 1776.910351911334,\n",
       " 1787.296138612576,\n",
       " 1755.743767361939,\n",
       " 1721.2500719397012,\n",
       " 1767.133815374407,\n",
       " 1826.1419130315119,\n",
       " 1806.1881696087307,\n",
       " 1805.2575106646725,\n",
       " 1811.6254613627773,\n",
       " 1779.9274094321706,\n",
       " 1772.21436881367,\n",
       " 1779.0521605210658,\n",
       " 1776.2394486160856,\n",
       " 1803.3348977850937,\n",
       " 1810.028609700133,\n",
       " 1785.3206520389695,\n",
       " 1785.6113698973204,\n",
       " 1798.797284911978,\n",
       " 1762.2934157444513,\n",
       " 1733.3180732393196,\n",
       " 1766.9441199672735,\n",
       " 1730.6664104893152,\n",
       " 1780.762341562634,\n",
       " 1787.8163022583303,\n",
       " 1802.1872820262872,\n",
       " 1767.0800071310346,\n",
       " 1777.3853163088672,\n",
       " 1788.1463444849617,\n",
       " 1887.191440299116,\n",
       " 1889.5865837170359,\n",
       " 1819.2937254876701,\n",
       " 1846.4694778265477,\n",
       " 1853.263225102853,\n",
       " 1862.8673680733004,\n",
       " 1866.8123694551177,\n",
       " 1888.120525447335,\n",
       " 1892.497676416291,\n",
       " 1891.5610810505877,\n",
       " 1862.5423761267098,\n",
       " 1890.871049959045,\n",
       " 1915.667036075024,\n",
       " 1896.5497384184534,\n",
       " 1880.1308729448472,\n",
       " 1886.0087716857017,\n",
       " 1898.6309702592157,\n",
       " 1845.4491654047783,\n",
       " 1863.3439797304798,\n",
       " 1942.1694253728865,\n",
       " 1918.2533787490568,\n",
       " 1944.4646950255194,\n",
       " 1885.2229119099397,\n",
       " 1878.18681517025,\n",
       " 1907.398441697075,\n",
       " 1852.3889875410077,\n",
       " 1904.6900554741871,\n",
       " 1890.224891685671,\n",
       " 1905.640445209397,\n",
       " 1949.3897336181021,\n",
       " 1845.026416757838,\n",
       " 1868.3698323164601,\n",
       " 1885.4985487391846,\n",
       " 1833.9915030175773,\n",
       " 1810.2899115034518,\n",
       " 1886.7931603785325,\n",
       " 1913.4368980965764,\n",
       " 1877.8154410689137,\n",
       " 1940.4435487853502,\n",
       " 1873.4291974648554,\n",
       " 1812.0537159183993,\n",
       " 1888.1938520265883,\n",
       " 1909.3760409896402,\n",
       " 1933.8399635977437,\n",
       " 1848.5539607093972,\n",
       " 1925.2316434511124,\n",
       " 1947.550480206418,\n",
       " 1910.3852198995323,\n",
       " 1945.7297509140196,\n",
       " 1961.037926830789,\n",
       " 1908.3379551410326,\n",
       " 1945.359163646819,\n",
       " 1950.7320785023971,\n",
       " 1964.1585267304863,\n",
       " 1965.5214407844917,\n",
       " 1972.1629560737108,\n",
       " 1897.5081676480615,\n",
       " 1887.116466674488,\n",
       " 1857.1275922330283,\n",
       " 1948.1584639607813,\n",
       " 1870.845584698224,\n",
       " 1868.7830945502408,\n",
       " 1966.9075659257965,\n",
       " 1924.6984876257786,\n",
       " 1953.0336343233148,\n",
       " 2005.174317764407,\n",
       " 2038.0897939519723,\n",
       " 2043.3775322990864,\n",
       " 2068.7064646021554,\n",
       " 2069.0816130137955,\n",
       " 2090.3490617015214,\n",
       " 2058.7769020978176,\n",
       " 2015.8783696054086,\n",
       " 2048.518208361957,\n",
       " 2016.5813216493325,\n",
       " 2010.7536479641847,\n",
       " 2023.9395493677025,\n",
       " 2014.3352156460658,\n",
       " 1924.2297837230494,\n",
       " 2027.027199352137,\n",
       " 2036.5175532879168,\n",
       " 2033.8983328560855,\n",
       " 2104.9389590902465,\n",
       " 2026.0852011763748,\n",
       " 2070.8619476118474,\n",
       " 2127.6467462959445,\n",
       " 2122.177345440062,\n",
       " 2093.7413823512175,\n",
       " 2121.5406957061773,\n",
       " 2023.4768629897433,\n",
       " 2038.0325410084217,\n",
       " 2109.5563320645783,\n",
       " 2126.773051354932,\n",
       " 2156.0505365356594,\n",
       " 2055.5402302838,\n",
       " 2119.294771578051,\n",
       " 2100.814010170787,\n",
       " 2115.2718135150894,\n",
       " 2081.2690427577636,\n",
       " 2121.5469781783877,\n",
       " 2176.6822191989004,\n",
       " 2218.228341610143,\n",
       " 2208.8328793616965,\n",
       " 2177.847353358455,\n",
       " 2266.3782188791038,\n",
       " 2182.250062245936,\n",
       " 2208.5267106401175,\n",
       " 2237.1688812167267,\n",
       " 2258.4092102160957,\n",
       " 2179.7369723948464,\n",
       " 2221.4550300797914,\n",
       " 2339.154179669069,\n",
       " 2331.325797587526,\n",
       " 2325.0529390771735,\n",
       " 2281.5660612596594,\n",
       " 2281.22795279423,\n",
       " 2274.407966887739,\n",
       " 2242.360340272654,\n",
       " 2288.157864157432,\n",
       " 2269.566438192206,\n",
       " 2300.4641775306895,\n",
       " 2310.4682724212457,\n",
       " 2333.6467233396065,\n",
       " 2337.077786166121,\n",
       " 2355.2198425550223,\n",
       " 2341.19470394732,\n",
       " 2343.7612184391496,\n",
       " 2195.097286301092,\n",
       " 2157.7614045734936,\n",
       " 2312.9933134142425,\n",
       " 2307.677580182266,\n",
       " 2310.2807288127883,\n",
       " 2370.548544306547,\n",
       " 2314.074122528529,\n",
       " 2316.20936130977,\n",
       " 2335.1776385692206,\n",
       " 2367.552193319281,\n",
       " 2374.7087131965486,\n",
       " 2391.3223392655095,\n",
       " 2400.603824431258,\n",
       " 2420.542700011558,\n",
       " 2426.4948070358437,\n",
       " 2438.220763848955,\n",
       " 2375.025378590287,\n",
       " 2404.912974692043,\n",
       " 2404.161935286601,\n",
       " 2411.377251175805,\n",
       " 2455.1325711741833,\n",
       " 2452.4003203109164,\n",
       " 2446.373807603973,\n",
       " 2464.9058299050666,\n",
       " 2467.6764817746775,\n",
       " 2428.0396927704755,\n",
       " 2448.409207779933,\n",
       " 2460.8409059329388,\n",
       " 2335.2922923299157,\n",
       " 2385.055145223369,\n",
       " 2404.143539079847,\n",
       " 2384.4352821241414,\n",
       " 2386.286999072405,\n",
       " 2391.528459462626,\n",
       " 2450.860064810747,\n",
       " 2448.68454601733,\n",
       " 2506.7497942365985,\n",
       " 2479.8203934375288,\n",
       " 2462.794845099533,\n",
       " 2425.679967752723,\n",
       " 2478.8460348835447,\n",
       " 2478.7182511690353,\n",
       " 2476.3132773742823,\n",
       " 2495.9318461216008,\n",
       " 2483.2778350560648,\n",
       " 2510.185154243661,\n",
       " 2465.6448041100193,\n",
       " 2511.5522065722707,\n",
       " 2552.9679371423367,\n",
       " 2558.388384244987,\n",
       " 2561.640430257707,\n",
       " 2587.826299739024,\n",
       " 2588.11083836515,\n",
       " 2581.866972812591,\n",
       " 2578.0502339449527,\n",
       " 2565.702004806367,\n",
       " 2561.5149305601462,\n",
       " 2503.0349256319228,\n",
       " 2552.1909329307427,\n",
       " 2572.7058160057454,\n",
       " 2579.605649974542,\n",
       " 2597.224444091534,\n",
       " 2601.4673858285973,\n",
       " 2605.9749543638013,\n",
       " 2466.475137407528,\n",
       " 2481.249743097979,\n",
       " 2490.4484907125216,\n",
       " 2496.353266944103,\n",
       " 2567.1275771000887,\n",
       " 2533.1860054139374,\n",
       " 2600.549078909946,\n",
       " 2557.0046567774752,\n",
       " 2559.4148739113007,\n",
       " 2567.9845709805704,\n",
       " 2579.8123540425067,\n",
       " 2604.0621115201247,\n",
       " 2633.5284797148315,\n",
       " 2636.303211371838,\n",
       " 2635.9039556162643,\n",
       " 2605.3773210347817,\n",
       " 2536.9363359108615,\n",
       " 2505.2705559601077,\n",
       " 2515.4119947191143,\n",
       " 2550.9740121477425,\n",
       " 2572.980957821924,\n",
       " 2569.802114725551,\n",
       " 2676.4521319993214,\n",
       " 2667.1989894194344,\n",
       " 2556.732848136062,\n",
       " 2576.9899020269468,\n",
       " 2638.4078487696406,\n",
       " 2668.961888041068,\n",
       " 2666.6923484171834,\n",
       " 2657.4036181741208,\n",
       " 2657.2586571049737,\n",
       " 2660.217367340694,\n",
       " 2661.204224841073,\n",
       " 2680.2131967177475,\n",
       " 2686.2772077453646,\n",
       " 2609.3168523474133,\n",
       " 2652.0774011264975,\n",
       " 2641.2595150756533,\n",
       " 2643.952502883449,\n",
       " 2571.1330061782105,\n",
       " 2572.7084159539595,\n",
       " 2595.646555017652,\n",
       " 2618.1727029900835,\n",
       " 2615.3690788162385,\n",
       " 2593.4851216558436,\n",
       " 2598.2679030095856,\n",
       " 2599.124166741518,\n",
       " 2622.6344130649486,\n",
       " 2476.173799126623,\n",
       " 2508.453752515754,\n",
       " 2488.783901356426,\n",
       " 2506.3762617786647,\n",
       " 2519.2795989705205,\n",
       " 2566.559950886783,\n",
       " 2557.672246908322,\n",
       " 2685.317550062854,\n",
       " 2691.407236352081,\n",
       " 2685.136948505321,\n",
       " 2685.7944266150544,\n",
       " 2691.0452732888793,\n",
       " 2698.786992636593,\n",
       " 2651.082280478935,\n",
       " 2639.4065079692346,\n",
       " 2552.8470772320265,\n",
       " 2590.6479178194886,\n",
       " 2637.2472047150786,\n",
       " 2651.1668291189244,\n",
       " 2656.548067895423,\n",
       " 2695.2189740833196,\n",
       " 2682.7264393225614,\n",
       " 2619.3759278366065,\n",
       " 2679.8696052817327,\n",
       " 2600.3885183153347,\n",
       " 2601.6678201276227,\n",
       " 2675.361595852184,\n",
       " 2602.606948528632,\n",
       " 2585.2110215372313,\n",
       " 2660.665594005911,\n",
       " 2665.564381893389,\n",
       " 2629.5966550728167,\n",
       " 2635.4860538348134,\n",
       " 2639.611348533332,\n",
       " 2666.766081528491,\n",
       " 2668.4695327941236,\n",
       " 2720.3605815076035,\n",
       " 2762.1795966975997,\n",
       " 2759.0771311678086,\n",
       " 2753.600512057459,\n",
       " 2725.9595659881925,\n",
       " 2549.3251468859426,\n",
       " 2561.5360969172557,\n",
       " 2566.131224021674,\n",
       " 2472.4561558518185,\n",
       " 2477.9799512371105,\n",
       " 2526.7102009384253,\n",
       " 2543.606128671932,\n",
       " 2562.135773690826,\n",
       " 2585.151855942876,\n",
       " 2760.3307101337705,\n",
       " 2757.680839018109,\n",
       " 2671.1333505886096,\n",
       " 2647.6854689370257,\n",
       " 2487.4206592170895,\n",
       " 2628.2835341450664,\n",
       " 2537.4889256195493,\n",
       " 2567.5005319752404,\n",
       " 2645.323368282621,\n",
       " 2660.991516689155,\n",
       " 2525.249357939097,\n",
       " 2742.2657346722904,\n",
       " 2669.271788397068,\n",
       " 2726.773186191679,\n",
       " 2755.233923991998,\n",
       " 2672.0888307414575,\n",
       " 2559.481020585098,\n",
       " 2568.0570986461735,\n",
       " 2754.974366437658,\n",
       " 2760.60239217801,\n",
       " 2760.4552112801744,\n",
       " 2758.603973205229,\n",
       " 2797.9314068276108,\n",
       " 2793.8818781192226,\n",
       " 2623.1290090122698,\n",
       " 2535.256494284214,\n",
       " 2564.5036928995537,\n",
       " 2601.4652691975284,\n",
       " 2698.1158960255257,\n",
       " 2643.5691152135055,\n",
       " 2779.6323496460823,\n",
       " 2817.8381095027926,\n",
       " 2793.904847363089,\n",
       " 2717.4969966804424,\n",
       " 2721.5911134050134,\n",
       " 2647.835196012744,\n",
       " 2497.2215512961334,\n",
       " 2514.3356228856906,\n",
       " 2544.7008538435052,\n",
       " 2583.901753203082,\n",
       " 2653.00172073873,\n",
       " 2609.331620294808,\n",
       " 2627.2241783792224,\n",
       " 2637.8150705110643,\n",
       " 2675.7766398074036,\n",
       " 2683.697954253631,\n",
       " 2673.2627101254557,\n",
       " 2662.234007965537,\n",
       " 2718.1822249620514,\n",
       " 2748.7412015296577,\n",
       " 2791.0235268323554,\n",
       " 2737.4511371083463,\n",
       " 2734.981821561407,\n",
       " 2713.2409083099874,\n",
       " 2800.126587759095,\n",
       " 2848.997396055641,\n",
       " 2833.6025346078723,\n",
       " 2678.604831058512,\n",
       " 2729.2990457006313,\n",
       " 2774.2532886725758,\n",
       " 2795.5154042430154,\n",
       " 2780.1801518387183,\n",
       " 2770.433005709152,\n",
       " 2885.862310506356,\n",
       " 2817.0503473435638,\n",
       " 2831.40472774097,\n",
       " 2811.981771718019,\n",
       " 2764.6440702473956,\n",
       " 2768.9470311681252,\n",
       " 2795.0770003833645,\n",
       " 2880.7205319308664,\n",
       " 2845.1105907215983,\n",
       " 2822.025515390533,\n",
       " 2888.074364123824,\n",
       " 2860.6606655802393,\n",
       " 2826.6608939254934,\n",
       " 2817.538228076487,\n",
       " 2830.522238942182,\n",
       " 2809.904698980812,\n",
       " 2776.28992819574,\n",
       " 2730.2127956383174,\n",
       " 2762.659626451494,\n",
       " 2777.22080629253,\n",
       " 2790.3549164370743,\n",
       " 2779.109543178777,\n",
       " 2694.5076876218845,\n",
       " 2790.2224010746086,\n",
       " 2797.7969454244594,\n",
       " 2833.2405010473717,\n",
       " 2736.0093668794666,\n",
       " 2722.8217160667123,\n",
       " 2670.098910750069,\n",
       " 2770.3684104103786,\n",
       " 2744.995552714836,\n",
       " 2742.2240425382497,\n",
       " 2724.9252350249094,\n",
       " 2574.0654159486694,\n",
       " 2583.42780950933,\n",
       " 2593.3910769234712,\n",
       " 2814.736084706127,\n",
       " 2622.44946121525,\n",
       " 2474.5627140694874,\n",
       " 2538.7868141696345,\n",
       " 2537.3831042788156,\n",
       " 2581.6293437677286,\n",
       " 2596.897749284152,\n",
       " 2564.488008447811,\n",
       " 2553.358239345263,\n",
       " 2653.9187685602537,\n",
       " 2616.074469704883,\n",
       " 2771.6266979751854,\n",
       " 2686.829332257292,\n",
       " 2710.2026612032478,\n",
       " 2697.48029677429,\n",
       " 2722.8770005039078,\n",
       " 2630.3113179164693,\n",
       " 2684.686800885808,\n",
       " 2603.509799844646,\n",
       " 2530.362006755803,\n",
       " 2673.763026567569,\n",
       " 2770.505154079842,\n",
       " 2697.6816508210172,\n",
       " 2781.8221304691942,\n",
       " 2625.3762367848585,\n",
       " 2649.0823777125515,\n",
       " 2659.518759676495,\n",
       " 2619.945233657305,\n",
       " 2558.4547850808794,\n",
       " 2640.5952265672245,\n",
       " 2668.367875903627,\n",
       " 2547.4055094785085,\n",
       " 2740.724171289392,\n",
       " 2651.996468215921,\n",
       " 2597.416272312361,\n",
       " 2579.094481517587,\n",
       " 2767.2548413029,\n",
       " 2767.1280527322156,\n",
       " 2807.9275979109602,\n",
       " 2720.597230708485,\n",
       " 2802.610986144474,\n",
       " 2878.0138043442903,\n",
       " 2671.1077970889955,\n",
       " 2836.602389935119,\n",
       " 2811.240246613389,\n",
       " 2800.519376486338,\n",
       " 2755.6903349214363,\n",
       " 2699.034104359006,\n",
       " 2722.000310576149,\n",
       " 2734.7864017533216,\n",
       " 2510.7169432378364,\n",
       " 2594.4727024258596,\n",
       " 2715.491083613641,\n",
       " 2554.995896271106,\n",
       " 2562.493150437415,\n",
       " 2779.88027895274,\n",
       " 2654.8269011896277,\n",
       " 2695.3305901671433,\n",
       " 2580.205108267418,\n",
       " 2697.911296374055,\n",
       " 2430.200354991633,\n",
       " 2600.1584190216236,\n",
       " 2634.7712183202507,\n",
       " 2636.7609661401007,\n",
       " 2655.6991383908894,\n",
       " 2685.59430024976,\n",
       " 2731.158457224683,\n",
       " 2623.5369438825046,\n",
       " 2678.9175254307966,\n",
       " 2686.628582043598,\n",
       " 2756.772522862947,\n",
       " 2663.641307951983,\n",
       " 2651.4571987807935,\n",
       " 2545.3295911228556,\n",
       " 2607.7682739530223,\n",
       " 2581.8823492723645,\n",
       " 2554.5078745224732,\n",
       " 2559.6859094850092,\n",
       " 2600.089357082291,\n",
       " 2675.9614994150247,\n",
       " 2635.811709464659,\n",
       " 2613.36871358349,\n",
       " 2664.3118475091073,\n",
       " 2693.4696757484903,\n",
       " 2683.0607735503754,\n",
       " 2586.5397596977455,\n",
       " 2727.9134132344984,\n",
       " 2699.777569445906,\n",
       " 2760.078514158287,\n",
       " 2721.317867254082,\n",
       " 2772.549945626792,\n",
       " 2738.7907335283116,\n",
       " 2714.4958294462995,\n",
       " 2743.3967904309243,\n",
       " 2746.706581324857,\n",
       " 2702.2117821873235,\n",
       " 2727.7796013817033,\n",
       " 2737.822473579234,\n",
       " 2629.6099098338746,\n",
       " 2729.872568998429,\n",
       " 2756.1941819993162,\n",
       " 2693.6854539297306,\n",
       " 2711.2691869562127,\n",
       " 2601.3447402939305,\n",
       " 2677.679731886955,\n",
       " 2764.46303329232,\n",
       " 2738.812523175028,\n",
       " 2773.917986936643,\n",
       " 2661.7183210608387,\n",
       " 2671.2489758769098,\n",
       " 2660.711763671474,\n",
       " 2778.029929677678,\n",
       " 2632.117540296703,\n",
       " 2665.4793853507285,\n",
       " 2606.3287098086903,\n",
       " 2621.603309632223,\n",
       " 2702.678161553247,\n",
       " 2801.780069806698,\n",
       " 2675.569805308025,\n",
       " 2685.5732245485915,\n",
       " 2579.4021202546696,\n",
       " 2606.860739408683,\n",
       " 2691.0993792301765,\n",
       " 2704.922413069455,\n",
       " 2692.560500469708,\n",
       " 2745.172699381649,\n",
       " 2631.5632001058398,\n",
       " 2713.958412282125,\n",
       " 2742.579555731467,\n",
       " 2676.642291274726,\n",
       " 2689.425615302344,\n",
       " 2704.6050240545865,\n",
       " 2665.9020002062093,\n",
       " 2690.5411410196252,\n",
       " 2657.452072186283,\n",
       " 2565.212884325735,\n",
       " 2797.0420693588094,\n",
       " 2620.8330086532205,\n",
       " 2649.834967388241,\n",
       " 2822.3084921631753,\n",
       " 2764.3184691823744,\n",
       " 2765.428602137611,\n",
       " 2764.299086252962,\n",
       " 2737.6032853170764,\n",
       " 2735.7706390519706,\n",
       " 2828.3632436194075,\n",
       " 2798.1524664887215,\n",
       " 2823.11906967788,\n",
       " 2818.2048829307537,\n",
       " 2799.7691604857932,\n",
       " 2637.367083763706,\n",
       " 2669.0676852856186,\n",
       " 2728.64932015214,\n",
       " 2756.5400870239337,\n",
       " 2643.25544056346,\n",
       " 2668.271291250904,\n",
       " 2825.946101411581,\n",
       " 2834.6749272252796,\n",
       " 2756.721631423948,\n",
       " 2767.281785474386,\n",
       " 2811.003177613448,\n",
       " 2766.4316754798206,\n",
       " 2810.487916280413,\n",
       " 2818.7428786525375,\n",
       " 2743.619422795939,\n",
       " 2828.7676393618954,\n",
       " 2785.6746263173527,\n",
       " 2708.371231422274,\n",
       " 2793.6227822418527,\n",
       " 2727.7154836540385,\n",
       " 2796.066862389499,\n",
       " 2821.46685781135,\n",
       " 2789.6969668210063,\n",
       " 2614.650193804051,\n",
       " 2688.8482306325486,\n",
       " 2732.6464088438543,\n",
       " 2643.0453229534346,\n",
       " 2660.2183974802197,\n",
       " 2777.7016362731397,\n",
       " 2818.834366150154,\n",
       " 2793.1615171205417,\n",
       " 2794.929574463384,\n",
       " 2792.1191316932436,\n",
       " 2623.5352384352936,\n",
       " 2685.9876646153025,\n",
       " 2782.0016736208427,\n",
       " 2799.8564121879717,\n",
       " 2718.3171980343095,\n",
       " 2722.7304928331178,\n",
       " 2693.54282011884,\n",
       " 2712.7641599736153,\n",
       " 2798.2860260745856,\n",
       " 2852.8657927903214,\n",
       " 2804.370664819128,\n",
       " 2785.827068692551,\n",
       " 2852.6732005440676,\n",
       " 2771.5625515874312,\n",
       " 2797.1196284579014,\n",
       " 2712.564783292296,\n",
       " 2717.1375609976158,\n",
       " 2780.490748627724,\n",
       " 2782.2221103332513,\n",
       " 2768.606072033963,\n",
       " 2775.1187276179867,\n",
       " 2744.56866263992,\n",
       " 2676.8816096606897,\n",
       " 2649.7817718527645,\n",
       " 2776.1084120459673,\n",
       " 2703.7154927162665,\n",
       " 2730.2686597220904,\n",
       " 2732.3342957246355,\n",
       " 2806.798828311851,\n",
       " 2850.652769225298,\n",
       " 2759.488915325044,\n",
       " 2724.020397829595,\n",
       " 2719.4899152037488,\n",
       " 2649.9598939192842,\n",
       " 2742.214026521501,\n",
       " 2659.5063780544606,\n",
       " 2651.362378198375,\n",
       " 2656.272586972264,\n",
       " 2567.836610769665,\n",
       " 2754.0311307211578,\n",
       " 2726.709182875699,\n",
       " 2532.6760829411073,\n",
       " 2718.180228122766,\n",
       " 2652.9499626827364,\n",
       " 2649.9885183439696,\n",
       " 2666.3694997630328,\n",
       " 2656.39907549981,\n",
       " 2721.1905978643567,\n",
       " 2725.158650712756,\n",
       " 2702.8151138648927,\n",
       " 2755.235207058678,\n",
       " 2644.5248973075186,\n",
       " 2702.998634216613,\n",
       " 2765.4929463313138,\n",
       " 2748.237457139247,\n",
       " 1149.7733294376824,\n",
       " 788.1530152650829,\n",
       " 338.0859246300673,\n",
       " 298.4458338363748,\n",
       " 232.24340198767138,\n",
       " 216.1399533043534,\n",
       " 240.73580114096055]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume Training to push agent to learn more...\n",
    "# RESULT: Max score = 2850\n",
    "\n",
    "# Restart training params (if restart training is false)\n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/final_alt'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/final_alt'\n",
    "params.restart_training = False\n",
    "params.eps_to_resume_from = 491\n",
    "params.actor_weights_filename_to_resume = 'checkpoint_actor_ep490.pth'\n",
    "params.critic_weights_filename_to_resume = 'checkpoint_critic_ep490.pth'\n",
    "params.terminate_on_target_score = True\n",
    "params.target_score = 3000.0\n",
    "\n",
    "#### MAIN #####\n",
    "#tb=CustomSummaryWriter()\n",
    "#logger = Logger(params, tb=tb)\n",
    "#agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAFNCAYAAABMn9WLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACKxklEQVR4nOzdd3gc1dn38e+96pIlV7l3bDC26cY2EDoEQyAmCSS0UBNDXlrKkwRSyZPwQEIqpBBCAJNQQktw6KY3d8DGvRe5yk297p73jxnJK3nVd7W70u9zXb40e6bsPYsYzd5zzn3MOYeIiIiIiIiIiEh7BeIdgIiIiIiIiIiIJDclmEREREREREREpEOUYBIRERERERERkQ5RgklERERERERERDpECSYREREREREREekQJZhERERERERERKRDlGCSbsvMrjaz9+Mdh4iIiHRvZvYDM3uwmfWXm9lrnRmTiIhIWynBJDFjZhvNrMLMSs1sh5k9YmY94h2XiHRtZva2me0zs4xWbh/1ZLOZ3WFm/4zmMUUkeZjZZWa20L8H2m5mL5vZZ5ra3jn3f865r/n7jjQzZ2apYesfc859th1xPGJmv2jfWYhIomv0favu3x9bue/bZva1WMfYGnrw33UowSSxdoFzrgdwNHAMcHs8ggi/SRORrsvMRgInAw74fCe9p64vIlLPzL4N/B74P2AAMBz4MzC9ie11DRGRjrjAOdcj7N9N0Tiork3SHkowSadwzu0AXsVLNGFmU83sQzPbb2aLzew0v/10M/u0bj8ze93M5oe9ft/MLvSXbzOzdWZWYmbLzewLYdtdbWYfmNnvzGwvcIeZ9TWzWWZW7B/zkLDtzd92l5kVmdkSM5sYy89ERGLiSmAu8AhwVfgKMxtmZs+ZWaGZ7TGzP5rZ4cD9wAn+U7/9/rY9zexRf9tNZvYjMwv46w66vrQlQDP7vJkt869/b/sx1K37vplt9a9rq8zsTL99st8botjMdprZb9v9CYlIzJhZT+B/gRudc88558qcczXOuf86577rb3OHmT1jZv80s2Lg6ka9Ht/1f+73r0snNH66b2YTzGy2me31rwk/aEesXzeztf4xZpnZYL+9yXsiMzvPv+cq8a9V/9OBj0tEYqjuumFmvzavZ/cGMzvXX3cn3gO5P4b3ejKv9+SNZrYGWOO3RbxWhG1/i5mtN7PdZnaPmQXMLMPf/oiwbfub19sqv43ncaKZLfCvRwvM7MRG57jevyZtMLPL/fYxZvaOv89uM/tXBz5KaQMlmKRTmNlQ4FxgrZkNAV4EfgH0Af4HeNa/2MwBxphZP/Oy5hOBoWaWa2ZZwHHAe/5h1+FdGHsCPwP+aWaDwt52CrAe6A/cCfwJqAQGAdf6/+p8FjgFOBToBXwF2BPNz0BEOsWVwGP+v3PMbACAmaUALwCbgJHAEOBJ59wK4AZgjv/Ur5d/nPvwri2jgVP9414T9j6Nry+tYmaHAk8A3wTygZeA/5pZupkdBtwEHO+cywXOATb6u/4B+INzLg8vOf5Ua99TRDrVCUAm8O8WtpsOPIN3z/FYo3Wn+D97+delOeErzSwXeB14BRgMjAHeaEuQZnYGcBfwZbz7ok3Ak/7q5u6J/g5c71+jJgJvtuV9RaTTTQFWAf2AXwF/NzNzzv0Q7zvVTRF6PV3o7ze+hWtFnS8Ak4Bj8a5t1zrnqvztrgjb7lLgdedcYWuDN7M+eN8b7wX6Ar8FXjSv40CO336uf006EfjE3/XnwGtAb2Ao3n2ddAIlmCTW/mNmJcAWYBfwU7wLzUvOuZeccyHn3GxgIXCec67SXz4F70K1BHgfOAmYCqxxzu0BcM497Zzb5h/jX3hZ9slh773NOXefc64WqAa+BPzEf5q4FJgZtm0NkAuMA8w5t8I5tz02H4mIxIJ59U1GAE855xbhJaEv81dPxvsi9l3/GlDpnIs41t9PRn0FuN05V+Kc2wj8Bvhq2Gb11xfnXEUbwvwK8KJzbrZzrgb4NZCFd1MUBDLwbujSnHMbnXPr/P1q8JPvzrlS59zcNryniHSevsBu/96jOXOcc//x72Hacg0BOB/Y4Zz7jX8tK3HOzWvjMS4HHnLOfeR/EbwdryfnSJq/J6rBu0blOef2Oec+auP7ikj0/cfvFV337+th6zY55/7mnAviffcZhDd0tzl3Oef2+tem5q4VdX7pb78Zb3jwpX77TOAy83uA491H/aON5/Y5vO9///DvuZ4AVgIX+OtDwEQzy3LObXfOLfPba/DuCQc3d88n0acEk8TahX5G+TS8G5V+eP+zXxx+IQQ+g3fBA3jH3/4Uf/ltvB4Ep/qvATCzK83sk7BjTPSPX2dL2HI+kNqobVPdgnPuTeCPeL2cdprZA2aW15ETF5FOdxXwmnNut//6cQ4MkxuGd5PV0pc+8K4j6YRdI/zlIWGvt9A+g2l47Qn5xxrinFuL17PpDmCXmT0Z1g39OrzeBCv97uHnt/P9RSS29gB1vbCb095rCHjXs3UtbtW8xteiUrzYh7RwT/Ql4Dxgkz/85IQOxiEiHXehc65X2L+/ha3bUbfgnCv3F1uadCn8+tTktaKJ7Tf5++AnvsuAU81sHF5vy1mtO6XI7x/2HkOcc2V4D+5uALab2Yv++wB8DzBgvnllCa5FOoUSTNIpnHPv4NVE+TXeRegfjS6EOc65u/3NGyeY3qFRgsnMRgB/wxtO0tcf1rIU70JS/7Zhy4VALd5NWZ3hjWK81zl3HDAB74vcdzt21iLSWfwhtF/Gu4nZYWY7gG8BR5nZUXjXneFNfOlzjV7v5sCTrzrDga3N7NNa28KPa2aGd13aCuCce9w5V9cTywG/9NvXOOcuxRuS90vgGb9ruIgkljl4w/EvbGG75q4hLV1fthBWR7KdGl+LcvB6X9VdiyLeEznnFjjnpuNdi/6DhuuKJLOmrjXh7c1eK3yNv19tC3s9E2/0yleBZ/zRKm3R4P3D3qPuWvWqc+5svI4KK/G+H+Kc2+Gc+7pzbjBwPfBnMxvTxveWdlCCSTrT74Gz8Ya8XWBm55hZipllmtlpfp0mgA+Bw/CGtMz3uzqOwBsLXFf4Mgfv4lcIYGbX4PVgisjvFvocXrHvbDMbT1gBYDM73symmFkaXqa9Em+4iogkhwvx/p8djzeZwNHA4Xj1Ba4E5gPbgbvNLMe/7pzk77sTr9ZbOtRfL54C7vTrv40Avg38k7YJ+O9T9y/DP+7nzOxM/3rzHaAK+NDMDjOzM/ztKoEK/5wwsyvMLN/v8bTfP76uUSIJxjlXBPwE+JOZXejfc6SZ2blm9qtWHqYQb9jH6CbWvwAMNLNvmldIN9fMpjRzvJRG16J0vB6e15jZ0f415/+Aec65jU3dE/m14i43s57+EN9idB0SSWY7afo6U6fJa0XYNt81s95mNgy4FQgvqP0PvBpNVwCPtvBe1uhalYlXq/JQM7vMzFLN7Ct493ovmNkA8yZOycG7lyrlwH3TxWHfLffhfW/U9aoTKMEkncYv6PYo3hCQ6cAP8G6ituA9GQv425UBHwHLnHPV/u5z8Ia37PK3WY5XE2UO3sXxCOCDFkK4Ca9L6A683lQPh63Lw8t478PrdrkHr7eViCSHq4CHnXOb/adWO5w3e+Uf8eoHGN54/THAZqAAr1s1eEVqlwE7zKxueN3NeF+s1uMlxR8HHmpjTJfiJYnq/q1zzq3Cu8m6D6+n1AV40wtX49Vfuttv34HXQ6BuZqhpwDIzK8Ur+H1JO54CikgncM79Fi8p/SMO3OfchNfjpzX7l+NNHvCBXwZgaqP1JXgP7C7Au1asAU5v5pC30fBa9KZz7g3gx8CzeMn3Q4BL/O2buyf6KrDRvNnvbqBhAV8RiY//mjcTXN2/liYZqPMH4CLzZpi7N9IGLVwr6jwPLMIrsP0i3mQAdfsX4H2vcxyYqKkpJ9LwWlUBFOHVnfsO3rXoe8D5fjmEgN++DdiLN9rl//nHOh6Y5983zQJudc5taOH9JQrMufb28hcRERERERGR7sjMHDDWryPZ1DYP4U2O8qPOi0zipaUChCIiIiIiIiIibeLPNvdF4Jg4hyKdREPkRERERERERCRqzOzneJMw3aPhad2HhsiJiIiIiIiIiEiHqAeTiIiIiIiIiIh0SMwSTP7UgvPNbLGZLTOzn/ntfcxstpmt8X/2DtvndjNba2arzOycsPbjzOxTf929ZmaxiltERERERERERNomZkPk/CRQjnOu1MzS8KZ5vhWvyNde59zdZnYb0Ns5930zGw88AUwGBgOvA4c654JmNt/fdy7wEnCvc+7l5t6/X79+buTIkTE5NxHpHIsWLdrtnMuPdxwdoWuRSPLTtUhEEkWyX490LRLpGpq6FsVsFjnnZa5K/Zdp/j8HTAdO89tnAm8D3/fbn3TOVQEbzGwtMNnMNgJ5zrk5AGb2KHAh0GyCaeTIkSxcuDB6JyQinc7MNsU7ho7StUgk+elaJCKJItmvR7oWiXQNTV2LYlqDycxSzOwTYBcw2zk3DxjgnNsO4P/s728+BNgStnuB3zbEX27cLiIiIiIiIiIiCSCmCSbnXNA5dzQwFK830sRmNo9UV8k1037wAcxmmNlCM1tYWFjY5nhFRERERERERKTtOmUWOefcfryhcNOAnWY2CMD/ucvfrAAYFrbbUGCb3z40Qnuk93nAOTfJOTcpPz9phyaLiIiIiIiIiCSVWM4il29mvfzlLOAsYCUwC7jK3+wq4Hl/eRZwiZllmNkoYCww3x9GV2JmU/3C4VeG7SMiIiIiIiIiInEWsyLfwCBgppml4CWynnLOvWBmc4CnzOw6YDNwMYBzbpmZPQUsB2qBG51zQf9Y3wAeAbLwins3W+BbREREREREREQ6TyxnkVsCHBOhfQ9wZhP73AncGaF9IdBc/SYRERERERGJwMymAX8AUoAHnXN3N1pv/vrzgHLgaufcRy3ta2Y3AzfhdRB40Tn3vU44HRFJULHswSQiIiIiIiJx5I8o+RNwNl592wVmNss5tzxss3PxSpSMBaYAfwGmNLevmZ0OTAeOdM5VmVl/RKRb65Qi3yIiIiIiIhIXk4G1zrn1zrlq4Em8xFC46cCjzjMX6OVPyNTcvt8A7nbOVQE453YhIt2aEkwiIiIiIiJd1xBgS9jrAr+tNds0t++hwMlmNs/M3jGz46MatYgkHSWYRKIgGHLsKa0CYF1hKVv2lsc5IunqPt68j6KKmniHISIiIu2wcONeyqpqO+vtLEKba+U2ze2bCvQGpgLfxZvI6aDtzWyGmS00s4WFhYWtj1pEOkV1bYjH521m2/6KDh9LCSaRKPj1a6s47hevM2vxNs78zTuc/Ku3OnzMZxcVsK+sOgrRSVcTCjm+8OcPueqh+fEORURERNpoT2kVF90/h1uf/KSz3rIAGBb2eiiwrZXbNLdvAfCcP6xuPhAC+jV+c+fcA865Sc65Sfn5+R06ERGJnmDI8fTCLZzxm7f5wb8/5flPGl8W2k4JJpEoeHXZDgBueeLjqBxv7a4SvvP0Yr7z9OKoHE+6lrrHhksK9sczDBEREWmHipogACu2F3fWWy4AxprZKDNLBy4BZjXaZhZwpXmmAkXOue0t7Psf4AwAMzsUSAd2x/xsRKRDnHO8snQH037/Lt99Zgl9ctJ55JrjueHU0R0+tmaRE4mCtEB0c7XFlV6X6bphd4no3dWF5GWlcfSwXvVtpVW1ZKQGSEtR7lpEREQkETjnas3sJuBVIAV4yDm3zMxu8NffD7wEnAesBcqBa5rb1z/0Q8BDZrYUqAaucs41HnonIgnkw3W7+eUrq1i8ZT+j83P4y+XHMm3iQCKMbm0XJZhEOuC+N9bwm9mrGT8o76B1lTVBMtNS2nXcmtoQAOmpiZmoeWvVLq55eAEAH952BoN7ZQEw8aevcuqh+cy8dnI8wxMRERFJeJ2Zi3HOvYSXRApvuz9s2QE3tnZfv70auCK6kYpILCzbVsTdL6/kvTW7GdQzk1996Ui+eOwQUqPcMSAxv72KJInfzF4NwI7iyoPWvb3KK2L4zKIC3l7Vtllba4LeDceCjfs6GGHrlFbVsss/h0Wb9nLrkx9TGwyxakdJxO13FB0438YFKt9ZreKNIiIiIiIi8VZYUsVtzy7h/Pve59OtRfzoc4fz1v+cxpePHxb15BKoB5NIq6zdVUKv7HT69cho0N4rO4395TXsjVCM+4Z/LmLj3Z/jf/w6Shvv/lyr368mGKpf7khPqJZUVAf5yfNLeW35Tooqanj6hhO4+P45AOwureKDtXu4/pTRHD2sFxMG92RveTVHD+tFauBAF8q6Z29VtcGYxCgi0lWY2UPA+cAu59xEv60P8C9gJLAR+LJzbp+/7nbgOiAI3OKce9VvPw54BMjC61Vwq4aliCSfaA1JERFprKo2yMMfbOSPb66lsibItSeN4pYzxtIzOy2m76sEk0grnPXbd8nNSOXTn53ToL282kuqpASMYOjge/vG9/sjb3uRC44azH2XHtPs+4X3eCrYV8GY/j3aG3qzZi3eytOLCupf1yWXAD5YuweAv767vsE+G+/+HKkpB26IKv1ClWVVSjCJiLTgEeCPwKNhbbcBbzjn7jaz2/zX3zez8XjFdCcAg4HXzexQ51wQ+AswA5iLl2CaBrzcaWchIiIiCck5x6vLdvJ/L61g895yzhzXnx9+7nBG58fm+2RjGiIn0oSSyhrufHE5u/1C2yWNhoIBVPu1ksKTS2ePH8A3zxoLwPaig4fO/Xdxy9M/zpyzqX75o00dHyYXDDlG3/4i/5i7qUH7C0u2t/lYv3hhOY98eOA4i/z4SisP/nwkNtRRQSQ5OefeBfY2ap4OzPSXZwIXhrU/6Zyrcs5twCu8O9nMBgF5zrk5fq+lR8P2ERERkW5qw+4yrnxoPjf8cxGZaQEevXYyf7/6+E5LLoF6MIk0ad76vfztvQ2sLyyLuP6In74asb1HRioj+mYDcOLdb7bqvQpLqshIC5CXmXZQ8qBgf0V9W3u7UlfWBAk5uPPF5Xx16gjAS1K8t6bhTLIBgwgdsRp48P0NDV7/7L/LmX70EEojJOBERKRFA/ypwHHObTez/n77ELweSnUK/LYaf7lx+0HMbAZeTyeGDx8e5bBFREQkEVTWBPnz2+u4/+11ZKQG+NnnJ3D5lOExqbHUEiWYRJqwv6IGgEK/B1NjkXo0AfTOTqd3dvpB7Y3rNH28eR+H9O9BTnoqx9/5On1z0ln047MPOm5xRQ2Pz9/MD/+9lAU/PIv83IZ1oMK9sGQbZx0+oL5m08eb9/HTWcvYU+q9d0pYgirSkL7UlEB9r6zG+vVIZ3fpwbWmAI79+Wx6xXg8r4hINxPpiYJrpv3gRuceAB4AmDRpkro+ioiIdDHvri7kJ88vZeOecqYfPZgffu5w+udmxi0eJZikW1pfWMpbqwq5+sSRpASMt1bu4sihPekbVsS7bjhZeoTMb1NJGIA+OWn0yTk4wXTsz2fXL9cGQ3zhzx8yaURvTjykLwB7/ATUWysbzjhXUlnLM36dpM17y8jPzcA5RzDkGmSlX1iyjZse/5jLpgzn/75wBBXVQb7w5w8bHCsQlmCqjZBgqg02fV4lLQyB219e0+S6F5Zs47VlO7m3hdpTIiLd0E4zG+T3XhoE1P0RKACGhW03FNjmtw+N0C4iSUZD3kWkvXYWV/K/LyznxSXbGd0vh8e+NoWTxvSLd1iqwSTd08MfbOTnLyzn2Y8KKK6s4ZpHFjD9Tx8A8ObKnYy87UUWb9kPeAW869T1+ok0a9xLt5zM5VOGc9WJIyP2YApXE/SOs2jzPj7avL/Bun2Njl1cWVPf86guJ/SXd9Yx5ocvU1x5IKlz0+MfAzB7+U7uenkFh//klYPe18xLIoVCjlCEm5rmhsdVNUqq5Wamkp4a+RKyZW85Z/7mbbYXVfDGip3c9PjHzFq8jTINo4sK3Y6KdCmzgKv85auA58PaLzGzDDMbBYwF5vvD6UrMbKp546avDNtHREREujDnHE8t3MJZv32H2ct38u2zD+Xlb56cEMklUA8m6aaCfnLl4837Of0wr9xFwb4KiitruPaRhQ22rZslrW45JyOVPWUHD5sbPziPO79wBNByraSakJesca5hAmvF9mJ+/uKKBttu2F1Gjwzvf9W6BNdjczcDUFReQ15mw6FphSVV/PWdhjO/1UkJGGN+6E009Mg1xzcZX25GapNDAOtkp6c02ZPr5F+9BcAT87fw7urC+vYt+8oZNzCv2eOKiHRVZvYEcBrQz8wKgJ8CdwNPmdl1wGbgYgDn3DIzewpYDtQCN/ozyAF8A29Guiy82eM0g5xIEmpvbU0R6Z627q/g9uc+5d3VhUwe1YdffulIRvXLiXdYDSjBJN1SkV9faUdRBbWhA0mSOev2HLRtRViCqaIuwdRELaI6Oekpza6vDR7ogxLeG+XKh+YfVBtp7a7S+uVQyPH8J1vZur/C29fftKaZoW3hwpNZd7+8ssntThzTl+9PG8cZv3mnyW2y01Mj9uQKV1hSySd+TzCAUOvCFBHpkpxzlzax6swmtr8TuDNC+0JgYhRDExERkQQVCjmeWLCZu15aScg5fvb5CXx16ggCgcRLUmuInHRLxX6CaU9ZdYNkT0aEIV/l1QcSTLM+8cpctJRYMTPuuGB8k+vDax2F9/Bp6RIRcnDrk5/Uv66q9WJ7ZemOFvb0hCev6npFAbxw82f4/rRxDd6npeksN+wuqx/q15Qn5m9p8NppcFdUqGSDiIhI8lMNJhFpyZa95Vz+4Dx++O+lHDWsJ69+8xSuOnFkQiaXQAkm6eIqqoMR/3jXJZhqg65BsevGNYXMGg6R21/uJZbqekA15+qTRjW5rqaJYkdN1TSqE2x0LpU1XqIqJ6P5HlN19oUV4l64aV/9cs+sNLLDel219obnsima9lpERERERCSa6motTfv9u3y6tYi7vngE/7xuCsP6ZMc7tGYpwSRJL9TEbGh3zFrG4T95hReWbOc7Ty1u0FOoLkFUGwoRDBu31XjGuIzUALvDhsOlBLz1pX59onk/iDiqoUVNzdbWUoLpqofmN3hd14Ppb+9uaFccdVJTjNSUA1nwuo/08a9P4brPNJ0ou+OCCSy547P1r68+cWSz76MHdSIiIiIe1WASkUj2lVXz/x77iO89s4SJQ3ryyjdP5tLJw5PimqEEkySlHUWVOOcoq6pl9A9e4h9zNjZY//LSHTzyodc2b8Menv2ogCsfmk95tZcYOpBgcs0O88pKa9gzqKImyJ7SKu55dRXg9fxpzqPXTo6YdIn0niP6Zh+U4GpJZU2IHUWVzFnv1Y76x3WTefnWk9t0DIDUQIDUsG6WdT2YTjykH8cM73XQ9hMG5/H416aQnhpoUGT8xtPHtPm9RURERLojDZETkcbeW1PItD+8y+srdnLbueN4/OtTGdo7sXsthVORb0k624sqOOGuNzlmeC+OHtYLgMfmbearJ4ys32ZncWX9clnVgSFu43/yKo9/fUr9ULHaoGtQl6hxge3MtBTgwLCyiupanv2ooP51XULo+lNGR4z1lEPzGT84rz7ZVac2QrXrtJQAK3eURDxOU/aWVzP1rjfqX/fMSmuxF1QkqQEjYAf3YKpb19gfLzs24owF2S0UN5foUC0rEREREZGuo7ImyK9eWcVDH2xgTP8e/P2q45k4pGe8w2ozJZgk6dT1Pvp4834+3rwf4KCsbrU/BC07PYX1u8sarLvsb/MAb0a1YMg1mIHtFy+uaLBt46LfJZW1bNxTXv86EDA23HVes/H2yU7n7PEDmL18Z31bcUXtQduFzxYH8PPpE8jPzeCGf37U5LF3FlU2eJ2WEohYqLwlqSnWYLa88KRSIEJXzKZmyUtrYw8sERERke4qGYa7iEjsrSss5cbHPmLljhKuPnEkt507zu/okHz0bVCSTnXtwb1/Xl+xk6Vbi+pf19R6PTz69chg8Zb9EY9z5rj+1ARDDXotfRp2DOCg/7Gf+3grj8/bDHj1icC7OWjuBiEQMP525aQGiZ9rHp7f5PZ1vnrCSKZNHNTsNvM37m3wOi3FWt2DacqoPvXLqYEA+8oO9NTKz82oX66OUC8qJ6NhbrpuRrq0lOZvlNQTXERERERExPP8J1u54L732VVSxcNXH88dn5+QtMklUIJJksgrS3cw49GF7Cyuqm/7wXnj6pd/O3t1/XJNMERKwJg4JK/J4+XnZvg9mJrOemSE/c89qGdm/fLAvExOPKRfm+IP7wlUVh1sZsvWCx8KCF4PosZ1nC4+bmjEfcOTSJlpgQY9uc474kBiq26munCNa1O9dMvJ/PriozAzHrp6UoN1s246qYWzkLZSok5ERCT5qQaTSPdVWRPk9ueWcOuTnzBhcB4v3vIZTh/XP95hdZiGyEnSuOWJj6kOhhpMzdgrK71+uSYYYunWIlbtKKE6GCI9JcCgnlkRjzV5ZB/SUgIH9WBqLNPvDXTBUYPZuLuM7f6QtL490pvcpykRShl1WN1wwTqpKQEyUhsmf84aP4CnFxXQWPhwNjPj+lNH43Bcf+ohDQp3V/pD5z5/1GBmLd4GeL2ywg3vm83wvt5/lzPGDWiw7sihvXjwykl87dGFqh0kIiIiIiLdWviQuG+cdgjfOftQUrtIqZGucRbSZRVXHkig1A3V2rL3QA2k8KFa763Zzfn3vc93nl5MdW2ItBQjMy3yr/hjX59Cal0NpggFt+vU9WDKTkshNWz418gIBa5bEmkY3aWTh7f5OADHj+xNTnoKm8LqQYE3RC0rPYXXv31qfds5EwY22Oa4Eb1Z9YtpBxXvzs1M47vnjGuQXIID9ZiG98nmvkuPabJHVHNUYkBERESkIdVgEul+/rt4G5+/7312Flfy8DXH8/1p47pMcgmUYJIE9sT8zRx5x2u8umwHtz/3aX37ln0V9cs5GSmcMLrvQfvWBEOkpwbI9HvzfO7IhrWM0lICpKQYNSFHsJkhcnU9mDLSAqQFDvzvcvWJI9t8PuG3EHmZXmLsmpPafhyAp284MeIwu7oYx/Tv0eS+aSlGRmoKaf65/eLCic2+15eOG8p3zzmMm84YwwVHDeaei49qV8ygoV0iIiIidTRETqT7qA2G+L+XVnDzEx8zblAeL916MqcflvxD4hpTgkkSyvaiCn76/FK27C3nJ88vBeD6fyziifmb67fZW3agBlOPjFSemDGVIb0aDoWrrAl5M6r5PZh6ZaVxUaOeN2mBAMGQo7aZHkx1BbNzM1NJS/VSRMcM78XxI/s0uU9TwotlF1d6s8g1rmXUGtlNzOAGDYeu3XfpMdz9xSMAmHP7GdxxwXgAemd7w/vS/G1rIxTxDpeWEuDG08d0qNicHtCJiIiIeNRzSaR72VdWzdUPL+CBd9dzxdThPPH1qU2Wckl2SjBJQnnp0x3MnLOJm5/4uMni2+FFvuuGyO1oVOy6oqbWr7HkHSM3M41f+z1vzpng1QhK8YfIlVU1XXC7rv5Qfo8MUv3eQTnp7StdVhVh9rusZpJFTQlEuCm59cyxQMPk0wVHDeYSfwjeoJ5Z9Z9VXTKuritmbTM1qKJNz+lERESku4tHzyUzm2Zmq8xsrZndFmG9mdm9/volZnZsS/ua2R1mttXMPvH/nddZ5yOSLJZtK+KCP77P/A17+eWXjuAXFx7R6lm/k5GKfEtC2bbfG/72yZb9Edf3yUlnb1l1/eu6YtvnThzIC0u2c/0po/nru+t56dMdwIEaTrn+kLTVvzi3vqZQ3c9/ztvUZDx1PY3yczNJ82swtafAN8BZh/fn9RW7GrQ11RvpD5cc3eRxIj30uuXMsXzr7EObff/pRw9hy74Kbjh1NEB9TanOSDAZelInIiIiEq6zejKZWQrwJ+BsoABYYGaznHPLwzY7Fxjr/5sC/AWY0op9f+ec+3WnnIhIknn+k618/9kl9MpK56kbTuDoYb3iHVLMdd3UmSSdqtogb6zY2eRwqqy0FPrnZjRoy+/hvb7j8xOY/a1TGNgzs8H6Ej9BVFfzKD01UD+MbMnWIgA+3ry/yZhK6hNMB3ow9c3JaHL75vztyklc7yd36mSGzfh2SP6BwuHTjx7S5HEi9WBKacUUdempAb599qFk+z2wrj5xJEcM6ckXj236vdrrtW+dErG9K9QaMLNvmdkyM1tqZk+YWWbLe0VXF/gYRUREur1OvC+aDKx1zq13zlUDTwLTG20zHXjUeeYCvcxsUCv3FZEwoZDj7pdXcuuTn3DkkF789+bPdIvkEijBJAlk5fYSNu4p59cXRS4i/eo3T6kfUnbk0J7cf8Vx9U9++vXIYOyA3AYV+KdNGMjVJ45kUM9Mzpk48KDjTRzcs355bKOi2P+8bgoLf3QWJX4PqH490ut7+vTLbV8PJjMjIyy+n31+QoOaSU9df0Kz+9927jj/OA3b77noyHbFM6hnFv+9+TP0z41+fuTQAbkNG7pIByYzGwLcAkxyzk0EUoBL4huViIiISLOGAFvCXhf4ba3ZpqV9b/KH1D1kZr2jF7JIciqvruUbjy3i/nfWcdmU4fzza1PIz21fB4VkFLMEk5kNM7O3zGyF/7T/Vr+9ybG6Zna7P7Z3lZmdE9Z+nJl96q+711QZr0vaX+Elc0b2y464fnjf7PoeP6cd1p9pEZJG6SkHfjXOGNefQwfkMuf2MyMmUW48/ZD6oXMTh/RssG5Ynyz69cion42tb04GxX58/drZgwmgsNSrHzVpRG+uajQTXd8eGbz//dN597unR9z31EPzgQM9mF6+9WQevuZ4Lp40rN3xdLYu0vEmFcgys1QgG9gW53hEREQkCXXiV5pIb9T4tqypbZrb9y/AIcDRwHbgNxHf3GyGmS00s4WFhYWtClgkGe0sruQrf53La8t38uPzx3PnhRO7dL2lSGJZg6kW+I5z7iMzywUWmdlsf91BY3XNbDxeT4AJwGDgdTM71DkXxLt4zQDmAi8B04CXYxi7xMH+cq+2Us+sg3sIHTfCeyAS8rsSD8yL3OumbhgbQF5WWrPvl5oSqP+LedjAhj1uevgFsf9wyTGs2F5Mz+w09ld48bW3BxMcGHL3pbAZ7b4yaRhTRnuz0g3tHTm5BgeGwdV1ejp8UB6HD8prdyyx9tDVk+prL3WVjLBzbquZ/RrYDFQArznnXotzWCIiIpKEOnGIXAEQ/kRyKAc/IGtqm/Sm9nXO7axrNLO/AS9EenPn3APAAwCTJk3qIs8bRRpaurWIr81cSHFlDQ9eOYkzDx8Q75DiImbpNOfcdufcR/5yCbCCg7tihpsOPOmcq3LObQDWApP9sb95zrk5zrsKPwpcGKu4pXPtLavm96+vJhhy3PrkJwD0yj44MfSFY7xfnSK/F9GwPpGndUwN68E0uFfLQ78q/Zndwms7vfPd0+jr13bqmZXG1NF9AdhT6iWY8nu0f0hZ3UxyvcPO8ZcXHckXjx3a1C71DtReSo50zRnjBnD6uP4N2pK9dpDf9Xs6MAovEZ5jZldE2C6mT+pcV+kLJiIi0g3FYTDGAmCsmY0ys3S8h/qzGm0zC7jSn01uKlDknNve3L7+97Q6XwCWxvpERBLR7OU7+fJf52AGz9xwYrdNLkEnzSJnZiOBY4B5wEl4Y3WvBBbi9XLah5d8mhu2W9343hp/uXG7dAG/fHkl/1q4pT5xBF5SB6BvTjp7/Bnj6mZbu+mMMdz+7KdMGtEn4vEqqoP1y417JUVS7Sd8+uR4vZJSA8aIvjkRty2t8nofHdI/8vrWqHu/jNTIs8dF8t+bPkNVbfCgHkzJpAuNaj0L2OCcKwQws+eAE4F/hm+kJ3UiIiLSlM6e9MQ5V2tmNwGv4tWPfMg5t8zMbvDX3483SuQ8vIf85cA1ze3rH/pXZnY03pC5jcD1nXZSIgli5ocbueO/yzhiSE8evHIS/ZsYadNdxDzBZGY9gGeBbzrnis3sL8DP8S5EP8cbq3st7Rv32/i9ZuANpWP48OEdD15irq5w9sMfbKxvS0sJsPx/zyFgxrgfvwLABL8g9/lHDub8Iwc3ebx95QcSVW1J4tTNDDesT9ND1J6cMZUFG/fWz8LWHlW1QT+21ncePGKod+6b95QDkWeRSx5Jn2vZDEw1s2y8IXJn4iXKRURERNqkMx/AOedewksihbfdH7bsgBtbu6/f/tUohymSNJxz/Pq1VfzprXWcdfgA7rv0mPoJqbqzmCaYzCwNL7n0mHPuOWh2rG5T434L/OXG7QdRr4HkUF5dy87iKkb1yyEvK/KvYOMkTmt6IwFkpXmJm+s+M6pNMeXnZvDny4+tr/UUyTHDe3PM8I5NjlGX9GrPxaeuvFQy5peSMOSInHPzzOwZ4CO8OnMf419zOjeOzn5HERERibbO7skkItFREwxx+3Of8syiAi6dPJyfT5/QYDbz7ixmCSZ/pre/Ayucc78Nax/kj+eFhmN1ZwGPm9lv8WqbjAXmO+eCZlbijwWeB1wJ3BeruCW2qmtDHP+L1ymrDvKHS45uVVX9EX2b7lXU2OVTR9AjM40vHtO6UZS//fJRLNtWzMCemZx3xKCWd+igey4+kqcXFnD0sF7tPkYy92DqCvdRzrmfAj+NdxwiIiKSnLpQ6QCRbqe8upb/99hHvL2qkG+eNZZbzxyr/6fDxLIH00nAV4FPzewTv+0HwKWRxur644CfApbj9Qy40Z9BDuAbwCNAFt7scZpBLkn97vXVlPl1kuqKetd59hsn1tdfqvP6t09hQBvGsaalBLjouJYLZtf54rFD+eKxrd68w/rnZnLj6WPatW/IK9+UlD2YRERERMSjnksiyWlPaRXXzlzIpwX7+b8vHMFlU1SWp7GYJZicc+8TeWTMQeN3w/a5E7gzQvtCYGL0opN4uPeNNfzl7XVNrp8wOI/MtIZDx8b0b93QuO4g5N+MJGMPpiQMWUREREREBICt+yv46oPz2Lq/gvuvOI7PThgY75ASUqfMIieyr6ya385efVB7ZlqAypq6mdU0brU5dcm3sf17xDmS9tPzuujQ5ygiIpK8NJxGJLls3F3G5Q/Oo7iyhn9+bQrHj4w8o7kowSSd5IUlB+qyTx7Zh/kb99KvRzq7S6sZPyiPo4f30h/bFgzsmcnMaydz7PBe8Q6lzazLlPkWERER6RgNkRNJHqt2lHDF3+cRDDme+PpUJg7pGe+QEpoSTNIpVu0sqV8enZ/D8L7ZPLOoAIAvHTe0zbO+dVenHpof7xA6RPdTIiIiIh49XBVJbJ8WFPHVh+aRnhLgXzOmMnaAyre0RGOSpFMs3LivfvnLxw+jNhiqf90jIyXSLtKF6P5JREREpCH1ZBJJXAs27uWyv82lR0Yqz9xwopJLraQEk8RccWUNK3cc6MF0zLBebCuqrH99xJBecYhK4kE3UtGhz1FERCR5qeeSSGJ7f81urvz7fPLzMnj6hhMY3jc73iElDSWYJKb+OXcTR97xWoM2M6OsqhaAn14wnvGD8+IRmnQi3UaJiIiIePSgSCRxvbu6kGtnLmBE32yeuv4EBvXMindISUU1mCQmFmzcy/aiSn70n6UABAyW/uwcQv7f04qaIABTR/eNV4gSB7qdEhERERGRRPTu6kK+9uhCxuT34LGvTaF3Tnq8Q0o6SjBJ1GzdX8GgvEwCAePi++c0WJeTnkp2+oFft6oarwZTjwz9CnYL6sIUVUrUiYiIJC8NkRNJPEouRYeGyElUlFTWcNLdb/KdpxdTUllz0PrM9IaFvHMzvcRSdroKfHcn6hEuIiIi3Z2GyIkkFiWXokfdRyQqSiq9mkr//ngrF08aetD6PtkN/yd98KpJvL2qkL49MjolPokvUxcmERERkQbUk0kk/t5dXcjXH13IIUouRYV6MElU1ARD9csbd5cftH7yqD4NXg/tnc0VU0fEPC5JLE6Du0REREQA9WQSibe65NLo/B48ruRSVCjBJFFRXXsgwfTGip2kpRx4IjOybzY//Nzh8QhLEoQe0EWX7kdFRESSl3ouicSfkkuxoQSTREVVeIJp5S7652bWv5557WQy01RrSVB1ahEREen21HNJJL7eW3MguaRhcdGlBJNERXXYEDnwZpSrk5qiX7PuTs/pRESaZmbfMrNlZrbUzJ4ws0wz62Nms81sjf+zd9j2t5vZWjNbZWbnxDN2ERGRZPLemkK+NvNAcqmPkktRpW/+0mGT73yd7zy1uEHboQN61C+nBZReEI+e10WJPkiRLsPMhgC3AJOccxOBFOAS4DbgDefcWOAN/zVmNt5fPwGYBvzZzNRNWCSJaIicSHzUJZdG9ctRcilGlGCSDttVUsWG3WUN2h66+vj6ZfVgEt1IiYg0KxXIMrNUIBvYBkwHZvrrZwIX+svTgSedc1XOuQ3AWmBy54YrIiKSXMKTS49/faqSSzGib/7SIU2NIc/PzahfTk1RckE8KjkgItKQc24r8GtgM7AdKHLOvQYMcM5t97fZDvT3dxkCbAk7RIHfJiJJQjWYRDrX3PV7lFzqJEowSYeEF/cGuP+K4/jVl44kI/VAb/20gH7Nujt1YBIRicyvrTQdGAUMBnLM7IrmdonQFvHbqpnNMLOFZrawsLCw48GKSNIys2l+3ba1ZnZbhPVmZvf665eY2bFt2Pd/zMyZWb9Yn4dIW31aUMTXZi5keJ9sJZc6gb75S4f85e11DV6P6d+DLx8/rEGbejBJHafiQVGhz1GkSzkL2OCcK3TO1QDPAScCO81sEID/c5e/fQEQ/od2KN6QuoM45x5wzk1yzk3Kz8+P2QmISGLz67T9CTgXGA9c6tdzC3cuMNb/NwP4S2v2NbNhwNl4vTBFEsraXaVc9fB8emal8Y/rVHOpMyjBJB3yhzfWNHjdMyvtoG1SVeS729NvgIhIkzYDU80s27yCdWcCK4BZwFX+NlcBz/vLs4BLzCzDzEbhfRmc38kxi0gHxGGE3GRgrXNuvXOuGngSr+dkuOnAo84zF+jlJ7db2vd3wPfQFCSSYLbur+Crf59HwIzHvjaFgT0z4x1St5Aa7wCka+mVfXCCSQWepY5KDoiINOScm2dmzwAfAbXAx8ADQA/gKTO7Di8JdbG//TIzewpY7m9/o3MuGJfgRSRZRKrdNqUV2wxpbl8z+zyw1Tm3WPf7kkh2l1bx1QfnUVpVy79mnMDIfjnxDqnbUIJJoipNM8ZJBLrniC4l6kS6FufcT4GfNmquwuvNFGn7O4E7Yx2XiHQZrand1tQ2EdvNLBv4IfDZFt/cbAbesDuGDx/e0uYiHVJcWcNVD81nW1EF/7xuCuMH58U7pG5F2QBpt8YzYIwbmBunSCRZKC8iIiIi0ulaU7utqW2aaj8Eb3KCxWa20W//yMwGNn5z1YOTzlJZE+Rrjyxk9c4S7r/iOCaN7BPvkLod9WCSdpm/YS+ZaV5+8ptnjeWbZx0a54gksakLk4iIiEicLADG+nXbtgKXAJc12mYWcJOZPYk3BK7IObfdzAoj7eucWwb0r9vZTzJNcs7tjvnZiERQGwxx42MfsWDTXu695BhOO6x/yztJ1CnBJO3y5b/OqV/unxu5YNqvLjqSBRv2dlZIkgQa93oTERERkdhyztWa2U3Aq0AK8JBfz+0Gf/39wEvAecBaoBy4prl943AaIk1yzvGj/yzljZW7+PmFE7ngqMHxDqnbUoJJ2iQUcgfV04k0cxzAlycN48uThkVcJ92LajBFl9J0IiIi0hbOuZfwkkjhbfeHLTvgxtbuG2GbkR2PUqR9/vDGGp5csIWbzxjDV6eOiHc43ZoSTNImJ//qLbbur2jQ1lSCSaQxJUZERERERCRanpy/md+/voaLjhvKt89W2ZZ4U5FvabXaYOig5BIowSQtUwcmEREREY8qBohExxsrdvLD/yzl1EPzueuLR2AaNhF3SjBJqx3z89kR23tlK8EkraQbqqhQLSsRERER6c4+3ryPGx//iAmD8/jz5ceSlqLURiLQfwVp1nefXsx/F3uzmJZU1kbcJk89mKQFepogIiIiIiLRsL6wlOtmLmRAXiYPXX08ORmq/JMolGCSJlXXhnh6UQE3P/Fxs9vl6n9oaSWnLkwiIiLSzel+SKT9dpVUctXD8zFg5jWT6dcjI94hSRhlBqRJz3+ytcVtnrr+BAIB9U6R5uk3REREREREOmJXSSWX/W0eu0uqeWLGVEb2y4l3SNKIEkzSpDW7SgEIGIRCkZ+0TB7VpzNDkiSn0kHRoY9RRERERLqTXSWVXPrAXLbtr+SRa47n6GG94h2SRKAhctKkDbvLAAg5uO/NtQet/9WXjuzskCRJqQSTiIiIiIi0R11yaXuRl1yaMrpvvEOSJsQswWRmw8zsLTNbYWbLzOxWv72Pmc02szX+z95h+9xuZmvNbJWZnRPWfpyZfeqvu9dUMTjmnHO8s7qw/vXvXl990DZfPn5YZ4YkXYB6MImIiEh3p/shkdbbVXwgufTw1UouJbpY9mCqBb7jnDscmArcaGbjgduAN5xzY4E3/Nf46y4BJgDTgD+bWYp/rL8AM4Cx/r9pMYxbgNKqWqprQ02uV4pP2sJUhUlERERERNpgV3Ell/6trufSZCWXkkDMajA557YD2/3lEjNbAQwBpgOn+ZvNBN4Gvu+3P+mcqwI2mNlaYLKZbQTynHNzAMzsUeBC4OVYxS6wv7wGgFMPzW/Qk2nZz85h055y+uWmxys0SWJ6YBcdevIpIiIiIl3ZruJKLvnbXHb4ySXV/k0OnVKDycxGAscA84ABfvKpLgnV399sCLAlbLcCv22Iv9y4XWKoLsF0xdQRvPLNk+vbczJSGT84j/65mfEKTZKQeryJiIiIiEhrKLmUvGKeYDKzHsCzwDedc8XNbRqhzTXTHum9ZpjZQjNbWFhYGGkTaaV95dUA9MpO47ABuXGORroKp643IiIi0s3pbkikaeHJpZnXKrmUbGKaYDKzNLzk0mPOuef85p1mNshfPwjY5bcXAOFVo4cC2/z2oRHaD+Kce8A5N8k5Nyk/Pz96J9KN/PWddby3ppCVO7xcYO/sNFRTXSSxON2aioiIiEgXs72ogq88MJedfnLp+JFKLiWbmNVg8md6+zuwwjn327BVs4CrgLv9n8+HtT9uZr8FBuMV857vnAuaWYmZTcUbYnclcF+s4u6ulm4t4pYnPmb97jIyUgNU+QW+e2ap1pKIiIiIiIjEztb9FVz6wFz2llXz6HWTOW6EkkvJKGYJJuAk4KvAp2b2id/2A7zE0lNmdh2wGbgYwDm3zMyeApbjzUB3o3Mu6O/3DeARIAuvuLcKfLeRc471u8vonZ3OWyt34YCLjvM6hlXWBDn/vvfrt60Kmz2uZ1ZaZ4cqXZj63YiIiEh3p5IBIg1t2VvOpX+bS1FFDf+4bjLHDO8d75CknWI5i9z7RK6fBHBmE/vcCdwZoX0hMDF60XU/Ty3cwvef/bRBW//cDK58aD5HDe3Z5H7pqZ1SB166OI2yFBERERGRxjbv8ZJLJZU1PPa1KRw5tFe8Q5IOUPagm3h56Y6D2v767joAFhcUdXY40k11hQd2ZtbLzJ4xs5VmtsLMTuj0ILrA5ygiIiIi3dvG3WV85YE5lFXX8vjXpyq51AXEcoicJIDdpVV888lPqA6GDlr3wdo9ze47vE92/fIFRw2mf25G1OOT7sGa7MyYlP4AvOKcu8jM0oHslnYQEREREZED1hWWctnf5lITdDz+tamMH5wX75AkCpRg6uL+/dFW3l+7u137/uC8w+uX77v0mGiFJN1acne9MbM84BTgagDnXDVQHc+YREREJLkk992QSMet3VXCpX+bh3OOJ74+lcMG5sY7JIkSDZHrgkqravnta6t4e9Uu7nxpRav3m/2tU7h8yvD61xlp+vWQ6OhCNZhGA4XAw2b2sZk9aGY5nR2EbkxFREREJBmt3FHMV/46F0DJpS5IGYQu6JEPNnDvm2u5+uEFbdpv7IBcjg2r2J+hAt8SZV2gBlMqcCzwF+fcMUAZcFvjjcxshpktNLOFhYWFnR2jiIiIiEjCWb6tmEsfmEtaSoB/zZjK2AFKLnU1yiB0QeXVwXbvmx9WZ0kJJomWLtSDqQAocM7N818/g5dwasA594BzbpJzblJ+fn6nBigiIiLJoTOfu5nZNDNbZWZrzSzSwzEzs3v99UvM7NiW9jWzn/vbfmJmr5nZ4M46H0k+y7YVcdmDc8lKS+Ff109ldH6PeIckMaAMQheUEmj4bb4tiaI+Oen1yxOH9IxaTCKQ/EO7nHM7gC1mdpjfdCawPI4hiYiISJLp7B7dZpYC/Ak4FxgPXGpm4xttdi4w1v83A/hLK/a9xzl3pHPuaOAF4CcxPhVJUku3FnH5g/PISU/lyRknMKJvp1eYkE6iIt9dUHh66aVbTmZ432wm/vRVwEsg7S1ruibx+EF53HT6GL5y/DAyUlNiHKl0F11sFrmbgcf8GeTWA9d0dgBdYKihiIhIt9eJd0eTgbXOufUAZvYkMJ2GD8mmA4865xww18x6mdkgYGRT+zrnisP2zyH5nyVKDNQll3pkpPLkjKkM66MJmLsyJZiSWCjkqKgJkpPR8D9jVTBUv1w33eNPLxjPhME9mTyqD8u3FXPeve812Oft/zkNgEDA+J9zDkMkFrpCYsQ59wkwKd5xiIiISHLrxNuiIcCWsNcFwJRWbDOkpX3N7E7gSqAIOD16IUtXsHjLfr7693nkZqYpudRNaIhcErvntVVM+OmrVNY0rLlUVRM6aNtrThrF5FF9AC/p1GgUHSP7qZuixE4XqsEkIiIi0kGd/sQt0p1Y4yCa2qbZfZ1zP3TODQMeA26K+Oaa/KRb+nDtbq54cB49s9P41/VKLnUXSjAlsec/3grAFQ/O41v/+oTVO0twzlHhF/m+5cyxTe6r/8ElHpx6TkeFPkcREZHk14nP3wqAYWGvhwLbWrlNa/YFeBz4UqQ31+Qn3c+ziwq46uH5DOqVyb9mnMDQ3vru2V1oiFwSG9kvh21FlSzctI+Fm/bx74+3MuOU0fxr4RbyczP49tmHNrnvI9dM5vF5mzhpTD/69chocjuRaFAHptgwdQ0TERGRli0AxprZKGArcAlwWaNtZgE3+TWWpgBFzrntZlbY1L5mNtY5t8bf//PAytifiiQy5xx/fnsd97y6ihMP6ctfrjiOnllp8Q5LOpESTElq9vKdfLhuz0HtD7y7HoCSyppm9x/VL4cffq7x5BEisdUVajAlEqcPVEREJGl11l9x51ytmd0EvAqkAA8555aZ2Q3++vuBl4DzgLVAOf4kJk3t6x/6bn9m3RCwCbihk05JEpBzjrteXskD767nwqMH86uLjiK9DbOZS9egBFMS2l5UwdcfXdjsNn2y0zspGpGWqaONiIiIiCcez4eccy/hJZHC2+4PW3bAja3d12+POCROup/tRRX84fU1PLlgC1eeMII7LphAoHHRX+kWlGBKQm+u3FW/nJWWQkVNkNMPy+etVQeK5p1/1OB4hCbSLPW3iQ51XBIREUl++votXcGT8zdz23OfAnD1iSP56QXjVcahG1OCKQmt3lFSv9w7O40Vt08jFHKM/oH3YGHq6D5875zD4hWeSAT6IyMiIiISTs+LJJk55/j1a6v401vrSE8JcP2po/nWWYcqudTNKcGUJFbvLOGzv3uXu794BAs37SMlYARDjsraEECDLoinHJpPaorGu0riUc0gEREREZHktq+smv95ejFvrNzFpZOH8fPpE/X9UwAlmJLGZ3/3LkB998NpEwbyyrIdVNYED9q2R4b+s0pi0YOM6FKaTkREJHnp77gks0Wb9nLz4x+zu7San31+AleeMEK9lqSe0oxJYM3OkoPaLp0yHIBJI/vUt733vdO58fRDuHTy8E6LTUTiR3/MRboOM+tlZs+Y2UozW2FmJ5hZHzObbWZr/J+9w7a/3czWmtkqMzsnnrGLSPvor7gkk1DI8Ze31/Hlv84lNSXAs984katOHKn7UWlAXV0SWEV1kJuf+JjdpVUHrRvdL4cXb/kMI/rm1LcN65PNd88Z15khirSK/uzEhoYcinQpfwBecc5dZGbpQDbwA+AN59zdZnYbcBvwfTMbD1wCTAAGA6+b2aHOuYO7NYtIwtJfcUkW+8qq+dZTn/D2qkI+d8Qg7vrSEeRlpsU7LElASjAlsNU7S3h9xc6D2r8/bRzD+mTHISKRjlE+RETkYGaWB5wCXA3gnKsGqs1sOnCav9lM4G3g+8B04EnnXBWwwczWApOBOZ0auIi0i+6HJJnsLK7kigfnsWlPOT+/cCJXTBmuXkvSJCWYEtj2osr65dH5OVRUB9leVMllGgInSUZ/hKJLPZdEupzRQCHwsJkdBSwCbgUGOOe2AzjntptZf3/7IcDcsP0L/DYRSSK6O5JEt3xbMdc+soDiyhpmXjuZEw7pG++QJMEpwZTACsOGxuWkp3LPRUexr6yantnqjijJyakzuIhIJKnAscDNzrl5ZvYHvOFwTYn0vfSgC6yZzQBmAAwfrodTIolGd0WSyD5Yu5vr/7GIHhmpPHPDiYwfnBfvkCQJqMh3AqusPlBKITs9heNG9Oas8QPiGJFI++gJnYhIswqAAufcPP/1M3gJp51mNgjA/7krbPthYfsPBbY1Pqhz7gHn3CTn3KT8/PyYBS8iIl3L859s5eqH5zO4VybP/T8ll6T1lGBKYBU1BxJMORnqbCbJTyO7REQO5pzbAWwxs8P8pjOB5cAs4Cq/7SrgeX95FnCJmWWY2ShgLDC/E0MWkQ5Qj25JZA++t55bn/yEY4f35ukbTmRwr6x4hyRJRFmLBFYZlmDqlaVhcZK8VIIpupSoE+mSbgYe82eQWw9cg/cg8Ckzuw7YDFwM4JxbZmZP4SWhaoEbNYOcSPLR7ZEkEucc97y6ij+/vY5zJw7kd185msy0lHiHJUlGCaYEVVEd5M9vr6t/PaBnZhyjEYkOJUZERCJzzn0CTIqw6swmtr8TuDOWMYlIbOm2SBJFTTDEHbOW8di8zVw6eTi/uHAiKQGlQKXtlGBKUI/N29TgtbomSjIzPaMTEREREUk4+8urufHxj/hg7R6uP3U0t00bpxmgpd2UYEpQBfsq6pfvvfQYzj5cxb0l+elJnYiIiHR36tEtiWLtrlK+NnMB2/ZXcs9FR3LxpGEt7yTSDCWYEpBzjp3FlQCcemg+nz9qcJwjEukYPQSJDT1dEhEREZH2eHvVLm5+4mMyUgM8/vUpTBrZJ94hSRfQ6gSTmWUBw51zq2IYT7e2vrCUXSVV3PjYR+wpq+a4Eb2Zee3keIclEjVOj+yiSp+niIiIiLRFTTDEb15bzV/fXce4gXn87crjGNo7O95hSRfRqgSTmV0A/BpIB0aZ2dHA/zrnPh/D2LqdM37zToPXmWmBOEUiIiIiIiKxoOdDEi8LN+7lh/9eyqqdJVw6eTg/OX88WemaKU6ip7U9mO4AJgNvgzfTiZmNjE1IUicloASTdC26n4oO3ZiKiIgkPw10l86yq7iSX726imcWFTC4ZyZ/u3ISZ49XjV+JvtYmmGqdc0Wq99G53l1dGO8QRKIiES8dZpYDVDjnQmZ2KDAOeNk5VxPn0EQkwen6ISLREOl5UVlZGVlZWQQCAVavXs3KlSs599xzSUtL6/T4JPk553h6UQH/99IKyqpquf7U0dxyxlhyMlSKWWKjtV1klprZZUCKmY01s/uAD5vbwcweMrNdZrY0rO0OM9tqZp/4/84LW3e7ma01s1Vmdk5Y+3Fm9qm/7l5TlkskeSVWz5t3gUwzGwK8AVwDPBLXiEQkWej6ISIxccopp1BZWcnWrVs588wzefjhh7n66qvjHZYkobW7Srjo/jl875kljMnvwSvfPIXbzz1cySWJqdYmmG4GJgBVwONAEfDNFvZ5BJgWof13zrmj/X8vAZjZeOAS/z2mAX82s7rBoH8BZgBj/X+RjtklpQSUS5OuIUHzwuacKwe+CNznnPsCMD7OMbWKS7BMnUg3lLTXDxGJv+b+jjvnyM7O5rnnnuPmm2/m3//+N8uXL+/E6CTZFVfW8IsXljPt9++xrrCUu794BE9dfwKH5PeId2jSDbSYYPITPbOccz90zh3v//uRc66yuf2cc+8Ce1sZx3TgSedclXNuA7AWmGxmg4A859wc502X9ChwYSuPKSIJJsESI2ZmJwCXAy/6bUn1SCdBE3ci3UHSXz9EJDE555gzZw6PPfYYn/vc5wCora3t8HHNbJo/UmStmd0WYb35o0XWmtkSMzu2pX3N7B4zW+lv/28z69XhQKXdiitreHzeZs79/Xv8/YMNXDxpKK9/+1QumTycgDouSCdp8WbIORc0s3Iz6+mcK4rCe95kZlcCC4HvOOf2AUOAuWHbFPhtNf5y4/ZuIRhKqC/jIu2WoH/SvgncDvzbObfMzEYDb8U3pLZxqvYtEi/fJMmvHyKSmH7/+99z11138YUvfIEJEyawfv16Tj/99A4d0+8w8CfgbLzvUwvMbJZzLrxr1LkcGDEyBW8UyZQW9p0N3O6cqzWzX+JdF7/foWClTQpLqli+vZhnFhXwxoqdlFcHGZ2fw7PfOJFjh/eOd3jSDbX2aVsl8KmZzQbK6hqdc7e08f3+AvwcrxLLz4HfANcS+funa6Y9IjObgTecjuHDh7cxtMTTJyc93iGIdFnOuXeAdwDMLADsbsc1TUS6IV0/RCRWTj31VE499VQAQqEQ/fr149577+3oYScDa51z6wHM7Em8ESThCabpwKP+qJG5ZtbLH00ysql9nXOvhe0/F7ioo4FK84ora3jkg43MXr6TQMBYvGU/AL2y05h+9GAunTycI4b0VC93iZvW1mB6EfgxXlHLRWH/2sQ5t9M5F3TOhYC/4V3swMuGDwvbdCiwzW8fGqG9qeM/4Jyb5JyblJ+f39bwEs6z3zgx3iGIRFUidbgxs8fNLM+fDWo5sMrMvhvvuFojkT5Hke4oma8fIhJ/zf0dv+yyyyguLqasrIzx48dz2GGHcc8993T0LYcAW8JeRxoV0tQ2rdkXvE4DL0d6czObYWYLzWxhYaFmyW6PmmCI/y7exjm/e5ffzl5NWoqRYvCdsw/lkWuOZ+7tZ3LXF4/kyKG9lFySuGpVDybn3EwzSwcO9ZtWtWcqXjMb5Jzb7r/8AlA3w9ws4HEz+y0wGK9r5nx/eF6JmU0F5gFXAve19X0TXSjkeGZRQYO2/rkZjOqXE6eIRKIrQf/OjXfOFZvZ5cBLeF26FwEdvovrLLqBEImbpL9+iEhiWr58OXl5eTz22GOcd955/PKXv+S4447ju9/tUA67NaNC2j2ixMx+CNQCj0V6c+fcA8ADAJMmTdJjsjZYu6uU11fs5JEPNrKjuJKx/XvwzA0nMGlkn3iHJhJRqxJMZnYaMBPYiHeRGWZmV/mFvJva5wngNKCfmRUAPwVOM7Oj8S5KG4HrAfz6BU/hPQWsBW50zgX9Q30Db0a6LLyseMTMeDKbtXgb33t2SYM2lV+SrijBfq3TzCwNb+KAPzrnaswswUJsnmowicRN0l8/RCQx1dTUUFNTw3/+8x9uuukm0tLSovFAqanRIq3ZJr25fc3sKuB84EynG5OoqKwJ8tbKXcycs5G56705syaN6M3PL5zImeP6q2C3JLTW1mD6DfBZ59wqADM7FHgCOK6pHZxzl0Zo/nsz298J3BmhfSEwsZVxJqXiyoM7g33x2G5Ty1y6AUvMMt9/xUt0LwbeNbMRQHFcI2ol3b2JxF3SXj9EJLFdf/31jBw5kqOOOopTTjmFTZs2kZeX19HDLgDGmtkoYCtwCXBZo21m4U3G9CReke8i59x2Mytsal8zm4bXg/NU51x5R4PsrpxzfLR5H89/so3FW/azZlcp5dVBhvTK4vZzx/G5IwcxtHd2vMMUaZXWJpjS6pJLAM651f6TO+mgbfsreGdVw7HIS392DtlpKXGKSCR2Eum5lnPuXiC8auYmM+vYNC2dTEPkROKjK1w/RCQx3XLLLdxyy4E5A0aMGMFbb3Vskkp/lrebgFeBFOAhfwTJDf76+/GG+54HrAXKgWua29c/9B+BDGC2f08y1zl3Q4eC7SaccyzfXsxf31nP/A172VFcSWZagKOH9eLLk4Zx+rj+nHRIX1JTWlsyWSQxtDbBtNDM/g78w399Oe0o8i0HO+d371JSVdugrUdGa/+ziCSHRMyDmFlPvKG7p/hN7wD/CxTFLag2Uk90kfjoCtcPEUlMRUVF/OxnP+Pdd71KJKeeeio/+clP6NmzZ4eO65x7CS+JFN52f9iyA25s7b5++5gOBdXNfLB2N498uJFVO0rYW1ZNaVUtvbLTOHlsPpNH9eHCoweTm6k+HJLcWpvJ+AbeBecWvBpM7wJ/jlVQ3Unj5NLQ3llxikQk9lxiDe56CG+igS/7r78KPAx8MW4RiUiy0PVDRGLi2muvZeLEiTz11FMA/OMf/+Caa67hueeei3Nk0h7rC0tZuaOEx+Zt4oO1exiQl8HxI/vQr0cGI/tmM/3oIfTOSY93mCJR09oEUyrwB+fcbwHMLAWvO6R0QGmj5BLAy7eeHIdIRGIrATswARzinPtS2Oufmdkn8QqmLdRzSSTukvb6ISLx19yf8XXr1vHss8/Wv/7pT3/K0UcfHfugJKrWF5bys/8u553VXimUPjnp/OT88Vw+dTgZqSqFIl1XaxNMbwBnAaX+6yzgNeDEWATVXewrqz6oTd0ipStLsLxIhZl9xjn3PoCZnQRUxDmmNlENJpG4Sfrrh4gkpqysLN5//30+85nPAPDBBx+QlaURDsmiqjbInS+u4PF5m3HALWeM4bRx/TlsQC45KoMi3UBrf8sznXN1ySWcc6VmplL2HRRp9jiRLikx8yA3AI/6tVQA9gFXxTGeNlNPJpG4Sfrrh4gkpvvvv58rr7ySoiKvpFvv3r2ZOXNmnKOS1iiprGHGo4uYs34PX540lG+dfSiDeio5KN1LaxNMZWZ2rHPuIwAzm4Se1HVYccXBQ+REurJESoc45xYDR5lZnv+62My+CSyJa2CtkEifo0h3lMzXDxFJbEcddRSLFy+muLgYgLy8PH7/+99z5JFHxjkyacrHm/dx18srWb2zhP3lNfzyS0fwleOHxzsskbho7byH3wSeNrP3zOxd4EngpphF1U0UVTTswfS5IwfFKRKR2LIE7cIE3hdD51yx//LbcQ2mjTRETiS+kvn6ISLx05pJT/Ly8sjLywPgt7/9baxDknaoCYZ48L31fOWvc1m5vZijh/Xi0WsnK7kk3VqzPZjM7Hhgi3NugZmNA67HmyHlFWBDJ8TXpS3b1nA24/+78Ig4RSLSSRJ/SFdSZWw0RE4koSTV9UNEkof+3ieepVuLuOWJj1m/u4wzx/Xn1xcfpdngRGh5iNxf8Yp7A5wA/AC4GTgaeAC4KGaRdWG7SipJCwS47821DdpTU3RvKl1TEnW00R2ciLSXrh8iEhPqsZxYdpdWcf0/FhFyjgevnMSZh/fXfyMRX0sJphTn3F5/+SvAA865Z4FnNR1v+02+842I7WkprR2xKJKcEuHbl5mVEDkUw5shM+HpQaZIfHSF64eIxF+kv+O5ubkRkxTOOSoqVPo2UewqruTCP33A3vJq/jXjBI4a1iveIYkklBYTTGaW6pyrBc4EZrRhX4mgNhhqcl16qhJM0jUl0jMd51xuR49hZinAQmCrc+78jkfV7jji9dYi3VI0rh8iIpGUlJTEOwRpQSjk+M7Ti9lbXs0TX5+q5JJIBC1lNJ4A3jGz5/FmjXsPwMzGAEXN7SiRldcEG7z+0ecOj1MkIp2vC/W8uRVYEe8gVJNBREREpHP8/f0NvLdmNz85fwLHDO8d73BEElKzvZCcc3ea2RvAIOA1d+DbTACvFpO0UUX1gQTTQ1dP4oxxA5h+9BDyczPiGJVIbHWlnjZmNhT4HHAnmjVKREREpMtbu6uUX726kmkTBnLp5GHxDkckYbU4zM05NzdC2+rYhNP1lVXV1i+fMW4AgJJL0m10kR43vwe+B8RxqEyX+BxFRES6Jf0VTz6/eW0V6SkB7vzCxC714FQk2lT0J8acc7y5cmd97aXy6mALe4h0PV3lz7CZnQ/scs4tamG7GWa20MwWFhYWxjKemB1bRERERGBJwX5eXrqDr508mr491DFApDlKMMXY7OU7ufaRhfz9/Q1Awx5MIt1NF3hidxLweTPbCDwJnGFm/2y8kXPuAefcJOfcpPz8/JgF00V6hImIiIgkrHteXUXv7DS+dvKoeIcikvCUYIqxjXvKANhVUoVzjtv//WmcIxLpfF2lo41z7nbn3FDn3EjgEuBN59wVnR9HZ7+jiIiISPfz4brdvLdmNzeePobczLR4hyOS8JRgirHSKm9IXE5GKjc+/hHrC72E0xVTh8czLJG4UGIkujRETkREJPmoB3JyKKms4X//u5xBPTO5YuqIeIcjkhRaLPItHVPuD4m79401Ddr/57OHxSMckbiwLlOF6QDn3NvA23GOIZ5vLyIiItIlOef4xQsrWL2zhIeuPp7MtJR4hySSFNSDKcZqQ5G/AKqLpXRHSoeIiIiISKL757zN/GvhFr528mhOO6x/vMMRSRpKMMVYbSgUsT0l0PV6dIg0Sb/uUaVEnYiISPLS3/HEVhMMcf/b6zh2eC9uP3dcvMMRSSpKMMVQWVUtq3eUHtR+my5U0k1pSFd0qQaTiIiISHQ9uWALW/dXcNMZY3SvJdJGSjDF0HUzFzB/494GbekpAW449ZA4RSQSH/rbHBtK2Il0HWaWYmYfm9kL/us+ZjbbzNb4P3uHbXu7ma01s1Vmdk78ohaRZGFm0/xrxlozuy3CejOze/31S8zs2Jb2NbOLzWyZmYXMbFJnnUsslVfX8rvZq5k8qg+na2icSJspwRRDc9fvPajtkWuOj0MkItKVKK8k0iXdCqwIe30b8IZzbizwhv8aMxsPXAJMAKYBfzYzVZ8VkSb514g/AecC44FL/WtJuHOBsf6/GcBfWrHvUuCLwLuxPofO8sT8Lewtq+Z75xym3ksi7aAEUyfLztDEfdL9BPw/0EqMRJdufES6BjMbCnwOeDCseTow01+eCVwY1v6kc67KObcBWAtM7qRQRSQK4nA/NBlY65xb75yrBp7Eu5aEmw486jxzgV5mNqi5fZ1zK5xzqzrvNGKrvLqW+99Zx5RRfZg0sk+8wxFJSkowdbKcdD1klO6nrqZ9SBmmqNIQOZEu4/fA94DwmUEGOOe2A/g/68ZqDAG2hG1X4LeJiDSlNdeNprbpNtecRz7cSGFJFd+bpnq5Iu2lBFOMNPXFb2DPzE6ORCT+6nowhZQPERFpwMzOB3Y55xa1dpcIbRGvrmY2w8wWmtnCwsLCdscoIkmvNdeNprZp9TWnyTdPgmuRc45nFhUweVQfjhvRu+UdRCQiJZhiZO2uhrPHZaV5PZdyM9PiEY5IXJl6MEWV0wTHIl3JScDnzWwj3tCTM8zsn8BOf3gK/s9d/vYFwLCw/YcC2yId2Dn3gHNuknNuUn5+fqziF5F26sTbotZcN5raptXXnKYkw7Vo7vq9rC8s48uThrW8sYg0SQmmGNhVUsnZvztQ625Uvxxe+9YpPH3DCXGMSiR+DtRgUmIkmlSDSST5Oedud84Ndc6NxCve/aZz7gpgFnCVv9lVwPP+8izgEjPLMLNReAV553dy2CLSIZ1+P7QAGGtmo8wsHe9aM6vRNrOAK/3Z5KYCRf7w3Nbsm/SeWriF3MxUPnfEoHiHIpLUVHE6Bgr2VdQv//4rR3PCIX0ZkJfJsD7ZcYxKJH40RC42lLAT6dLuBp4ys+uAzcDFAM65ZWb2FLAcqAVudM4F4xemiLRXZz0ncs7VmtlNwKtACvCQfy25wV9/P/AScB7exAHlwDXN7evFb18A7gPygRfN7BPn3Dmdc1bRs7+8mpc+3c7Fk4aSpXq5Ih2iBFOUVdYEeXf1gbHFFx7TJWvgibSJinxHlz5Gka7JOfc28La/vAc4s4nt7gTu7LTARCTpOedewksihbfdH7bsgBtbu6/f/m/g39GNtPM9+9FWqmpDXDZ5RLxDEUl6SjBF2XeeXsyLS7bHOwyRhGLqwRQTGiInIiKSfPSgKHE453h83iaOGd6L8YPz4h2OSNJTDaYoCYYc/128jfdWJ+bMCCLxFjAN6RIRERGRxDFvw17WFZZx+RT1XhKJhpglmMzsITPbZWZLw9r6mNlsM1vj/+wdtu52M1trZqvM7Jyw9uPM7FN/3b2WoI/sH/5gAzc/8THFlbX1bQt+eFYcIxJJLAEzDZGLMiXsoi8UcvpcRUREuolnFhWQm5HK+UequLdINMSyB9MjwLRGbbcBbzjnxgJv+K8xs/F4MxJM8Pf5s5nVVVj7CzADb5aUsRGOmRDWFZYe1JafmxGHSEQSU8BMXcKjRJ9j7Iz+wUtcN3NhvMMQEZFuQH/P46uyJsgrS3cwbeJAMtNU3FskGmKWYHLOvQvsbdQ8HZjpL88ELgxrf9I5V+Wc24A3e8FkMxsE5Dnn5viF5x4N2yehfLq1KN4hiCQ2Uw2maEvQDp1J782Vu+IdgoiIdGG6HUoMry7bQWlVLdOP1qRMItHS2TWYBjjntgP4P/v77UOALWHbFfhtQ/zlxu0Jp7xKMwSLNEc1mKJPn6eIiEjy0nOi+Hps3mZG9s3mxEP6xjsUkS4jUYp8R7q8umbaIx/EbIaZLTSzhYWFnVtsu7y6YYIpNaC/GCLhVIMpepyefYqIiIi0246iSuZv2MtFxw0loO9tIlHT2Qmmnf6wN/yfdeMQCoBhYdsNBbb57UMjtEfknHvAOTfJOTcpPz8/qoG3pKyqlpPGHMh+nzimX6e+v0ii8xJM8Y6ia9EQORERkeSl527x89Kn2wE47wgV9xaJps5OMM0CrvKXrwKeD2u/xMwyzGwUXjHv+f4wuhIzm+rPHndl2D4JwzlHWXUtxwzrzapfTOPha47nr1ccF++wRBKKGerBJCIiIt2ebofi78VPtzNuYC6j83vEOxSRLiVmCSYzewKYAxxmZgVmdh1wN3C2ma0BzvZf45xbBjwFLAdeAW50ztWNOfsG8CBe4e91wMuxirm9qmpDhBxkZ6SQkZrC6Yf1JytdMxGIhNMsctGnGkwiIiLJSx2R42PtrhIWbdrHhcckZGlfkaSWGqsDO+cubWLVmU1sfydwZ4T2hcDEKIYWdaVVtQDkpMfs4xRJegH1YIoafYwiIiLJT3/P4+OxeZtJSzEuOm5oyxuLSJskSpHvpLW+sJQZjy4EIFu9lkSapCLf0acaTCIiIslHPZDjp7ImyLOLCjhnwkD69ciIdzgiXY663LTTlr3l7C6t4ttPLWbD7jIAemTo4xRpiqnId9TpBlVERCR56TlR55u9fCfFlbVcOnl4vEMR6ZKUEWmHzXvKOeWetw5qz1aCSaRJAVNCRERERETiZ9bibQzIy2Dq6L4tbywibaYhcu0QKbkEkKMhciJNCpgRCsU7ChEREZHEoOdunauovIa3V+3igiMHkxJQ9zGRWFCCKYp6ZKoHk0hTVOQ7+lSDSUREJPnobig+Xl66nZqgY/rRmj1OJFaUYIqiYb2z4x2CSMJSDabo05BDERGR5KXnRJ3r5aU7GNE3m4lD8uIdikiXpQRTlKSnBshRDSaRJgUCSohEiz5GERGR5Ke/552nuLKGD9ft5pwJA9UDXCSGlGBqh3EDcxu8zkwLsPoX58YpGpHkEDBTl/Ao0w2SiIiISMveWrmLmqDjnAkD4h2KSJemBFMb/eH1NazcUdKg7X+nT4xTNCLJI2CmGkwiIiLS7el2qPO9tmwn+bkZHDOsd7xDEenSlGBqo9+9vrrB60uOH8bFxw2NUzQiycMM1WCKMg05FBERSV7qiNw5KmuCvL1qF2ePH0BAs8eJxJQSTG1QUR2sX87PzQDggqMGa5iKSCuoB1P0OA02FBERSXq6LeocH6zdTVl1kM+O1/A4kVhTgqkN1hWW1i+P6pvDyp9P46Qx/eIYkUjyCJh63ESbktsiIiLJJx4PisxsmpmtMrO1ZnZbhPVmZvf665eY2bEt7Wtmfcxstpmt8X8m5PizV5ftIDcjlRMP0fc2kVhTgqkNqoOh+uVjR/QmMy0ljtGIJBfDCIVa3k5aTwk7ERGR5NVZz4nMLAX4E3AuMB641MzGN9rsXGCs/28G8JdW7Hsb8IZzbizwhv86oRRX1vDK0h2ccXh/0lP11Vck1vR/WRuUVdUC8JuLj+I7nz00ztGIJBevBpMSItGgj1FERCT5deLf88nAWufceudcNfAkML3RNtOBR51nLtDLzAa1sO90YKa/PBO4MMbn0WZPLdhCcWUt131mVLxDEekWlGBqg7oE0+GD8khL0Ucn0hZeDaZ4R9G1aIiciIiItMIQYEvY6wK/rTXbNLfvAOfcdgD/Z/9Ib25mM8xsoZktLCwsbPdJtFV5dS33v7OeqaP7cOTQXp32viLdmbIkbfDasp0A5GRoaJxIWwUCGtIlIiIiEo8STK2IoqltWrNvs5xzDzjnJjnnJuXn57dl1w55d3Uhu0uruPmMsZ32niLdnRJMbfDcx1sByM1Mi3MkIslHs8hFnxJ2IiIiyasTOyIXAMPCXg8FtrVym+b23ekPo8P/uSuKMXfYh+v2kJ2ewvEj+8Q7FJFuQwmmVgqGje3plaUEk0hbmYbIRY0+RhERkeTXic+JFgBjzWyUmaUDlwCzGm0zC7jSn01uKlDkD3trbt9ZwFX+8lXA87E+kbb4YO1ujh/ZR8W9RTpRarwDSBZl1bX1y4GA6p6ItFVARb6jTjWYREREpCXOuVozuwl4FUgBHnLOLTOzG/z19wMvAecBa4Fy4Jrm9vUPfTfwlJldB2wGLu7E02rWzuJK1hWW8ZXjh7W8sYhEjRJMrTB/w172lFbFOwyRpBYw0+xnUaYhciIiIsknHn+9nXMv4SWRwtvuD1t2wI2t3ddv3wOcGd1Io2POuj0AnHhIvzhHItK9KMHUCl/+65z65T9ffmwcIxFJXurBFD1KLImIiIg07YO1u+mZlcb4QXnxDkWkW9GA1DYa2jsr3iGIJCVTke+o0xA5ERERkYacc3y4bg8njO6r0iYinUwJpjZITwlw6IDceIchkpS8HkzxjqJjzGyYmb1lZivMbJmZ3RrvmERERCS56HlbbG3eW87W/RWcNKZvvEMR6XY0RK4F4UNRhvbJIjMtJY7RiCSvgBmhZM8wQS3wHefcR2aWCywys9nOueXxCEZD5URERJKXOiLHxod+/aUTVH9JpNOpB1MLbnri4/rlq04YGb9ARJJcoAsMkXPObXfOfeQvlwArgCGdHkdnv6GIiIhEXZLfFiWsD9buZkBeBofk58Q7FJFuRwmmFry4ZHv9cjD5e1+IxI11sSLfZjYSOAaYF8cY4vXWIiIiIgknFPLqL500pp/uk0TiQEPkWmHikDyOHd6biycNjXcoIknL68EU7yiiw8x6AM8C33TOFUdYPwOYATB8+PBOjk7aS0MORUSkMzj1RY6ZFTuK2VtWzUkaHicSF+rB1IyK6iAA5x0xiP+dPpHczLQ4RySSvALWNb7Am1kaXnLpMefcc5G2cc494Jyb5JyblJ+fH/UY6j7GrvB5JhJ9nCIiIsntg7W7AThpjBJMIvGgBFMz3lq1C4BRfTV+V6SjukIPJvP6Wv8dWOGc+22845HoSvJfT0liTc1QaWZ9zGy2ma3xf/YO2+d2M1trZqvM7Jz4RS8ikjg+WLuHMf17MLBnZrxDEemWlGBqxpqdpQCcPq5/nCMRSX7WBYp8AycBXwXOMLNP/H/nxSsY1RaILvUIkziqm6HycGAqcKOZjQduA95wzo0F3vBf46+7BJgATAP+bGaa5lZEurWaYIgFG/dy4iF94x2KSLelGkzN2LKvnP65GWSm6Z5NpKMCRtL3YHLOvQ8kTFZHCRGRrsE5tx3Y7i+XmFndDJXTgdP8zWYCbwPf99ufdM5VARvMbC0wGZjTuZGLSHvoz3dsLNtWTHl1kMmj+sQ7FJFuSz2YmrFlbznD+mTHOwyRLiFgpoRI1OhzjAV9qpIIGs1QOcBPPtUloeq6VA8BtoTtVuC3iYh0W/M37AFg8kglmETiRQmmZhTsq2BY76x4hyHSJZjRFYbIJRQNkYsu/XpKvLU0Q2X4phHaDvoNNrMZZrbQzBYWFhZGK0wRkYQ0f8M+RvbNpn+e6i+JxIsSTE2oCYbYXlShHkwiUdIVinx3ljN/8zaTfjE73mF0O5o2WuKpiRkqd5rZIH/9IGCX314ADAvbfSiwrfExYz2jpYi0j/7aRF8o5Fi4aS/Hq/eSSFzFJcFkZhvN7FO/QO5Cvy2hZkrZvr+SkIOh6sEkEhXqwdR66wrL2F1a3eJ2GnIo0jU0M0PlLOAqf/kq4Pmw9kvMLMPMRgFjgfmdFa+ISKJZs6uU/eU1qr8kEmfx7MF0unPuaOfcJP91Qs2Usq/c+3LXNycj1m8l0i14NZjiHUXXoM8xNvS5Shw1NUPl3cDZZrYGONt/jXNuGfAUsBx4BbjROReMT+giIvE3f+NeACWYROIskWaRS6iZUkoqawHIy0qL5duIdBsB9WCKOtVgEukaWpih8swm9rkTuDNmQYmIJJEFG/bSPzeD4SpvIhJX8erB5IDXzGyRmc3w2xJqppTFBfsByMtKpBycSPLyajApwSSJS7+eIiLSGTTEPbqcc8xZv4cpo/vq4ZtInMUre3KSc26bmfUHZpvZyma2bdVMKeDNlgLMABg+fHiHArzn1VUA5GWqB5NINJgZoVC8o+ga2nNb6pzzZsbUk70mqci3iIhI8llXWEZhSRUnHtI33qGIdHtx6cHknNvm/9wF/BtvyFuHZkrxjxeV2VKqaw98C+6Tk97u44jIAQE9UIqrR+ds4uRfvcWnBUXxDkVEREQkauas2w2gBJNIAuj0BJOZ5ZhZbt0y8FlgKQk0U8r63aX1y5lpMa8nLtItaIhcfNUVv9y4pyzOkSQu/XqKiIgkn9krdjG8T7bqL4kkgHj0YBoAvG9mi/ESRS86514hgWZKufbhBQBcMbVjw+xE5IBAQEW+o001HKJLn6aIiHSGzvx7Y2Z9zGy2ma3xf/ZuYrtpZrbKzNaa2W0t7W9mfc3sLTMrNbM/dtb5NLa/vJoP1+7m3CMGqv6SSALo9ASTc269c+4o/98EfxYUnHN7nHNnOufG+j/3hu1zp3PuEOfcYc65l2MdY0qKd3E6/bD+LWwpIq1lZoT0DT4qlFeKDSXsRESkC7oNeMM5NxZ4w3/dgJmlAH8CzgXGA5ea2fgW9q8Efgz8T2zDb95ry3ZSG3Kcf8TgeIYhIr54zSKX0A4bkEefnHTOPHxAvEMR6TICpi/w0aYndSIiItKC6cBMf3kmcGGEbSYDa/2OANXAk/5+Te7vnCtzzr2Pl2iKm1eX7WBo7ywmDsmLZxgi4lOCKYLC0iomDNZFSiSaAurBFF/67Fukj0hERDpF5/7BGeCc2w7g/4w0RGMIsCXsdYHf1tr946KyJsgH63Zz5rj+eugmkiBS4x1AItpdUsUh+TnxDkOkS1GR7+hRT7DY0McqIiLJyMxeBwZGWPXD1h4iQlvU/iqa2QxgBsDw4dGrcTtn/R4qa0KcoVEnIglDCaZGnHMUllSR3yMj3qGIdClmEFIXpvjRg72W6ddTRESSkHPurKbWmdlOMxvknNtuZoOAXRE2KwCGhb0eCmzzl1uzf0vxPQA8ADBp0qSo/bV9bdkOstJSmDKqT7QOKSIdpCFyjRRX1lIdDJGfqwSTSDQFzNRDRBKaU4ZJRES6nlnAVf7yVcDzEbZZAIw1s1Fmlg5c4u/X2v073a6SSp5dtJULjxlMZlpKvMMREZ8STI1s2lMGoASTSJQFDA2RizINlRMREUk+nfxA427gbDNbA5ztv8bMBpvZSwDOuVrgJuBVYAXwlHNuWXP7+8fYCPwWuNrMCsJmnou5D9bupjoY4oqpIzrrLUWkFTRErpE/vbUWUIJJJNpU5Dt62vUx6rNvkfJ1IiLS1Tjn9gBnRmjfBpwX9vol4KXW7u+vGxm1QNto/oZ95GamMm6gJmYSSSTqwdRIeqrXxfL4kRrLKxJNpiLfUacZU6JLv50iIiLJYf6GPRw/sg8pAd0LiSQSJZgaqQ2GGNO/B2kp+mhEoik1YNSGnIZ1tcGjczZSXFkT7zC6Df1uiohIZ1Ltv/bZXVrFusIyJqu4t0jCURalkaKKGnpmpcU7DJEup2dWGsGQo7SqNt6hJI2fPL+MH/9n6UHt7cqD6AGfiIhIQtDzjI5ZuHEvoBEnIolICaYwzjkK9lXQNyc93qGIdDm9/f+v9pWpR05b7C2rjncI3Ybu90VEpDOZnv60y7wNe8lMC3DEkJ7xDkVEGlGCKcyaXaVs3lvOyYfmxzsUkS6nd7bXM3BPWVWcI+mmlD1pkZ4oi4iIJL75G/ZyzLDepKfqq6xIotH/lWGWbysG4ITR6m4pEm15/tBTDZGLL9UFb5pqYYiISGfQA432K66sYfn2YtVfEklQSjCFKarwhu70ytYQOZFoy073ZmgsqwrGOZLk15FESDxuajftKWPkbS/ywpJtnf/mbaEbfhERkYS2aNM+nIMpSjCJJCQlmMLUJZhU5Fsk+nLSUwEor1YPpriIY8+lut6hLyzeHr8gREREJOnNW7+X1IBx9PBe8Q5FRCJQgilMUUUN2ekppKXoYxGJtuwMrwdTebV6MMXS0q1FvL9md7zDSErqwCQiIp1JQ7Pbbs663Rw9rBfZ/oNLEUksyqSEKaqoUe8lkRip68H0o/8spbhSM8lFg4sw3u38+97nir/Pi7BxJwSU5FQTQ0REOoP+3LRPUXkNS7YWceKYfvEORUSaoARTGCWYRGInKy2lfjk3Q0+dOqQDd6Yq8t00PUkWEZHOZPEcv56E5m7Yg3Nw0iF94x2KiDRBCaYwRRU19TNdiUh0BQIHbqJMWY6o0OcoIiIi3cVHm/eRlmIcNaxXvEMRkSaoG0GY4ooahvXJjncYIl3WXy4/ltqQeonEk4aBNU2fjYiIdCb1nG2bTzbvZ/ygPDLDesWLSGJRgilMUUUNR6gHk0jMnHvEoHiH0CW063bUOrBvN6HPRkREOkOkGorSvGDI8enWIi46bmi8QxGRZmiIXBjVYBKRLsu/l03Wm1rnHKEY935L1s9GRESSk2owtd4nW/ZTXh3k2OG94x2KiDRDCSZfTTBEeXVQCSYRkQT0k+eXMfoHL8X0PZRf6h5G3vYi3/rXJ/EOQ0REQ+Ta4NE5G8nNSOXMw/vHOxQRaYYSTL6iCm/a9J7ZSjCJSOJ4b81u/ufpxRHXtafHTShJsyj/mLsJUC8jiY5/f7w13iGISDemv2RtEww53l5VyDkTB5Kbqe9qIolMCSbfntJqAPrkpMc5EhGRhp5ZVNDgdWtzLG+s2Mme0ioAPli3G4BQKKqhdToViRcRka5CQ+RaZ+nWIooqajh5bL94hyIiLVCCybe9qAKAgXmZcY5ERORgzjmCIceanSX1bWZN35hWVAe5buZCrn1kAQD7y71emsnag6lOTTB2GbIk/2hERES6pPfXeg/JThqjBJNIolOCybezuBKAAUowiUgCqg057n55BWf/7l227a9ocfvvP7sEgPWFZQ3akz2JUhOM3QmoFkbXpyGWIpJIgromtcq7qwsZPyiPfj0y4h2KiLRACSbf9iIlmEQkcVXXhnj+k20A7C6rirhNZU2wfnnWYm/bxr3vGydR5q3fwydb9kctzkiiefscyx5M0vVpiKWIJIK6vFJ1rf6mtWRHUSWLNu3jlEPz4x2KiLSCEky+bfsr6NcjnfRUfSQikniqakOUVtUC8KtXVkXc5oS73jioraSytkHiaeOecjbtOdCr6SsPzOXCP33A8m3FMevdEYzil/raWPZgUu6hy4vl74+ISFtV1QZb3qibe3zeJkLOcfmU4fEORURaQdkU37urd3P0sF7xDkNEJKKL7/+Q8uqGN6LBkGNHUSVPLdhCdW2IfX6dpcb+32Mf1S//5e11nHrP2wdtc9697/HgexuiGnOdaNZ9imkNppgdWdrKOVc/u2s01YRVuQ9PvIqIxENlTex7MJlZHzObbWZr/J+9m9humpmtMrO1ZnZbS/ub2dlmtsjMPvV/nhGL+N9eXchxI3ozrE92LA4vIlGmBBOwr6yaHcWVTBnVN96hiIhEtK5RLaU6U+96g+89u4RDf/Ryk/u+uXJXq97jv0u2MXf9HgpLqthdGnkYXntE6sG0vaiCpxZs4a6XV7TpWNVtSDC9sWInI297kbW7SlreGNXnSSSPfLiRo372Glv2lkf1uOE9mD7atC+qxxYRSVC3AW8458YCb/ivGzCzFOBPwLnAeOBSMxvfwv67gQucc0cAVwH/iHbghSVVfLq1iJPHanicSLJQgglYW1gKwJj+PeIciYhI52ncg2NJQRGXPDCX4+98nUm/eB2A2mCIT7bsb3Xypbjy4F4nkerenHDXm3zv2SX89Z31EY+zbX8F2/ZXUFJZ06BGRVuGOL2wZDsAH2/e36rtu2N66Wf/XcZbrUxAdqZXl+0AYNOe1ieY9pRW1c8I25TasATlqp2tSzyKdBfOuQb/j0gsdepfnOnATH95JnBhhG0mA2udc+udc9XAk/5+Te7vnPvYOecXfGQZkGlmUa3C/dryHTgHZ48fEM3DikgMKcEErNxeDCjBJCKJ7dqTRvG7rxzFcSN6s+CHZzG0d1a7j3XHrGWM+/ErLW734qfbufBPH/DMooKI64OhA19I5q7fw5F3vMb7a3bXr3fO1Q9rM7/geONhbqEICagT736TE+9+kyPueI1v/euT+vaaYIhdJZWs2tH65ICZtbxRJ1tfWMp6/+FGwb7yiJ9BuK8/upD73ljT6uP/v8cW8crSHc1uEwo5Hv5gI9c8sqDVxw3f98H31rd7GNv7a3ZTUd30ELXUgHd7Uhtq/ZfdqXe9wQl3vdnsZ1kTtm7p1uJWH1ukO3jg3fWM+eHLlPn1/qTLGOCc2w7g/+wfYZshwJaw1wV+W2v3/xLwsXMuYvdnM5thZgvNbGFhYWGrA39i/mbG9u/BuIG5rd5HROIrNd4BJIJXl+1kVL+cDn1ZE5HuwcymAX8AUoAHnXN3x/L93vnuafz8hRVcdeKI+i7iXzhmKADvfe90nllUwGfG9uOEu95s03Ef+XBji9uMvO3F+uXvPrOE6UcPIT01wD/mbmJ3SRXfOvtQvvr3eXy6tYhP7zinPrH0wHvrKa+u5azDB/DLV1fW91Jyzks47W9UK2pdYSlFFTUckt+D3jnpB8Xx4qfb65dfXrqdRz/cRElVLRvv/lybzrklkTpp1SUrAoGGSaqq2iApZqSmBKiqDbJxdzmHNboBruv1VZfgcs7x0qc72LinjHte9Qq1v//90/nML9/i0snD+b8vTOTpRQV875kl3HfpMSwp2M93PnsYmWkpzF6+k9nLd3LzmWMBWLOzhDH9e0RMnpVV1fLSpzu894rwGZVW1ZIasAY1vTbvKef7zy7hT5cfS58I/w2qaoOkBQL1n8Oc9Xv4xYsrWLWjhHsuPiryB4o3Q9KP/7OUGaeO5pB87yHOpj1lXPH3eXzp2KFcdeIIqmpDHDOsF9XBEB9v3k9+bgYF+7yeS68s3cGxI3qTFgjw8tLtDOyZSf/cDN5dvZsJg/PYtLecEX2y+dWrq6jxe7eN/sFL3HbuOEb1y2FHUSUPfbCBwpIqzjp8APvKq+tj++/ibXz3nMMY2DM5Z4/t7GuRNFQTDJEasBYT2MGQIyVghEKOkqpaemalecuVtTgcwZAjNzONtJQDx6qqDeIcZKalNHm8OvvLqzGMjLQAJZW19OuRTnUwhHOwr7yavjkZ/GvhFn718kr+df0J9MlJ53ezV/Odcw6lujZEaiBAdkYKW/dVcNfLKwF4dM4mAgYnj81nTP8eFFfW0K9HRv31Oz01gJmXpB2Ql8GQXlnM37CXf87bxMC8LL58/FDWF5axbFsRN50+ltpQiBeXbKe4soZt+ys59bB8Tj+sP7tLq6gJhhjUM6v+QUVJZS0b95QxpFcWPbPTyEhNqT9vw7sWV9YESQkYaSkBnHMH/TdwzlFVG6r//CJtE368SJxzVNQEWbWjhCOH9mrwmdcGQ6SmRH5Gv6OoktpQiNzMNFICxqodxYzpn0tuRiqVtUH2lFaTl5nWYJ9H52zkyhNGRjxea5nZ68DACKt+2NpDRGhrVTcrM5sA/BL4bFPbOOceAB4AmDRpUquOW1pVy7JtxdxyxtiEfFAkIpFZstScaOuN1KRJk9zChQtbPG5hSRUn/+pNLjl+OHd8fkJ0ghWRqDCzRc65SfGOo45fo2A1cDbe070FwKXOueVN7dPaa1FNMEQw5LwkwhMf17e3NonyytIdjOibzbl/eA+AL08aSu/sdD5Yt5sbTxvDml2l/PnttfTMSuOxr03lupkLuODIwfzxrbWtOn5Lzjp8AO+tKaSqg1Mu/3z6BH78/LJWbfv5owYTDDmOGd6Lh97fQK/sdH510ZEUV9SwZV8533/2UwCOGtaL26aNY876PbyweBuH9O/BkUN6UhMMsXx7MbeeeSj//ngr63eX8vYq78nqs984kf/97zIWFxQB8I/rJlNUUcNZhw9g7a5Szr/vfQA++vHZXP+PhSzYuI8po/pw7WdG0SsrjcMG5vL39zfwp7fWUtdp5vwjB9UP26vTPzeDXSVN17u6/pTRjOyXw+3Peefyg/PG8cgHG9lWVMnQ3lk4B1v3V3DaYfkEzNiyt5wzxvXnr+96Sb3hfbJxOI4f2Yei8hrGDcrlT2+ta/ZzvfXMsazaUcKc9XvITAuQlZbCRn+o2kXHDSUnPYV/zttcX1trcM9MSqpqKamsZdzAXKpqQ+wpraKsOnhQ/a2hvbMY7H8ZjafrTx1Nwb4KfnDe4Qzp1fLDpe50LWrK3rJqstNTIiY9OoNzjkfnbKK0qpbR/XLonZPOpj1lFFfUkppiDMjLpNjvUZeRFmDb/kpG9M2mqiZEUUUNJZW1LNi4l8MG5pISMLbtr+DtVYVMP3owpVW1VNeG6JWdxsi+OWzeW87Q3tmkBLwizCkBq5+Rc3HBfkora1mzq5Sx/Xtw7PDeVNYGKamspby6ltRAgMKSKjLTU6ipDbGtqIK+OelN1tGrEzA4dnhvPt6yn5BzOAeH5OcQDDm27q+gJujITAtQWROiT046/Xqks3pnaf2+UZysM6LcjFSCztUnpjv6noN6ZrK9qBKA7PQUyqu9pFHja0a/HulkpKZQWFpFdW2I3tlp7CuvIS3FyO+RwbaiyvpY0lKMwwbmsnVfBfsrashKSyE7PYXiilp6ZqcxtHcWu0urqKwJsbesmvSUAKP65VBWXYvhZVNSzEhPDbCusJSAGVW1ITJSA2SkBshMSyEjLcD2/d71d0jvLGqCXjKrtLKG4spaCpu5njfn3//vRI4ZHrH29kHaej0ys1XAac657WY2CHjbOXdYo21OAO5wzp3jv74dwDl3V3P7m9lQ4E3gGufcB62Jp7XXornr93DJA3N5+OrjOX1cpE5TIhJPTV2LkiLBFMsbqdufW8LTCwt47VunMDpfQ+REEkkCfqlr8gasqX1acy0KhRxT7nqjwY1pZlqAq04Yye3nHd6mGJ9dVMB3nl7MJz85m17ZDXuihELuoKe1a3eVsqe0ik17yzn10HyqakJkpgcorwqyvaiSe15dyUetrGEkXUduZiollQcPk+mRkUptKFQ/81FuZio1wVCbZkIa2juLgn0HaiU1/lKZl5lK75x0Dh2QS8E+rxZXVloKvbLTOGfCQJ7/ZCvbiio5Z8JAhvXO4qPN+0hLCfCbi4+iOhgiNyONuRv2sHRrETkZqWzZW87ph/VnxfZi/rtkG6t3lnL9qaO5/dzW/7/VXa5FAPPW72FvWTW1IcfesmpmLd7GpwVFVAdDpKUYY/vnEnKOYX2y2bK3nCOG9CS3UY8M8OqolVTVMLa/17OvOhiiNhgi5A70ZnR4s0zWBh21IS/JHgw5SqtqqQ05qmtD/pf3WgpLqyJOGNBZvN5K0DMrjbysNNb7CaMeGan0zEojEICaWkd2egr5uRlU1AQp2FfB3rJqThrTl13FVWwvqiQrPaX+Wn/U0J4UVdRQVRtie1El4wflkZkWoFd2OsP7ZFOwr5yMNC9RtaukyusptHEv4wflURsKsXDjPob0yiIQMPaXV7O71OuhN3FIHhMG9WRI7yxW7ShhV0klA/Iy2ba/gj45Xg/BEw7p6yXC0lLqkz0V1UGuPGEEzy/exrJtxRw3vDc5GSls219JeqpRE3Ss2uH1nkxLMQr2VVBWHWT8oFwyUlOYPKoPfXLS2bC7jLKqWlZsL2FQz0zKq4OUVtVQXh3E4XWVSQ0YG/zE9dj+PXAOemWnUVkTZH95DRU1QSqqg4zsl83esmoG5mWyq6SKypogEwb3ZG95NeVVtYQcDO6VRUllDfvLa9i6v4Ix/XvUJ+MqaoL0zUmntKqWNTtLGdYni/SUgDdc1sGmvWWkpQSo8pNOE4fkUVkTYntRBUcN7UWfnHS2FVXQIyOVfeU1FJXXMKxPNrtLq9hfUUNGSoDqYIj01AA4GD84j/W7y+iVlUbPrDSOHdGLpVuL2VdWTWZ6CsN6ZzNn/R5SDEb2y+FLxw7l2099wp8vP67VpTrakWC6B9jjnLvbnx2uj3Pue422ScX7rnUmsBXvu9ZlzrllTe1vZr2Ad4D/dc4929p4WnsteuDddfzfSytZ9KOz6NsjqqWdRCQKmroWJcsQufrCcwBmVld4rskEU2vsKKrk6YUFXHnCSCWXRKQ1ItUomNLRgwYCxv877RB+O3t1/Zf6j3/8WbLS295T4EvHDeVLxw1t8n0aG9O/B2P692DK6EazaOZ6N7/P/b+TAC85VR0MEXLel7+1u0q57G/zuOXMsVwxZTiBgPH68p0M7Z3N4/M30TcngyOG9sQ5x46iKp75aAsXHzeMDbu9YRPfOO0Qzjp8AL+bvYZe2WmM6d+DdbtK6ZWTTnFFDYs27ePqE0cyOj+Hx+ZtZknBfj5/1GAy01LonZ3Ob2av5tSx/RjRN4ePNu+joiZIYUkV4wfnsXZnKfM27GXGKaM5Y1x/1hWWUlEdJDsjlfkb9pCVlsLYAbks3LiXEX1zKK+uxfC+PG7bX8mG3aWUVQUZ3jebzLQUXl26g0G9MumRkcqK7cUEzKgNOXpkpHLk0J6UVtUSDDkOH5TH6Pwc3l5ZyPyNe/nq1BH1vZZ656Rz4iF9KauqZf6GvVTUBKkJhjhz3ADOGNefoooaPinYz5FDehJysGjTPvaWVTN/wx72V9QQDDkunTycmmCIsf1z6Zmdxoptxewrr+aciQPZX1bDkq37vSf8Oen0ykqjT0465dVBBuRlsq+8GsM7v9H5Oezxv4gO7JmJmfclOTVgFJZWkZuZRo+MVIorayiuqCEjNYU+OenUBENN9l4JT17uKa2id3Y6Qb/+VmZqCkHnSGtiSElbfevsQ1vc5pwJAzlnQsPRImeNH8AFRw3mtF+/zbQJkUaSJJVWXYvMbAYwA2D48OGtOvCvX1vFgo0HZtgb0TebsycM4IghPdlfXsPCjXtZuGkfG/eUUVkTYl1hKRmpKQeNrynx6/h8vHk/qQGvV0hqIEDAvGGjZhDwf6YGjNRAgJSAkRIwMtMC9MhIJSMnQEaq1wulX24GOekpjOrXg8UF+xnUM5OUgLF1fwWHD8wjLSXg9fzBS16lBIyc9FTSUwMMyPN+z0f0ySboHJXVITbvLWdIb29oVm3IkZvpbbu/vIbs9BTKqoKkpnhxp6d4PViCIUfArMlhVV3FQX8P2mhqB/fvar5wTMPX3zjtkAavX/3mKbEeAnY38JSZXQdsBi4GMLPBeKNCznPO1ZrZTcCreKNFHnLOLWtuf+AmYAzwYzP7sd/2WedcVGaOWLyliKG9s5RcEkkyydKD6SJgmnPua/7rrwJTnHM3Ndou/EbquE2bNrV47KVbixjWO5ue2Qc/fROR+ErAXgMXA+c0uhZNds7d3Gi7Nl+LgPpER3l1rW6oRBJIsl6LwrW218CG3WX1NcZyM9Pon5vR5RMqIskk0a5HbdXaa5E3M2glE4f07ISoRKStkr0HU6sKz7WngJwuWiLSBgXAsLDXQ4FtjTdqz7UIIDvduyS3p+eSiHQrrboWtceofjnROIyISIf07ZGhh20iSSg6/dVjL2Y3UiIibbAAGGtmo8wsHbgEmBXnmESk+9G1SERERBJOsvRgqr+Rwis8dwlwWXxDEpHupoUaBSIinULXIhEREUlESZFg0o2UiCQK59xLwEvxjkNEujddi0RERCTRJEWCCXQjJSIiIiIiIiKSqJKlBpOIiIiIiIiIiCQoJZhERERERERERKRDlGASEREREREREZEOUYJJREREREREREQ6RAkmERERERERERHpECWYRERERERERESkQ8w5F+8YYsLMCoFNrdi0H7A7xuF0Np1TctA5tWyEcy4/isfrdG24FkHX+53oaucDOqdkoWtRI938WgRd75y62vmAzqm1kvp6pGuRzikJdLXzgU68FnXZBFNrmdlC59ykeMcRTTqn5KBzksa62ufX1c4HdE7JoiueU2fqip9fVzunrnY+oHOSg3XFz0/nlPi62vlA556ThsiJiIiIiIiIiEiHKMEkIiIiIiIiIiIdogQTPBDvAGJA55QcdE7SWFf7/Lra+YDOKVl0xXPqTF3x8+tq59TVzgd0TnKwrvj56ZwSX1c7H+jEc+r2NZhERERERERERKRj1INJREREREREREQ6pFsnmMxsmpmtMrO1ZnZbvONpDTMbZmZvmdkKM1tmZrf67X3MbLaZrfF/9g7b53b/HFeZ2Tnxi755ZpZiZh+b2Qv+66Q+JzPrZWbPmNlK/7/XCV3gnL7l/94tNbMnzCwz2c8pESTjtQi67vVI16KkOCddi2JA16LEomtRUpyTrkUxoGtRYulq1yLoetejhLoWOee65T8gBVgHjAbSgcXA+HjH1Yq4BwHH+su5wGpgPPAr4Da//Tbgl/7yeP/cMoBR/jmnxPs8mji3bwOPAy/4r5P6nICZwNf85XSgVzKfEzAE2PD/27v/ULvrOo7jz3ct5U6ptpmymqXCiIhiW2KRJtaCUGM3Ktiq0forxEj6S1wrcv+G6P4I6g9LKmUaJWtghKDSL2JqNsaYRTOXrlZTyGY/SFvv/vh+RsfL3b2Xnfvd+Xy+9/mAwznnc8655/P63ntff3z4fM8Bpsr97wGfaTlTDZdWu6jMfZB9ZBfVncku6u242kUVZJmRyy6qOJNd1NtxtYsqyDIj16C6qMx1MH1UWxct5R1MVwCHM/P3mfkScC8wPeE5zSszj2XmE+X2i8CTdH9U03T/KJTrj5Tb08C9mfnvzHwaOEyXvSoRsQa4HrhzZLjZTBHxWuBq4JsAmflSZr5Aw5mKZcBURCwDlgN/ov1Mk9ZkF8Ew+8guqj9TYRctPruoInZR/ZkKu2jx2UUVGVoXwWD7qJouWsoLTG8Cnh25f7SMNSMiLgHWA/uAizLzGHTlBlxYntZKzl3AzcB/R8ZaznQZ8BxwV9lSemdEnEfDmTLzj8BtwDPAMeBvmfkgDWeqxCCO04D6aBd2UdWZ7KLeDOI42UVAnXnsogYyVWIQx8kuAurMAwPro9q6aCkvMMUsY3nWZ3GGIuJ84AfAFzLzxFxPnWWsqpwR8WHgeGb+aqEvmWWsqkx0q8gbgK9n5nrgH3RbE0+n+kzlvN1puq2UbwTOi4itc71klrGqMlWi+eM0lD6yi4AGMtlFvWn+ONlFr1BNnsIuaiBTJZo/TnbRK1STZ8Sg+qi2LlrKC0xHgYtH7q+h20pWvYh4DV1p3ZOZ95fhv0TE6vL4auB4GW8h55XApog4QrcN9gMRcTdtZzoKHM3MfeX+9+mKrOVMHwSezsznMvNl4H7gvbSdqQZNH6eB9ZFd1EYmu6gfTR8nu6jqPGAXQRuZatD0cbKLqs5zytD6qKouWsoLTI8BayPi0og4B9gC7J3wnOYVEUF3vuiTmXn7yEN7gW3l9jbghyPjWyLi3Ii4FFgLPHq25rsQmbk9M9dk5iV0v4eHM3MrbWf6M/BsRLy1DG0EDtFwJrptl++JiOXl73Aj3bnlLWeqQZNdBMPrI7sIaCATdlFf7KJK2EVAA5mwi/piF1ViiF0Eg+yjurooK/jk80ldgOvoPt3/KWDHpOezwDlfRbeF7QCwv1yuA1YBDwG/K9crR16zo2T8LXDtpDPMk+8a/v8NBU1nAtYBj5ff1R5gxQAy7QR+AxwEvkv37QNNZ6rh0mIXlXkPto/souoz2UX9HFe7qLKLXVR9Jruon+NqF1V2GVIXlXkOqo9q6qIobyBJkiRJkiSdkaV8ipwkSZIkSZIWgQtMkiRJkiRJGosLTJIkSZIkSRqLC0ySJEmSJEkaiwtMkiRJkiRJGosLTOpNRJyMiP0jl1vmef4NEfHpRXjfIxFxwRm87kMRcWtErIiIH407D0l1sIsk1cAuklQDu0h9WjbpCWjQ/pWZ6xb65Mz8Ro9zWYj3AY8AVwO/mPBcJC0eu0hSDewiSTWwi9QbF5h01kXEEeA+4P1l6JOZeTgibgX+npm3RcRNwA3Af4BDmbklIlYC3wIuA/4JfDYzD0TEKmA38AbgUSBG3msrcBNwDrAPuDEzT86Yz2Zge/m508BFwImIeHdmburjGEiaPLtIUg3sIkk1sIu0GDxFTn2amrH9cvPIYycy8wrga8CuWV57C7A+M99JV2IAO4Ffl7EvAt8p418Bfp6Z64G9wJsBIuJtwGbgyrJKfxL41Mw3ysz7gA3Awcx8B3CwvLfFJQ2DXSSpBnaRpBrYReqNO5jUp7m2X+4eub5jlscPAPdExB5gTxm7CvgYQGY+HBGrIuJ1dNslP1rGH4iIv5bnbwTeBTwWEQBTwPHTzGct8FS5vTwzX5wvnKRm2EWSamAXSaqBXaTeuMCkScnT3D7lerpS2gR8OSLezsi2ylleO9vPCODbmbl9rolExOPABcCyiDgErI6I/cDnM/Nnc6aQ1Dq7SFIN7CJJNbCLNBZPkdOkbB65/uXoAxHxKuDizHwEuBl4PXA+8FPK9smIuAZ4PjNPzBi/FlhRftRDwMcj4sLy2MqIeMvMiWTm5cADdOf2fhXYkZnrLC5pSbCLJNXALpJUA7tIY3EHk/o0VVaZT/lxZp76GsxzI2If3SLnJ2a87tXA3WVrZQB3ZOYL5QPm7oqIA3QfILetPH8nsDsingB+AjwDkJmHIuJLwIOlEF8GPgf8YZa5bqD7oLkbgdvHyCypPnaRpBrYRZJqYBepN5E52641qT/lGwouz8znJz0XSUuXXSSpBnaRpBrYRVoMniInSZIkSZKksbiDSZIkSZIkSWNxB5MkSZIkSZLG4gKTJEmSJEmSxuICkyRJkiRJksbiApMkSZIkSZLG4gKTJEmSJEmSxuICkyRJkiRJksbyP137RycArlrAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graph(logger):\n",
    "    \n",
    "    score_arr  = np.array(logger.scores_list)\n",
    "    #score_arr[score_arr < 0] = 0\n",
    "    _, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    # Scores\n",
    "    axs[0].plot(np.arange(1, len(logger.scores_list)+1), score_arr)\n",
    "    axs[0].set(xlabel='Episode #', ylabel='Score')\n",
    "    axs[0].set_title('Rewards')\n",
    "        \n",
    "    # Actor Loss\n",
    "    axs[1].plot(np.arange(1, len(logger.actor_loss_list)+1), logger.actor_loss_list)\n",
    "    axs[1].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[1].set_title('Actor Loss')\n",
    "    \n",
    "    # Critic Loss\n",
    "    axs[2].plot(np.arange(1, len(logger.critic_loss_list)+1), logger.critic_loss_list)\n",
    "    axs[2].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[2].set_title('Critic Loss')\n",
    "    \n",
    "    # Entropy Loss\n",
    "    axs[3].plot(np.arange(1, len(logger.entropy_loss_list)+1), logger.entropy_loss_list)\n",
    "    axs[3].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[3].set_title('Entropy Loss')\n",
    "    plt.show()\n",
    "    \n",
    "plot_graph(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Here are my key attempts at tuning the hyperparams to finally achieve R > 2500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--18:42:50 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 16.67 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.05 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 25.56 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.06 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 40.25 \t Steps: 2047\n",
      "\n",
      "Episode 40: \tActor Loss: 0.06 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 53.84 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.07 \tCritic Loss: 0.32 \n",
      "\t\tAvg Score [100eps]: 83.67 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.07 \tCritic Loss: 0.48 7\n",
      "\t\tAvg Score [100eps]: 119.49 \t Steps: 2047\n",
      "\n",
      "Episode 70: \tActor Loss: 0.10 \tCritic Loss: 0.70 7\n",
      "\t\tAvg Score [100eps]: 121.49 \t Steps: 2047\n",
      "\n",
      "Episode 80: \tActor Loss: 0.10 \tCritic Loss: 0.79 7\n",
      "\t\tAvg Score [100eps]: 141.55 \t Steps: 2047\n",
      "\n",
      "Episode 90: \tActor Loss: 0.10 \tCritic Loss: 0.88 2\n",
      "\t\tAvg Score [100eps]: 155.02 \t Steps: 1002\n",
      "\n",
      "Episode 100: \tActor Loss: 0.10 \tCritic Loss: 0.95 7\n",
      "\t\tAvg Score [100eps]: 167.20 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.10 \tCritic Loss: 1.13 7\n",
      "\t\tAvg Score [100eps]: 189.66 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.11 \tCritic Loss: 1.32 7\n",
      "\t\tAvg Score [100eps]: 189.91 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.12 \tCritic Loss: 1.48 7\n",
      "\t\tAvg Score [100eps]: 228.75 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.13 \tCritic Loss: 1.75 7\n",
      "\t\tAvg Score [100eps]: 221.35 \t Steps: 2047\n",
      "\n",
      "Episode 150: \tActor Loss: 0.13 \tCritic Loss: 1.86 7\n",
      "\t\tAvg Score [100eps]: 220.74 \t Steps: 2047\n",
      "\n",
      "Episode 160: \tActor Loss: 0.13 \tCritic Loss: 2.34 2\n",
      "\t\tAvg Score [100eps]: 278.68 \t Steps: 1002\n",
      "\n",
      "Episode 170: \tActor Loss: 0.13 \tCritic Loss: 2.35 7\n",
      "\t\tAvg Score [100eps]: 224.74 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.13 \tCritic Loss: 2.67 7\n",
      "\t\tAvg Score [100eps]: 332.94 \t Steps: 2047\n",
      "\n",
      "Episode 190: \tActor Loss: 0.14 \tCritic Loss: 3.32 7\n",
      "\t\tAvg Score [100eps]: 462.00 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.15 \tCritic Loss: 4.19 7\n",
      "\t\tAvg Score [100eps]: 512.58 \t Steps: 2047\n",
      "\n",
      "Episode 210: \tActor Loss: 0.14 \tCritic Loss: 5.16 7\n",
      "\t\tAvg Score [100eps]: 522.13 \t Steps: 2047\n",
      "\n",
      "Episode 220: \tActor Loss: 0.14 \tCritic Loss: 6.05 2\n",
      "\t\tAvg Score [100eps]: 538.64 \t Steps: 1002\n",
      "\n",
      "Episode 230: \tActor Loss: 0.14 \tCritic Loss: 7.02 7\n",
      "\t\tAvg Score [100eps]: 565.91 \t Steps: 2047\n",
      "\n",
      "Episode 232\t Score [This Eps]: 580.47 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "Episode 240: \tActor Loss: 0.13 \tCritic Loss: 7.52 2\n",
      "\t\tAvg Score [100eps]: 589.37 \t Steps: 1002\n",
      "\n",
      "Episode 250: \tActor Loss: 0.14 \tCritic Loss: 8.54 7\n",
      "\t\tAvg Score [100eps]: 505.49 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.13 \tCritic Loss: 9.19 2\n",
      "\t\tAvg Score [100eps]: 632.91 \t Steps: 1002\n",
      "\n",
      "Episode 270: \tActor Loss: 0.13 \tCritic Loss: 9.28 2\n",
      "\t\tAvg Score [100eps]: 370.80 \t Steps: 1002\n",
      "\n",
      "Episode 280: \tActor Loss: 0.13 \tCritic Loss: 9.87 2\n",
      "\t\tAvg Score [100eps]: 689.65 \t Steps: 1002\n",
      "\n",
      "Episode 290: \tActor Loss: 0.13 \tCritic Loss: 10.12 \n",
      "\t\tAvg Score [100eps]: 625.61 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.12 \tCritic Loss: 10.11 \n",
      "\t\tAvg Score [100eps]: 703.00 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.12 \tCritic Loss: 9.91 7\n",
      "\t\tAvg Score [100eps]: 720.35 \t Steps: 2047\n",
      "\n",
      "Episode 320: \tActor Loss: 0.12 \tCritic Loss: 9.80 7\n",
      "\t\tAvg Score [100eps]: 800.06 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.13 \tCritic Loss: 10.24 \n",
      "\t\tAvg Score [100eps]: 829.16 \t Steps: 1002\n",
      "\n",
      "Episode 340: \tActor Loss: 0.13 \tCritic Loss: 10.61 \n",
      "\t\tAvg Score [100eps]: 848.33 \t Steps: 1002\n",
      "\n",
      "Episode 350: \tActor Loss: 0.12 \tCritic Loss: 11.05 \n",
      "\t\tAvg Score [100eps]: 847.59 \t Steps: 1002\n",
      "\n",
      "Episode 360: \tActor Loss: 0.12 \tCritic Loss: 11.29 \n",
      "\t\tAvg Score [100eps]: 855.72 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.11 \tCritic Loss: 12.55 \n",
      "\t\tAvg Score [100eps]: 887.86 \t Steps: 1002\n",
      "\n",
      "Episode 380: \tActor Loss: 0.11 \tCritic Loss: 12.90 \n",
      "\t\tAvg Score [100eps]: 854.57 \t Steps: 2047\n",
      "\n",
      "Episode 390: \tActor Loss: 0.11 \tCritic Loss: 13.28 \n",
      "\t\tAvg Score [100eps]: 864.49 \t Steps: 1002\n",
      "\n",
      "Episode 400: \tActor Loss: 0.11 \tCritic Loss: 13.00 \n",
      "\t\tAvg Score [100eps]: 661.30 \t Steps: 1002\n",
      "\n",
      "Episode 410: \tActor Loss: 0.12 \tCritic Loss: 12.23 \n",
      "\t\tAvg Score [100eps]: 537.45 \t Steps: 1002\n",
      "\n",
      "Episode 420: \tActor Loss: 0.13 \tCritic Loss: 11.40 \n",
      "\t\tAvg Score [100eps]: 689.51 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.15 \tCritic Loss: 10.59 \n",
      "\t\tAvg Score [100eps]: 776.51 \t Steps: 2047\n",
      "\n",
      "Episode 440: \tActor Loss: 0.16 \tCritic Loss: 9.95 7\n",
      "\t\tAvg Score [100eps]: 731.61 \t Steps: 2047\n",
      "\n",
      "Episode 450: \tActor Loss: 0.17 \tCritic Loss: 9.29 7\n",
      "\t\tAvg Score [100eps]: 772.78 \t Steps: 2047\n",
      "\n",
      "Episode 460: \tActor Loss: 0.18 \tCritic Loss: 9.00 7\n",
      "\t\tAvg Score [100eps]: 848.92 \t Steps: 2047\n",
      "\n",
      "Episode 470: \tActor Loss: 0.19 \tCritic Loss: 8.48 7\n",
      "\t\tAvg Score [100eps]: 741.57 \t Steps: 2047\n",
      "\n",
      "Episode 480: \tActor Loss: 0.20 \tCritic Loss: 8.01 7\n",
      "\t\tAvg Score [100eps]: 818.94 \t Steps: 2047\n",
      "\n",
      "Episode 490: \tActor Loss: 0.21 \tCritic Loss: 7.67 7\n",
      "\t\tAvg Score [100eps]: 870.38 \t Steps: 2047\n",
      "\n",
      "Episode 500: \tActor Loss: 0.21 \tCritic Loss: 8.03 7\n",
      "\t\tAvg Score [100eps]: 881.02 \t Steps: 2047\n",
      "\n",
      "Episode 510: \tActor Loss: 0.22 \tCritic Loss: 8.84 2\n",
      "\t\tAvg Score [100eps]: 906.73 \t Steps: 1002\n",
      "\n",
      "Episode 520: \tActor Loss: 0.22 \tCritic Loss: 9.21 7\n",
      "\t\tAvg Score [100eps]: 860.08 \t Steps: 2047\n",
      "\n",
      "Episode 530: \tActor Loss: 0.23 \tCritic Loss: 8.72 2\n",
      "\t\tAvg Score [100eps]: 683.69 \t Steps: 1002\n",
      "\n",
      "Episode 540: \tActor Loss: 0.24 \tCritic Loss: 8.15 7\n",
      "\t\tAvg Score [100eps]: 396.15 \t Steps: 2047\n",
      "\n",
      "Episode 550: \tActor Loss: 0.25 \tCritic Loss: 7.33 7\n",
      "\t\tAvg Score [100eps]: 483.04 \t Steps: 2047\n",
      "\n",
      "Episode 560: \tActor Loss: 0.26 \tCritic Loss: 6.20 7\n",
      "\t\tAvg Score [100eps]: 478.04 \t Steps: 2047\n",
      "\n",
      "Episode 570: \tActor Loss: 0.27 \tCritic Loss: 5.20 7\n",
      "\t\tAvg Score [100eps]: 472.78 \t Steps: 2047\n",
      "\n",
      "Episode 580: \tActor Loss: 0.28 \tCritic Loss: 4.38 2\n",
      "\t\tAvg Score [100eps]: 480.22 \t Steps: 1002\n",
      "\n",
      "Episode 590: \tActor Loss: 0.29 \tCritic Loss: 3.39 7\n",
      "\t\tAvg Score [100eps]: 507.63 \t Steps: 2047\n",
      "\n",
      "Episode 600: \tActor Loss: 0.31 \tCritic Loss: 2.39 2\n",
      "\t\tAvg Score [100eps]: 550.19 \t Steps: 1002\n",
      "\n",
      "Episode 603\t Score [This Eps]: 565.52 \t Steps: 1002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a0278a43b67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-c53f3a19b957>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, a)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# state network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_3s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_3s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# Q value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# std input: 0.3\n",
    "# std_scale hard_tanh max = 0.5*std_scale\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cpu\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.9\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-04--14:27:09 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.30 \n",
      "\t\tAvg Score [100eps]: 33.23 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.10 \tCritic Loss: 2.57 7\n",
      "\t\tAvg Score [100eps]: 181.66 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.14 \tCritic Loss: 5.15 0\n",
      "\t\tAvg Score [100eps]: 288.22 \t Steps: 1000\n",
      "\n",
      "Episode 40: \tActor Loss: 0.15 \tCritic Loss: 6.97 7\n",
      "\t\tAvg Score [100eps]: 330.52 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.16 \tCritic Loss: 8.80 7\n",
      "\t\tAvg Score [100eps]: 308.96 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.19 \tCritic Loss: 9.97 7\n",
      "\t\tAvg Score [100eps]: 317.72 \t Steps: 2047\n",
      "\n",
      "Episode 70: \tActor Loss: 0.19 \tCritic Loss: 11.15 \n",
      "\t\tAvg Score [100eps]: 329.00 \t Steps: 2047\n",
      "\n",
      "Episode 80: \tActor Loss: 0.19 \tCritic Loss: 12.28 \n",
      "\t\tAvg Score [100eps]: 345.67 \t Steps: 2047\n",
      "\n",
      "Episode 90: \tActor Loss: 0.19 \tCritic Loss: 13.02 \n",
      "\t\tAvg Score [100eps]: 427.46 \t Steps: 2047\n",
      "\n",
      "Episode 100: \tActor Loss: 0.19 \tCritic Loss: 13.46 \n",
      "\t\tAvg Score [100eps]: 359.68 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.20 \tCritic Loss: 15.42 \n",
      "\t\tAvg Score [100eps]: 449.71 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.21 \tCritic Loss: 16.98 \n",
      "\t\tAvg Score [100eps]: 422.86 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.20 \tCritic Loss: 17.78 \n",
      "\t\tAvg Score [100eps]: 361.45 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.20 \tCritic Loss: 18.12 \n",
      "\t\tAvg Score [100eps]: 487.65 \t Steps: 2047\n",
      "\n",
      "Episode 150: \tActor Loss: 0.19 \tCritic Loss: 18.41 \n",
      "\t\tAvg Score [100eps]: 508.40 \t Steps: 2047\n",
      "\n",
      "Episode 156\t Score [This Eps]: 563.43 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 160: \tActor Loss: 0.17 \tCritic Loss: 18.80 \n",
      "\t\tAvg Score [100eps]: 567.84 \t Steps: 2047\n",
      "\n",
      "Episode 170: \tActor Loss: 0.17 \tCritic Loss: 18.96 \n",
      "\t\tAvg Score [100eps]: 480.41 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.17 \tCritic Loss: 18.57 \n",
      "\t\tAvg Score [100eps]: 508.41 \t Steps: 2047\n",
      "\n",
      "Episode 190: \tActor Loss: 0.17 \tCritic Loss: 18.46 \n",
      "\t\tAvg Score [100eps]: 579.50 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.17 \tCritic Loss: 18.41 \n",
      "\t\tAvg Score [100eps]: 581.19 \t Steps: 2047\n",
      "\n",
      "Episode 210: \tActor Loss: 0.17 \tCritic Loss: 18.05 \n",
      "\t\tAvg Score [100eps]: 653.50 \t Steps: 2047\n",
      "\n",
      "Episode 220: \tActor Loss: 0.16 \tCritic Loss: 17.48 \n",
      "\t\tAvg Score [100eps]: 534.82 \t Steps: 2047\n",
      "\n",
      "Episode 230: \tActor Loss: 0.21 \tCritic Loss: 16.84 \n",
      "\t\tAvg Score [100eps]: 532.21 \t Steps: 2047\n",
      "\n",
      "Episode 240: \tActor Loss: 0.22 \tCritic Loss: 16.43 \n",
      "\t\tAvg Score [100eps]: 528.97 \t Steps: 2047\n",
      "\n",
      "Episode 250: \tActor Loss: 0.23 \tCritic Loss: 15.72 \n",
      "\t\tAvg Score [100eps]: 560.75 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.22 \tCritic Loss: 15.05 \n",
      "\t\tAvg Score [100eps]: 646.37 \t Steps: 2047\n",
      "\n",
      "Episode 270: \tActor Loss: 0.22 \tCritic Loss: 14.46 \n",
      "\t\tAvg Score [100eps]: 700.70 \t Steps: 2047\n",
      "\n",
      "Episode 280: \tActor Loss: 0.21 \tCritic Loss: 14.07 \n",
      "\t\tAvg Score [100eps]: 678.55 \t Steps: 2047\n",
      "\n",
      "Episode 290: \tActor Loss: 0.20 \tCritic Loss: 13.44 \n",
      "\t\tAvg Score [100eps]: 558.41 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.21 \tCritic Loss: 13.05 \n",
      "\t\tAvg Score [100eps]: 732.73 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.21 \tCritic Loss: 12.68 \n",
      "\t\tAvg Score [100eps]: 624.57 \t Steps: 2047\n",
      "\n",
      "Episode 320: \tActor Loss: 0.20 \tCritic Loss: 12.41 \n",
      "\t\tAvg Score [100eps]: 684.71 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.15 \tCritic Loss: 12.46 \n",
      "\t\tAvg Score [100eps]: 701.01 \t Steps: 2047\n",
      "\n",
      "Episode 340: \tActor Loss: 0.13 \tCritic Loss: 12.71 \n",
      "\t\tAvg Score [100eps]: 799.20 \t Steps: 2047\n",
      "\n",
      "Episode 350: \tActor Loss: 0.13 \tCritic Loss: 12.85 \n",
      "\t\tAvg Score [100eps]: 856.80 \t Steps: 2047\n",
      "\n",
      "Episode 360: \tActor Loss: 0.13 \tCritic Loss: 12.78 \n",
      "\t\tAvg Score [100eps]: 810.62 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.14 \tCritic Loss: 12.71 \n",
      "\t\tAvg Score [100eps]: 870.01 \t Steps: 2047\n",
      "\n",
      "Episode 380: \tActor Loss: 0.14 \tCritic Loss: 12.86 \n",
      "\t\tAvg Score [100eps]: 888.47 \t Steps: 2047\n",
      "\n",
      "Episode 390: \tActor Loss: 0.14 \tCritic Loss: 12.95 \n",
      "\t\tAvg Score [100eps]: 741.70 \t Steps: 2047\n",
      "\n",
      "Episode 400: \tActor Loss: 0.12 \tCritic Loss: 12.91 \n",
      "\t\tAvg Score [100eps]: 799.06 \t Steps: 1000\n",
      "\n",
      "Episode 410: \tActor Loss: 0.11 \tCritic Loss: 13.00 \n",
      "\t\tAvg Score [100eps]: 905.98 \t Steps: 2047\n",
      "\n",
      "Episode 420: \tActor Loss: 0.13 \tCritic Loss: 13.03 \n",
      "\t\tAvg Score [100eps]: 940.32 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.13 \tCritic Loss: 12.93 \n",
      "\t\tAvg Score [100eps]: 918.55 \t Steps: 2047\n",
      "\n",
      "Episode 440: \tActor Loss: 0.14 \tCritic Loss: 12.81 \n",
      "\t\tAvg Score [100eps]: 873.30 \t Steps: 2047\n",
      "\n",
      "Episode 450: \tActor Loss: 0.13 \tCritic Loss: 12.67 \n",
      "\t\tAvg Score [100eps]: 936.74 \t Steps: 1000\n",
      "\n",
      "Episode 460: \tActor Loss: 0.13 \tCritic Loss: 12.65 \n",
      "\t\tAvg Score [100eps]: 979.89 \t Steps: 1000\n",
      "\n",
      "Episode 470: \tActor Loss: 0.13 \tCritic Loss: 12.70 7\n",
      "\t\tAvg Score [100eps]: 1030.96 \t Steps: 2047\n",
      "\n",
      "Episode 480: \tActor Loss: 0.13 \tCritic Loss: 12.56 7\n",
      "\t\tAvg Score [100eps]: 1026.60 \t Steps: 2047\n",
      "\n",
      "Episode 490: \tActor Loss: 0.13 \tCritic Loss: 12.60 7\n",
      "\t\tAvg Score [100eps]: 1071.68 \t Steps: 2047\n",
      "\n",
      "Episode 500: \tActor Loss: 0.13 \tCritic Loss: 12.62 7\n",
      "\t\tAvg Score [100eps]: 1024.99 \t Steps: 2047\n",
      "\n",
      "Episode 510: \tActor Loss: 0.13 \tCritic Loss: 12.52 7\n",
      "\t\tAvg Score [100eps]: 988.67 \t Steps: 2047\n",
      "\n",
      "Episode 520: \tActor Loss: 0.11 \tCritic Loss: 12.48 7\n",
      "\t\tAvg Score [100eps]: 908.10 \t Steps: 2047\n",
      "\n",
      "Episode 530: \tActor Loss: 0.11 \tCritic Loss: 12.34 7\n",
      "\t\tAvg Score [100eps]: 842.13 \t Steps: 2047\n",
      "\n",
      "Episode 540: \tActor Loss: 0.10 \tCritic Loss: 12.17 \n",
      "\t\tAvg Score [100eps]: 868.22 \t Steps: 2047\n",
      "\n",
      "Episode 550: \tActor Loss: 0.11 \tCritic Loss: 12.22 7\n",
      "\t\tAvg Score [100eps]: 1013.86 \t Steps: 2047\n",
      "\n",
      "Episode 560: \tActor Loss: 0.11 \tCritic Loss: 11.84 \n",
      "\t\tAvg Score [100eps]: 794.72 \t Steps: 2047\n",
      "\n",
      "Episode 570: \tActor Loss: 0.11 \tCritic Loss: 11.47 7\n",
      "\t\tAvg Score [100eps]: 960.72 \t Steps: 2047\n",
      "\n",
      "Episode 580: \tActor Loss: 0.11 \tCritic Loss: 11.19 \n",
      "\t\tAvg Score [100eps]: 842.91 \t Steps: 2047\n",
      "\n",
      "Episode 590: \tActor Loss: 0.11 \tCritic Loss: 10.94 \n",
      "\t\tAvg Score [100eps]: 863.17 \t Steps: 2047\n",
      "\n",
      "Episode 600: \tActor Loss: 0.11 \tCritic Loss: 10.48 \n",
      "\t\tAvg Score [100eps]: 732.05 \t Steps: 2047\n",
      "\n",
      "Episode 610: \tActor Loss: 0.12 \tCritic Loss: 10.18 \n",
      "\t\tAvg Score [100eps]: 921.33 \t Steps: 2047\n",
      "\n",
      "Episode 620: \tActor Loss: 0.12 \tCritic Loss: 10.02 7\n",
      "\t\tAvg Score [100eps]: 1005.56 \t Steps: 2047\n",
      "\n",
      "Episode 630: \tActor Loss: 0.12 \tCritic Loss: 9.87 77\n",
      "\t\tAvg Score [100eps]: 865.62 \t Steps: 2047\n",
      "\n",
      "Episode 640: \tActor Loss: 0.12 \tCritic Loss: 9.58 7\n",
      "\t\tAvg Score [100eps]: 977.42 \t Steps: 2047\n",
      "\n",
      "Episode 650: \tActor Loss: 0.12 \tCritic Loss: 9.18 47\n",
      "\t\tAvg Score [100eps]: 1097.22 \t Steps: 2047\n",
      "\n",
      "Episode 660: \tActor Loss: 0.13 \tCritic Loss: 9.14 47\n",
      "\t\tAvg Score [100eps]: 1053.59 \t Steps: 2047\n",
      "\n",
      "Episode 670: \tActor Loss: 0.13 \tCritic Loss: 9.02 77\n",
      "\t\tAvg Score [100eps]: 914.52 \t Steps: 2047\n",
      "\n",
      "Episode 680: \tActor Loss: 0.13 \tCritic Loss: 8.80 47\n",
      "\t\tAvg Score [100eps]: 1050.83 \t Steps: 2047\n",
      "\n",
      "Episode 690: \tActor Loss: 0.54 \tCritic Loss: 8.52 77\n",
      "\t\tAvg Score [100eps]: 937.44 \t Steps: 2047\n",
      "\n",
      "Episode 700: \tActor Loss: 0.54 \tCritic Loss: 8.45 77\n",
      "\t\tAvg Score [100eps]: 999.72 \t Steps: 2047\n",
      "\n",
      "Episode 710: \tActor Loss: 0.54 \tCritic Loss: 8.34 47\n",
      "\t\tAvg Score [100eps]: 1247.00 \t Steps: 2047\n",
      "\n",
      "Episode 720: \tActor Loss: 0.55 \tCritic Loss: 7.87 77\n",
      "\t\tAvg Score [100eps]: 594.52 \t Steps: 2047\n",
      "\n",
      "Episode 730: \tActor Loss: 0.56 \tCritic Loss: 7.75 47\n",
      "\t\tAvg Score [100eps]: 1255.05 \t Steps: 2047\n",
      "\n",
      "Episode 740: \tActor Loss: 0.57 \tCritic Loss: 7.68 77\n",
      "\t\tAvg Score [100eps]: 416.57 \t Steps: 2047\n",
      "\n",
      "Episode 750: \tActor Loss: 0.58 \tCritic Loss: 8.13 7\n",
      "\t\tAvg Score [100eps]: 163.80 \t Steps: 2047\n",
      "\n",
      "Episode 751\t Score [This Eps]: 160.44 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 757\t Score [This Eps]: 174.97 \t Steps: 2047"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# Set all params decay rate (except for LR to be 1.0 - don't decay)\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.gae_tau = 0.90\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-04--20:46:04 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.15 \n",
      "\t\tAvg Score [100eps]: 31.05 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.06 \tCritic Loss: 0.48 7\n",
      "\t\tAvg Score [100eps]: 162.32 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.11 \tCritic Loss: 1.50 7\n",
      "\t\tAvg Score [100eps]: 243.61 \t Steps: 2047\n",
      "\n",
      "Episode 40: \tActor Loss: 0.15 \tCritic Loss: 2.31 7\n",
      "\t\tAvg Score [100eps]: 275.90 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.16 \tCritic Loss: 2.64 7\n",
      "\t\tAvg Score [100eps]: 297.37 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.16 \tCritic Loss: 3.12 7\n",
      "\t\tAvg Score [100eps]: 291.75 \t Steps: 2047\n",
      "\n",
      "Episode 70: \tActor Loss: 0.17 \tCritic Loss: 3.50 7\n",
      "\t\tAvg Score [100eps]: 355.76 \t Steps: 2047\n",
      "\n",
      "NaN next_states Found! Skipping this episode.\n",
      "Episode 80: \tActor Loss: 0.17 \tCritic Loss: 3.60 7\n",
      "\t\tAvg Score [100eps]: 296.86 \t Steps: 2047\n",
      "\n",
      "Episode 90: \tActor Loss: 0.17 \tCritic Loss: 3.81 7\n",
      "\t\tAvg Score [100eps]: 349.26 \t Steps: 2047\n",
      "\n",
      "Episode 100: \tActor Loss: 0.17 \tCritic Loss: 3.99 7\n",
      "\t\tAvg Score [100eps]: 408.44 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.18 \tCritic Loss: 4.54 7\n",
      "\t\tAvg Score [100eps]: 432.13 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.19 \tCritic Loss: 5.06 7\n",
      "\t\tAvg Score [100eps]: 446.99 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.19 \tCritic Loss: 5.34 7\n",
      "\t\tAvg Score [100eps]: 483.24 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.18 \tCritic Loss: 5.43 7\n",
      "\t\tAvg Score [100eps]: 496.91 \t Steps: 2047\n",
      "\n",
      "Episode 150: \tActor Loss: 0.18 \tCritic Loss: 5.63 7\n",
      "\t\tAvg Score [100eps]: 481.74 \t Steps: 2047\n",
      "\n",
      "Episode 160: \tActor Loss: 0.17 \tCritic Loss: 5.65 7\n",
      "\t\tAvg Score [100eps]: 512.44 \t Steps: 2047\n",
      "\n",
      "Episode 170: \tActor Loss: 0.17 \tCritic Loss: 5.61 7\n",
      "\t\tAvg Score [100eps]: 528.30 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.16 \tCritic Loss: 5.69 7\n",
      "\t\tAvg Score [100eps]: 520.81 \t Steps: 2047\n",
      "\n",
      "Episode 190: \tActor Loss: 0.16 \tCritic Loss: 5.68 7\n",
      "\t\tAvg Score [100eps]: 518.39 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.16 \tCritic Loss: 5.65 7\n",
      "\t\tAvg Score [100eps]: 536.85 \t Steps: 2047\n",
      "\n",
      "Episode 210: \tActor Loss: 0.15 \tCritic Loss: 5.48 7\n",
      "\t\tAvg Score [100eps]: 482.34 \t Steps: 2047\n",
      "\n",
      "Episode 220: \tActor Loss: 0.15 \tCritic Loss: 5.35 7\n",
      "\t\tAvg Score [100eps]: 535.29 \t Steps: 2047\n",
      "\n",
      "Episode 230: \tActor Loss: 0.15 \tCritic Loss: 5.12 7\n",
      "\t\tAvg Score [100eps]: 572.71 \t Steps: 2047\n",
      "\n",
      "Episode 240: \tActor Loss: 0.25 \tCritic Loss: 4.95 7\n",
      "\t\tAvg Score [100eps]: 622.76 \t Steps: 2047\n",
      "\n",
      "Episode 250: \tActor Loss: 0.25 \tCritic Loss: 4.74 7\n",
      "\t\tAvg Score [100eps]: 593.38 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.26 \tCritic Loss: 4.50 7\n",
      "\t\tAvg Score [100eps]: 593.18 \t Steps: 2047\n",
      "\n",
      "Episode 270: \tActor Loss: 0.26 \tCritic Loss: 4.29 7\n",
      "\t\tAvg Score [100eps]: 625.66 \t Steps: 2047\n",
      "\n",
      "Episode 280: \tActor Loss: 0.28 \tCritic Loss: 4.10 7\n",
      "\t\tAvg Score [100eps]: 573.75 \t Steps: 2047\n",
      "\n",
      "Episode 290: \tActor Loss: 0.28 \tCritic Loss: 3.92 7\n",
      "\t\tAvg Score [100eps]: 628.05 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.30 \tCritic Loss: 3.78 7\n",
      "\t\tAvg Score [100eps]: 695.27 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.30 \tCritic Loss: 3.73 7\n",
      "\t\tAvg Score [100eps]: 603.04 \t Steps: 2047\n",
      "\n",
      "Episode 320: \tActor Loss: 0.30 \tCritic Loss: 3.59 7\n",
      "\t\tAvg Score [100eps]: 618.49 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.30 \tCritic Loss: 3.60 7\n",
      "\t\tAvg Score [100eps]: 732.43 \t Steps: 2047\n",
      "\n",
      "Episode 340: \tActor Loss: 0.21 \tCritic Loss: 3.57 0\n",
      "\t\tAvg Score [100eps]: 719.65 \t Steps: 1000\n",
      "\n",
      "Episode 350: \tActor Loss: 0.20 \tCritic Loss: 3.48 7\n",
      "\t\tAvg Score [100eps]: 722.50 \t Steps: 2047\n",
      "\n",
      "Episode 360: \tActor Loss: 0.20 \tCritic Loss: 3.51 7\n",
      "\t\tAvg Score [100eps]: 809.54 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.21 \tCritic Loss: 3.54 7\n",
      "\t\tAvg Score [100eps]: 768.77 \t Steps: 2047\n",
      "\n",
      "Episode 380: \tActor Loss: 0.20 \tCritic Loss: 3.46 7\n",
      "\t\tAvg Score [100eps]: 796.19 \t Steps: 2047\n",
      "\n",
      "Episode 384\t Score [This Eps]: 820.55 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 390: \tActor Loss: 0.30 \tCritic Loss: 3.45 7\n",
      "\t\tAvg Score [100eps]: 848.60 \t Steps: 2047\n",
      "\n",
      "Episode 400: \tActor Loss: 0.29 \tCritic Loss: 3.37 7\n",
      "\t\tAvg Score [100eps]: 817.81 \t Steps: 2047\n",
      "\n",
      "Episode 410: \tActor Loss: 0.28 \tCritic Loss: 3.34 7\n",
      "\t\tAvg Score [100eps]: 864.86 \t Steps: 2047\n",
      "\n",
      "Episode 420: \tActor Loss: 0.29 \tCritic Loss: 3.33 7\n",
      "\t\tAvg Score [100eps]: 870.04 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.28 \tCritic Loss: 3.24 7\n",
      "\t\tAvg Score [100eps]: 833.96 \t Steps: 2047\n",
      "\n",
      "Episode 440: \tActor Loss: 0.28 \tCritic Loss: 3.13 7\n",
      "\t\tAvg Score [100eps]: 920.20 \t Steps: 2047\n",
      "\n",
      "Episode 450: \tActor Loss: 0.29 \tCritic Loss: 3.19 7\n",
      "\t\tAvg Score [100eps]: 949.80 \t Steps: 2047\n",
      "\n",
      "Episode 460: \tActor Loss: 0.29 \tCritic Loss: 3.22 00\n",
      "\t\tAvg Score [100eps]: 1002.82 \t Steps: 1000\n",
      "\n",
      "Episode 470: \tActor Loss: 0.27 \tCritic Loss: 3.17 70\n",
      "\t\tAvg Score [100eps]: 957.83 \t Steps: 2047\n",
      "\n",
      "Episode 480: \tActor Loss: 0.27 \tCritic Loss: 3.21 77\n",
      "\t\tAvg Score [100eps]: 983.88 \t Steps: 2047\n",
      "\n",
      "Episode 490: \tActor Loss: 0.17 \tCritic Loss: 3.10 7\n",
      "\t\tAvg Score [100eps]: 962.85 \t Steps: 2047\n",
      "\n",
      "Episode 500: \tActor Loss: 0.17 \tCritic Loss: 3.06 47\n",
      "\t\tAvg Score [100eps]: 1014.62 \t Steps: 2047\n",
      "\n",
      "Episode 510: \tActor Loss: 0.18 \tCritic Loss: 2.90 47\n",
      "\t\tAvg Score [100eps]: 1057.20 \t Steps: 2047\n",
      "\n",
      "Episode 520: \tActor Loss: 0.17 \tCritic Loss: 2.78 77\n",
      "\t\tAvg Score [100eps]: 995.27 \t Steps: 2047\n",
      "\n",
      "Episode 530: \tActor Loss: 0.17 \tCritic Loss: 2.75 47\n",
      "\t\tAvg Score [100eps]: 1044.23 \t Steps: 2047\n",
      "\n",
      "Episode 540: \tActor Loss: 0.18 \tCritic Loss: 2.83 77\n",
      "\t\tAvg Score [100eps]: 982.32 \t Steps: 2047\n",
      "\n",
      "Episode 550: \tActor Loss: 0.17 \tCritic Loss: 2.80 77\n",
      "\t\tAvg Score [100eps]: 979.25 \t Steps: 2047\n",
      "\n",
      "Episode 560: \tActor Loss: 0.18 \tCritic Loss: 2.66 47\n",
      "\t\tAvg Score [100eps]: 1065.89 \t Steps: 2047\n",
      "\n",
      "Episode 570: \tActor Loss: 0.18 \tCritic Loss: 2.68 77\n",
      "\t\tAvg Score [100eps]: 983.73 \t Steps: 2047\n",
      "\n",
      "Episode 580: \tActor Loss: 0.18 \tCritic Loss: 2.60 77\n",
      "\t\tAvg Score [100eps]: 999.56 \t Steps: 2047\n",
      "\n",
      "Episode 590: \tActor Loss: 0.18 \tCritic Loss: 2.66 47\n",
      "\t\tAvg Score [100eps]: 1036.03 \t Steps: 2047\n",
      "\n",
      "Episode 600: \tActor Loss: 0.18 \tCritic Loss: 2.67 47\n",
      "\t\tAvg Score [100eps]: 1090.04 \t Steps: 2047\n",
      "\n",
      "Episode 610: \tActor Loss: 0.20 \tCritic Loss: 2.74 47\n",
      "\t\tAvg Score [100eps]: 1043.58 \t Steps: 2047\n",
      "\n",
      "Episode 620: \tActor Loss: 0.20 \tCritic Loss: 2.83 47\n",
      "\t\tAvg Score [100eps]: 1084.50 \t Steps: 2047\n",
      "\n",
      "Episode 630: \tActor Loss: 0.20 \tCritic Loss: 2.87 00\n",
      "\t\tAvg Score [100eps]: 1099.37 \t Steps: 1000\n",
      "\n",
      "Episode 640: \tActor Loss: 0.20 \tCritic Loss: 2.84 47\n",
      "\t\tAvg Score [100eps]: 1198.66 \t Steps: 2047\n",
      "\n",
      "Episode 650: \tActor Loss: 0.21 \tCritic Loss: 2.76 47\n",
      "\t\tAvg Score [100eps]: 1166.81 \t Steps: 2047\n",
      "\n",
      "Episode 660: \tActor Loss: 0.20 \tCritic Loss: 2.90 00\n",
      "\t\tAvg Score [100eps]: 1258.94 \t Steps: 1000\n",
      "\n",
      "Episode 670: \tActor Loss: 0.21 \tCritic Loss: 2.98 47\n",
      "\t\tAvg Score [100eps]: 1268.61 \t Steps: 2047\n",
      "\n",
      "Episode 680: \tActor Loss: 0.20 \tCritic Loss: 3.24 47\n",
      "\t\tAvg Score [100eps]: 1240.46 \t Steps: 2047\n",
      "\n",
      "Episode 690: \tActor Loss: 0.20 \tCritic Loss: 3.28 47\n",
      "\t\tAvg Score [100eps]: 1215.81 \t Steps: 2047\n",
      "\n",
      "Episode 700: \tActor Loss: 0.20 \tCritic Loss: 3.23 47\n",
      "\t\tAvg Score [100eps]: 1234.93 \t Steps: 2047\n",
      "\n",
      "Episode 710: \tActor Loss: 0.19 \tCritic Loss: 3.20 47\n",
      "\t\tAvg Score [100eps]: 1197.10 \t Steps: 2047\n",
      "\n",
      "Episode 720: \tActor Loss: 0.19 \tCritic Loss: 3.24 47\n",
      "\t\tAvg Score [100eps]: 1280.91 \t Steps: 2047\n",
      "\n",
      "Episode 730: \tActor Loss: 0.19 \tCritic Loss: 3.26 47\n",
      "\t\tAvg Score [100eps]: 1261.04 \t Steps: 2047\n",
      "\n",
      "Episode 740: \tActor Loss: 0.19 \tCritic Loss: 3.23 47\n",
      "\t\tAvg Score [100eps]: 1315.97 \t Steps: 2047\n",
      "\n",
      "Episode 750: \tActor Loss: 0.19 \tCritic Loss: 3.57 00\n",
      "\t\tAvg Score [100eps]: 1406.04 \t Steps: 1000\n",
      "\n",
      "Episode 760: \tActor Loss: 0.20 \tCritic Loss: 3.60 47\n",
      "\t\tAvg Score [100eps]: 1333.72 \t Steps: 2047\n",
      "\n",
      "Episode 770: \tActor Loss: 0.21 \tCritic Loss: 3.39 47\n",
      "\t\tAvg Score [100eps]: 1033.64 \t Steps: 2047\n",
      "\n",
      "Episode 780: \tActor Loss: 0.22 \tCritic Loss: 3.18 77\n",
      "\t\tAvg Score [100eps]: 952.84 \t Steps: 2047\n",
      "\n",
      "Episode 790: \tActor Loss: 0.23 \tCritic Loss: 3.20 47\n",
      "\t\tAvg Score [100eps]: 1144.46 \t Steps: 2047\n",
      "\n",
      "Episode 800: \tActor Loss: 0.23 \tCritic Loss: 3.21 47\n",
      "\t\tAvg Score [100eps]: 1189.09 \t Steps: 2047\n",
      "\n",
      "Episode 810: \tActor Loss: 0.24 \tCritic Loss: 3.17 00\n",
      "\t\tAvg Score [100eps]: 1144.85 \t Steps: 1000\n",
      "\n",
      "Episode 820: \tActor Loss: 0.24 \tCritic Loss: 3.28 47\n",
      "\t\tAvg Score [100eps]: 1284.39 \t Steps: 2047\n",
      "\n",
      "Episode 830: \tActor Loss: 0.25 \tCritic Loss: 3.38 00\n",
      "\t\tAvg Score [100eps]: 1319.56 \t Steps: 1000\n",
      "\n",
      "Episode 840: \tActor Loss: 0.25 \tCritic Loss: 3.36 47\n",
      "\t\tAvg Score [100eps]: 1311.99 \t Steps: 2047\n",
      "\n",
      "Episode 850: \tActor Loss: 0.25 \tCritic Loss: 2.95 47\n",
      "\t\tAvg Score [100eps]: 1304.02 \t Steps: 2047\n",
      "\n",
      "Episode 860: \tActor Loss: 0.25 \tCritic Loss: 2.70 00\n",
      "\t\tAvg Score [100eps]: 1240.43 \t Steps: 1000\n",
      "\n",
      "Episode 870: \tActor Loss: 0.25 \tCritic Loss: 2.78 00\n",
      "\t\tAvg Score [100eps]: 1284.36 \t Steps: 1000\n",
      "\n",
      "Episode 880: \tActor Loss: 0.25 \tCritic Loss: 3.11 00\n",
      "\t\tAvg Score [100eps]: 1400.95 \t Steps: 1000\n",
      "\n",
      "Episode 890: \tActor Loss: 0.26 \tCritic Loss: 3.17 47\n",
      "\t\tAvg Score [100eps]: 1082.43 \t Steps: 2047\n",
      "\n",
      "Episode 900: \tActor Loss: 0.27 \tCritic Loss: 3.18 47\n",
      "\t\tAvg Score [100eps]: 1117.26 \t Steps: 2047\n",
      "\n",
      "Episode 910: \tActor Loss: 0.28 \tCritic Loss: 3.44 00\n",
      "\t\tAvg Score [100eps]: 1343.44 \t Steps: 1000\n",
      "\n",
      "Episode 920: \tActor Loss: 0.28 \tCritic Loss: 3.32 47\n",
      "\t\tAvg Score [100eps]: 1384.47 \t Steps: 2047\n",
      "\n",
      "Episode 930: \tActor Loss: 0.29 \tCritic Loss: 3.22 00\n",
      "\t\tAvg Score [100eps]: 1410.91 \t Steps: 1000\n",
      "\n",
      "Episode 940: \tActor Loss: 0.29 \tCritic Loss: 3.17 00\n",
      "\t\tAvg Score [100eps]: 1386.55 \t Steps: 1000\n",
      "\n",
      "Episode 950: \tActor Loss: 0.31 \tCritic Loss: 3.22 00\n",
      "\t\tAvg Score [100eps]: 1410.73 \t Steps: 1000\n",
      "\n",
      "Episode 960: \tActor Loss: 0.31 \tCritic Loss: 3.44 00\n",
      "\t\tAvg Score [100eps]: 1464.11 \t Steps: 1000\n",
      "\n",
      "Episode 970: \tActor Loss: 0.31 \tCritic Loss: 3.43 47\n",
      "\t\tAvg Score [100eps]: 1264.16 \t Steps: 2047\n",
      "\n",
      "Episode 980: \tActor Loss: 0.32 \tCritic Loss: 3.05 47\n",
      "\t\tAvg Score [100eps]: 1270.97 \t Steps: 2047\n",
      "\n",
      "Episode 990: \tActor Loss: 0.32 \tCritic Loss: 2.97 77\n",
      "\t\tAvg Score [100eps]: 989.29 \t Steps: 2047\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.33 \tCritic Loss: 3.07 47\n",
      "\t\tAvg Score [100eps]: 1064.98 \t Steps: 2047\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.33 \tCritic Loss: 2.82 47\n",
      "\t\tAvg Score [100eps]: 1019.91 \t Steps: 2047\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.34 \tCritic Loss: 2.78 47\n",
      "\t\tAvg Score [100eps]: 1136.16 \t Steps: 2047\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.35 \tCritic Loss: 2.63 00\n",
      "\t\tAvg Score [100eps]: 1144.98 \t Steps: 1000\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.35 \tCritic Loss: 2.61 47\n",
      "\t\tAvg Score [100eps]: 1358.35 \t Steps: 2047\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.36 \tCritic Loss: 2.58 47\n",
      "\t\tAvg Score [100eps]: 1132.32 \t Steps: 2047\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.37 \tCritic Loss: 2.44 47\n",
      "\t\tAvg Score [100eps]: 1059.20 \t Steps: 2047\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.37 \tCritic Loss: 2.41 47\n",
      "\t\tAvg Score [100eps]: 1243.11 \t Steps: 2047\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.38 \tCritic Loss: 2.32 47\n",
      "\t\tAvg Score [100eps]: 1187.85 \t Steps: 2047\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.38 \tCritic Loss: 2.15 47\n",
      "\t\tAvg Score [100eps]: 1104.98 \t Steps: 2047\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.38 \tCritic Loss: 2.12 77\n",
      "\t\tAvg Score [100eps]: 922.47 \t Steps: 2047\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.39 \tCritic Loss: 2.13 00\n",
      "\t\tAvg Score [100eps]: 1127.97 \t Steps: 1000\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.39 \tCritic Loss: 1.96 47\n",
      "\t\tAvg Score [100eps]: 1198.65 \t Steps: 2047\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.39 \tCritic Loss: 2.05 00\n",
      "\t\tAvg Score [100eps]: 1224.26 \t Steps: 1000\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.40 \tCritic Loss: 2.00 00\n",
      "\t\tAvg Score [100eps]: 1073.35 \t Steps: 1000\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.42 \tCritic Loss: 2.07 77\n",
      "\t\tAvg Score [100eps]: 670.86 \t Steps: 2047\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.42 \tCritic Loss: 2.47 7\n",
      "\t\tAvg Score [100eps]: 174.29 \t Steps: 2047\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.43 \tCritic Loss: 3.02 7\n",
      "\t\tAvg Score [100eps]: 153.04 \t Steps: 2047\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.43 \tCritic Loss: 3.36 7\n",
      "\t\tAvg Score [100eps]: 141.59 \t Steps: 2047\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.44 \tCritic Loss: 3.52 7\n",
      "\t\tAvg Score [100eps]: 112.76 \t Steps: 2047\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.44 \tCritic Loss: 3.42 7\n",
      "\t\tAvg Score [100eps]: 147.76 \t Steps: 2047\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.44 \tCritic Loss: 3.41 7\n",
      "\t\tAvg Score [100eps]: 170.34 \t Steps: 2047\n",
      "\n",
      "Episode 1213\t Score [This Eps]: 246.55 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 1220: \tActor Loss: 0.48 \tCritic Loss: 3.53 7\n",
      "\t\tAvg Score [100eps]: 534.01 \t Steps: 2047\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.49 \tCritic Loss: 3.54 7\n",
      "\t\tAvg Score [100eps]: 449.27 \t Steps: 2047\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.49 \tCritic Loss: 3.66 7\n",
      "\t\tAvg Score [100eps]: 334.10 \t Steps: 2047\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.49 \tCritic Loss: 3.69 0\n",
      "\t\tAvg Score [100eps]: 992.95 \t Steps: 1000\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.47 \tCritic Loss: 3.49 00\n",
      "\t\tAvg Score [100eps]: 1171.66 \t Steps: 1000\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.47 \tCritic Loss: 3.06 70\n",
      "\t\tAvg Score [100eps]: 834.63 \t Steps: 2047\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.47 \tCritic Loss: 2.89 7\n",
      "\t\tAvg Score [100eps]: 457.51 \t Steps: 2047\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.47 \tCritic Loss: 2.74 7\n",
      "\t\tAvg Score [100eps]: 736.16 \t Steps: 2047\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.47 \tCritic Loss: 2.65 0\n",
      "\t\tAvg Score [100eps]: 866.43 \t Steps: 1000\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.47 \tCritic Loss: 2.72 7\n",
      "\t\tAvg Score [100eps]: 265.79 \t Steps: 2047\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.43 \tCritic Loss: 2.59 0\n",
      "\t\tAvg Score [100eps]: 728.25 \t Steps: 1000\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.43 \tCritic Loss: 2.47 0\n",
      "\t\tAvg Score [100eps]: 873.68 \t Steps: 1000\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.43 \tCritic Loss: 2.32 0\n",
      "\t\tAvg Score [100eps]: 916.76 \t Steps: 1000\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.42 \tCritic Loss: 2.16 0\n",
      "\t\tAvg Score [100eps]: 910.50 \t Steps: 1000\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.43 \tCritic Loss: 1.83 0\n",
      "\t\tAvg Score [100eps]: 811.23 \t Steps: 1000\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.43 \tCritic Loss: 1.57 7\n",
      "\t\tAvg Score [100eps]: 682.89 \t Steps: 2047\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.43 \tCritic Loss: 1.64 0\n",
      "\t\tAvg Score [100eps]: 506.64 \t Steps: 1000\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.45 \tCritic Loss: 1.62 0\n",
      "\t\tAvg Score [100eps]: 641.82 \t Steps: 1000\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.45 \tCritic Loss: 1.65 0\n",
      "\t\tAvg Score [100eps]: 580.90 \t Steps: 1000\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.46 \tCritic Loss: 1.60 0\n",
      "\t\tAvg Score [100eps]: 534.51 \t Steps: 1000\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.47 \tCritic Loss: 1.79 0\n",
      "\t\tAvg Score [100eps]: 480.93 \t Steps: 1000\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.47 \tCritic Loss: 2.07 0\n",
      "\t\tAvg Score [100eps]: 424.59 \t Steps: 1000\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.47 \tCritic Loss: 2.50 0\n",
      "\t\tAvg Score [100eps]: 363.64 \t Steps: 1000\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.47 \tCritic Loss: 2.70 0\n",
      "\t\tAvg Score [100eps]: 462.98 \t Steps: 1000\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.47 \tCritic Loss: 2.88 0\n",
      "\t\tAvg Score [100eps]: 419.88 \t Steps: 1000\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.47 \tCritic Loss: 3.01 7\n",
      "\t\tAvg Score [100eps]: 427.36 \t Steps: 2047\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.49 \tCritic Loss: 2.82 0\n",
      "\t\tAvg Score [100eps]: 416.87 \t Steps: 1000\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.47 \tCritic Loss: 2.84 7\n",
      "\t\tAvg Score [100eps]: 407.95 \t Steps: 2047\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.47 \tCritic Loss: 2.85 7\n",
      "\t\tAvg Score [100eps]: 429.52 \t Steps: 2047\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.47 \tCritic Loss: 2.80 0\n",
      "\t\tAvg Score [100eps]: 411.51 \t Steps: 1000\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.47 \tCritic Loss: 2.67 0\n",
      "\t\tAvg Score [100eps]: 406.51 \t Steps: 1000\n",
      "\n",
      "Episode 1530: \tActor Loss: 0.47 \tCritic Loss: 2.36 0\n",
      "\t\tAvg Score [100eps]: 554.72 \t Steps: 1000\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.48 \tCritic Loss: 1.90 0\n",
      "\t\tAvg Score [100eps]: 643.38 \t Steps: 1000\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.52 \tCritic Loss: 1.64 0\n",
      "\t\tAvg Score [100eps]: 620.65 \t Steps: 1000\n",
      "\n",
      "Episode 1560: \tActor Loss: 0.51 \tCritic Loss: 1.47 0\n",
      "\t\tAvg Score [100eps]: 607.11 \t Steps: 1000\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.50 \tCritic Loss: 1.27 7\n",
      "\t\tAvg Score [100eps]: 560.58 \t Steps: 2047\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.48 \tCritic Loss: 1.11 0\n",
      "\t\tAvg Score [100eps]: 530.38 \t Steps: 1000\n",
      "\n",
      "Episode 1590: \tActor Loss: 0.47 \tCritic Loss: 0.98 0\n",
      "\t\tAvg Score [100eps]: 490.85 \t Steps: 1000\n",
      "\n",
      "Episode 1600: \tActor Loss: 0.47 \tCritic Loss: 0.89 0\n",
      "\t\tAvg Score [100eps]: 597.77 \t Steps: 1000\n",
      "\n",
      "Episode 1610: \tActor Loss: 0.46 \tCritic Loss: 0.81 0\n",
      "\t\tAvg Score [100eps]: 639.51 \t Steps: 1000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1620: \tActor Loss: 0.45 \tCritic Loss: 0.72 0\n",
      "\t\tAvg Score [100eps]: 680.02 \t Steps: 1000\n",
      "\n",
      "Episode 1630: \tActor Loss: 0.44 \tCritic Loss: 0.78 0\n",
      "\t\tAvg Score [100eps]: 753.22 \t Steps: 1000\n",
      "\n",
      "Episode 1640: \tActor Loss: 0.42 \tCritic Loss: 0.80 0\n",
      "\t\tAvg Score [100eps]: 688.38 \t Steps: 1000\n",
      "\n",
      "Episode 1650: \tActor Loss: 0.38 \tCritic Loss: 0.83 0\n",
      "\t\tAvg Score [100eps]: 616.24 \t Steps: 1000\n",
      "\n",
      "Episode 1660: \tActor Loss: 0.38 \tCritic Loss: 0.86 0\n",
      "\t\tAvg Score [100eps]: 635.83 \t Steps: 1000\n",
      "\n",
      "Episode 1670: \tActor Loss: 0.38 \tCritic Loss: 0.90 7\n",
      "\t\tAvg Score [100eps]: 637.35 \t Steps: 2047\n",
      "\n",
      "Episode 1680: \tActor Loss: 0.39 \tCritic Loss: 0.93 7\n",
      "\t\tAvg Score [100eps]: 543.54 \t Steps: 2047\n",
      "\n",
      "Episode 1690: \tActor Loss: 0.39 \tCritic Loss: 0.96 7\n",
      "\t\tAvg Score [100eps]: 573.51 \t Steps: 2047\n",
      "\n",
      "Episode 1700: \tActor Loss: 0.39 \tCritic Loss: 0.95 7\n",
      "\t\tAvg Score [100eps]: 595.06 \t Steps: 2047\n",
      "\n",
      "Episode 1710: \tActor Loss: 0.39 \tCritic Loss: 0.95 7\n",
      "\t\tAvg Score [100eps]: 688.57 \t Steps: 2047\n",
      "\n",
      "Episode 1720: \tActor Loss: 0.38 \tCritic Loss: 1.13 0\n",
      "\t\tAvg Score [100eps]: 782.17 \t Steps: 1000\n",
      "\n",
      "Episode 1730: \tActor Loss: 0.38 \tCritic Loss: 1.22 7\n",
      "\t\tAvg Score [100eps]: 717.64 \t Steps: 2047\n",
      "\n",
      "Episode 1740: \tActor Loss: 0.37 \tCritic Loss: 1.34 7\n",
      "\t\tAvg Score [100eps]: 358.37 \t Steps: 2047\n",
      "\n",
      "Episode 1750: \tActor Loss: 0.37 \tCritic Loss: 1.41 7\n",
      "\t\tAvg Score [100eps]: 385.92 \t Steps: 2047\n",
      "\n",
      "Episode 1760: \tActor Loss: 0.37 \tCritic Loss: 1.48 7\n",
      "\t\tAvg Score [100eps]: 348.99 \t Steps: 2047\n",
      "\n",
      "Episode 1770: \tActor Loss: 0.37 \tCritic Loss: 1.47 7\n",
      "\t\tAvg Score [100eps]: 406.26 \t Steps: 2047\n",
      "\n",
      "Episode 1780: \tActor Loss: 0.35 \tCritic Loss: 1.51 0\n",
      "\t\tAvg Score [100eps]: 556.66 \t Steps: 1000\n",
      "\n",
      "Episode 1790: \tActor Loss: 0.35 \tCritic Loss: 1.51 7\n",
      "\t\tAvg Score [100eps]: 637.05 \t Steps: 2047\n",
      "\n",
      "Episode 1800: \tActor Loss: 0.35 \tCritic Loss: 1.55 7\n",
      "\t\tAvg Score [100eps]: 606.43 \t Steps: 2047\n",
      "\n",
      "Episode 1810: \tActor Loss: 0.35 \tCritic Loss: 1.61 7\n",
      "\t\tAvg Score [100eps]: 648.42 \t Steps: 2047\n",
      "\n",
      "Episode 1820: \tActor Loss: 0.35 \tCritic Loss: 1.44 7\n",
      "\t\tAvg Score [100eps]: 627.95 \t Steps: 2047\n",
      "\n",
      "Episode 1830: \tActor Loss: 0.35 \tCritic Loss: 1.33 7\n",
      "\t\tAvg Score [100eps]: 667.11 \t Steps: 2047\n",
      "\n",
      "Episode 1840: \tActor Loss: 0.35 \tCritic Loss: 1.24 7\n",
      "\t\tAvg Score [100eps]: 658.32 \t Steps: 2047\n",
      "\n",
      "Episode 1850: \tActor Loss: 0.35 \tCritic Loss: 1.25 0\n",
      "\t\tAvg Score [100eps]: 584.45 \t Steps: 1000\n",
      "\n",
      "Episode 1860: \tActor Loss: 0.35 \tCritic Loss: 1.25 7\n",
      "\t\tAvg Score [100eps]: 290.83 \t Steps: 2047\n",
      "\n",
      "Episode 1870: \tActor Loss: 0.34 \tCritic Loss: 1.28 7\n",
      "\t\tAvg Score [100eps]: 466.30 \t Steps: 2047\n",
      "\n",
      "Episode 1880: \tActor Loss: 0.34 \tCritic Loss: 1.33 7\n",
      "\t\tAvg Score [100eps]: 350.75 \t Steps: 2047\n",
      "\n",
      "Episode 1890: \tActor Loss: 0.34 \tCritic Loss: 1.35 7\n",
      "\t\tAvg Score [100eps]: 405.48 \t Steps: 2047\n",
      "\n",
      "Episode 1900: \tActor Loss: 0.34 \tCritic Loss: 1.35 7\n",
      "\t\tAvg Score [100eps]: 322.98 \t Steps: 2047\n",
      "\n",
      "Episode 1910: \tActor Loss: 0.34 \tCritic Loss: 1.33 7\n",
      "\t\tAvg Score [100eps]: 315.75 \t Steps: 2047\n",
      "\n",
      "Episode 1920: \tActor Loss: 0.34 \tCritic Loss: 1.37 7\n",
      "\t\tAvg Score [100eps]: 311.45 \t Steps: 2047\n",
      "\n",
      "Episode 1930: \tActor Loss: 0.33 \tCritic Loss: 1.33 7\n",
      "\t\tAvg Score [100eps]: 344.16 \t Steps: 2047\n",
      "\n",
      "Episode 1940: \tActor Loss: 0.33 \tCritic Loss: 1.44 7\n",
      "\t\tAvg Score [100eps]: 113.53 \t Steps: 2047\n",
      "\n",
      "Episode 1950: \tActor Loss: 0.33 \tCritic Loss: 1.68 7\n",
      "\t\tAvg Score [100eps]: 178.78 \t Steps: 2047\n",
      "\n",
      "Episode 1960: \tActor Loss: 0.33 \tCritic Loss: 1.78 7\n",
      "\t\tAvg Score [100eps]: 107.22 \t Steps: 2047\n",
      "\n",
      "Episode 1966\t Score [This Eps]: 58.76 \t Steps: 20477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-0145d7a6a6a1>\", line 30, in <module>\n",
      "    ppo(params, logger)\n",
      "  File \"<ipython-input-7-c11e12c69666>\", line 27, in ppo\n",
      "    actions, log_probs, _, values = agent.act(states, agent.std_scale)\n",
      "  File \"scripts\\ppo_agent.py\", line 70, in act\n",
      "    action, log_prob, entropy, value = self.ppo_ac_net(state, std_scale=std_scale)  # stdev cannot = 0\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"scripts\\model.py\", line 260, in forward\n",
      "    v = self.critic(s, action)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"scripts\\model.py\", line 235, in forward\n",
      "    s = self.PReLU(self.fc_1s(self.bn_1s(s)))\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 96, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\", line 1847, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0145d7a6a6a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, a)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# state network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# Model min hardtanh = 0.1\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.gae_tau = 0.95\n",
    "params.critic_loss_coeff = 0.25\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-05--08:18:18 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.04 \tCritic Loss: 0.15 \n",
      "\t\tAvg Score [100eps]: 34.50 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.36 \tCritic Loss: 1.01 7\n",
      "\t\tAvg Score [100eps]: 197.72 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.30 \tCritic Loss: 2.28 7\n",
      "\t\tAvg Score [100eps]: 280.55 \t Steps: 2047\n",
      "\n",
      "Episode 40: \tActor Loss: 0.28 \tCritic Loss: 3.26 7\n",
      "\t\tAvg Score [100eps]: 304.62 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.27 \tCritic Loss: 3.74 7\n",
      "\t\tAvg Score [100eps]: 333.04 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.25 \tCritic Loss: 4.03 7\n",
      "\t\tAvg Score [100eps]: 341.50 \t Steps: 2047\n",
      "\n",
      "Episode 70: \tActor Loss: 0.26 \tCritic Loss: 4.34 7\n",
      "\t\tAvg Score [100eps]: 347.73 \t Steps: 2047\n",
      "\n",
      "Episode 80: \tActor Loss: 0.25 \tCritic Loss: 4.64 0\n",
      "\t\tAvg Score [100eps]: 373.42 \t Steps: 1000\n",
      "\n",
      "Episode 90: \tActor Loss: 0.24 \tCritic Loss: 4.80 7\n",
      "\t\tAvg Score [100eps]: 381.90 \t Steps: 2047\n",
      "\n",
      "Episode 100: \tActor Loss: 0.23 \tCritic Loss: 4.98 7\n",
      "\t\tAvg Score [100eps]: 444.98 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.25 \tCritic Loss: 5.52 7\n",
      "\t\tAvg Score [100eps]: 427.07 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.20 \tCritic Loss: 6.00 7\n",
      "\t\tAvg Score [100eps]: 445.63 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.19 \tCritic Loss: 6.23 7\n",
      "\t\tAvg Score [100eps]: 469.74 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.18 \tCritic Loss: 6.31 0\n",
      "\t\tAvg Score [100eps]: 495.75 \t Steps: 1000\n",
      "\n",
      "Episode 150: \tActor Loss: 0.17 \tCritic Loss: 6.40 7\n",
      "\t\tAvg Score [100eps]: 456.76 \t Steps: 2047\n",
      "\n",
      "Episode 156\t Score [This Eps]: 452.42 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 160: \tActor Loss: 0.18 \tCritic Loss: 6.42 7\n",
      "\t\tAvg Score [100eps]: 413.46 \t Steps: 2047\n",
      "\n",
      "Episode 170: \tActor Loss: 0.16 \tCritic Loss: 6.44 7\n",
      "\t\tAvg Score [100eps]: 527.94 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.17 \tCritic Loss: 6.31 7\n",
      "\t\tAvg Score [100eps]: 476.17 \t Steps: 2047\n",
      "\n",
      "Episode 190: \tActor Loss: 0.18 \tCritic Loss: 6.24 7\n",
      "\t\tAvg Score [100eps]: 508.68 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.17 \tCritic Loss: 6.05 0\n",
      "\t\tAvg Score [100eps]: 542.00 \t Steps: 1000\n",
      "\n",
      "Episode 210: \tActor Loss: 0.19 \tCritic Loss: 6.01 7\n",
      "\t\tAvg Score [100eps]: 576.85 \t Steps: 2047\n",
      "\n",
      "Episode 220: \tActor Loss: 0.20 \tCritic Loss: 5.93 7\n",
      "\t\tAvg Score [100eps]: 591.00 \t Steps: 2047\n",
      "\n",
      "Episode 230: \tActor Loss: 0.21 \tCritic Loss: 5.73 7\n",
      "\t\tAvg Score [100eps]: 567.08 \t Steps: 2047\n",
      "\n",
      "Episode 240: \tActor Loss: 0.21 \tCritic Loss: 5.43 7\n",
      "\t\tAvg Score [100eps]: 532.43 \t Steps: 2047\n",
      "\n",
      "Episode 250: \tActor Loss: 0.22 \tCritic Loss: 5.11 7\n",
      "\t\tAvg Score [100eps]: 534.69 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.22 \tCritic Loss: 4.87 7\n",
      "\t\tAvg Score [100eps]: 507.51 \t Steps: 2047\n",
      "\n",
      "Episode 270: \tActor Loss: 0.21 \tCritic Loss: 4.65 7\n",
      "\t\tAvg Score [100eps]: 594.08 \t Steps: 2047\n",
      "\n",
      "Episode 280: \tActor Loss: 0.19 \tCritic Loss: 4.53 7\n",
      "\t\tAvg Score [100eps]: 659.97 \t Steps: 2047\n",
      "\n",
      "Episode 290: \tActor Loss: 0.19 \tCritic Loss: 4.43 7\n",
      "\t\tAvg Score [100eps]: 669.30 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.19 \tCritic Loss: 4.44 7\n",
      "\t\tAvg Score [100eps]: 675.09 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.17 \tCritic Loss: 4.31 7\n",
      "\t\tAvg Score [100eps]: 674.22 \t Steps: 2047\n",
      "\n",
      "Episode 320: \tActor Loss: 0.15 \tCritic Loss: 4.16 7\n",
      "\t\tAvg Score [100eps]: 666.86 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.15 \tCritic Loss: 4.05 7\n",
      "\t\tAvg Score [100eps]: 691.55 \t Steps: 2047\n",
      "\n",
      "Episode 340: \tActor Loss: 0.14 \tCritic Loss: 4.02 7\n",
      "\t\tAvg Score [100eps]: 707.00 \t Steps: 2047\n",
      "\n",
      "Episode 350: \tActor Loss: 0.13 \tCritic Loss: 4.12 7\n",
      "\t\tAvg Score [100eps]: 744.74 \t Steps: 2047\n",
      "\n",
      "Episode 360: \tActor Loss: 0.12 \tCritic Loss: 4.14 7\n",
      "\t\tAvg Score [100eps]: 696.22 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.12 \tCritic Loss: 4.21 7\n",
      "\t\tAvg Score [100eps]: 798.82 \t Steps: 2047\n",
      "\n",
      "Episode 374\t Score [This Eps]: 789.64 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 380: \tActor Loss: 0.12 \tCritic Loss: 4.19 7\n",
      "\t\tAvg Score [100eps]: 791.39 \t Steps: 2047\n",
      "\n",
      "Episode 390: \tActor Loss: 0.12 \tCritic Loss: 4.15 7\n",
      "\t\tAvg Score [100eps]: 843.63 \t Steps: 2047\n",
      "\n",
      "Episode 400: \tActor Loss: 0.12 \tCritic Loss: 4.10 7\n",
      "\t\tAvg Score [100eps]: 865.45 \t Steps: 2047\n",
      "\n",
      "Episode 410: \tActor Loss: 0.13 \tCritic Loss: 4.13 0\n",
      "\t\tAvg Score [100eps]: 857.46 \t Steps: 1000\n",
      "\n",
      "Episode 420: \tActor Loss: 0.12 \tCritic Loss: 4.15 7\n",
      "\t\tAvg Score [100eps]: 863.13 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.12 \tCritic Loss: 4.20 7\n",
      "\t\tAvg Score [100eps]: 934.80 \t Steps: 2047\n",
      "\n",
      "Episode 440: \tActor Loss: 0.12 \tCritic Loss: 4.28 7\n",
      "\t\tAvg Score [100eps]: 937.92 \t Steps: 2047\n",
      "\n",
      "Episode 450: \tActor Loss: 0.12 \tCritic Loss: 4.32 47\n",
      "\t\tAvg Score [100eps]: 1002.69 \t Steps: 2047\n",
      "\n",
      "Episode 460: \tActor Loss: 0.12 \tCritic Loss: 4.37 0\n",
      "\t\tAvg Score [100eps]: 994.30 \t Steps: 1000\n",
      "\n",
      "Episode 470: \tActor Loss: 0.12 \tCritic Loss: 4.40 47\n",
      "\t\tAvg Score [100eps]: 1003.27 \t Steps: 2047\n",
      "\n",
      "Episode 480: \tActor Loss: 0.12 \tCritic Loss: 4.47 00\n",
      "\t\tAvg Score [100eps]: 1025.66 \t Steps: 1000\n",
      "\n",
      "Episode 490: \tActor Loss: 0.12 \tCritic Loss: 4.52 77\n",
      "\t\tAvg Score [100eps]: 925.19 \t Steps: 2047\n",
      "\n",
      "Episode 500: \tActor Loss: 0.12 \tCritic Loss: 4.55 77\n",
      "\t\tAvg Score [100eps]: 946.76 \t Steps: 2047\n",
      "\n",
      "Episode 510: \tActor Loss: 0.11 \tCritic Loss: 4.54 7\n",
      "\t\tAvg Score [100eps]: 942.80 \t Steps: 2047\n",
      "\n",
      "Episode 520: \tActor Loss: 0.11 \tCritic Loss: 4.50 47\n",
      "\t\tAvg Score [100eps]: 1047.92 \t Steps: 2047\n",
      "\n",
      "Episode 530: \tActor Loss: 0.10 \tCritic Loss: 4.49 47\n",
      "\t\tAvg Score [100eps]: 1094.80 \t Steps: 2047\n",
      "\n",
      "Episode 540: \tActor Loss: 0.11 \tCritic Loss: 4.46 47\n",
      "\t\tAvg Score [100eps]: 1048.83 \t Steps: 2047\n",
      "\n",
      "Episode 550: \tActor Loss: 0.11 \tCritic Loss: 4.37 47\n",
      "\t\tAvg Score [100eps]: 1108.94 \t Steps: 2047\n",
      "\n",
      "Episode 560: \tActor Loss: 0.11 \tCritic Loss: 4.41 47\n",
      "\t\tAvg Score [100eps]: 1137.97 \t Steps: 2047\n",
      "\n",
      "Episode 570: \tActor Loss: 0.11 \tCritic Loss: 4.41 47\n",
      "\t\tAvg Score [100eps]: 1140.38 \t Steps: 2047\n",
      "\n",
      "Episode 580: \tActor Loss: 0.12 \tCritic Loss: 4.34 47\n",
      "\t\tAvg Score [100eps]: 1136.44 \t Steps: 2047\n",
      "\n",
      "Episode 590: \tActor Loss: 0.11 \tCritic Loss: 4.28 47\n",
      "\t\tAvg Score [100eps]: 1151.80 \t Steps: 2047\n",
      "\n",
      "Episode 600: \tActor Loss: 0.12 \tCritic Loss: 4.18 47\n",
      "\t\tAvg Score [100eps]: 1139.26 \t Steps: 2047\n",
      "\n",
      "Episode 610: \tActor Loss: 0.12 \tCritic Loss: 4.09 47\n",
      "\t\tAvg Score [100eps]: 1164.69 \t Steps: 2047\n",
      "\n",
      "Episode 620: \tActor Loss: 0.12 \tCritic Loss: 3.90 47\n",
      "\t\tAvg Score [100eps]: 1101.58 \t Steps: 2047\n",
      "\n",
      "Episode 630: \tActor Loss: 0.14 \tCritic Loss: 3.90 00\n",
      "\t\tAvg Score [100eps]: 1179.22 \t Steps: 1000\n",
      "\n",
      "Episode 640: \tActor Loss: 0.14 \tCritic Loss: 4.02 00\n",
      "\t\tAvg Score [100eps]: 1285.94 \t Steps: 1000\n",
      "\n",
      "Episode 650: \tActor Loss: 0.14 \tCritic Loss: 4.05 00\n",
      "\t\tAvg Score [100eps]: 1208.27 \t Steps: 1000\n",
      "\n",
      "Episode 660: \tActor Loss: 0.14 \tCritic Loss: 3.98 00\n",
      "\t\tAvg Score [100eps]: 1293.12 \t Steps: 1000\n",
      "\n",
      "Episode 670: \tActor Loss: 0.14 \tCritic Loss: 3.93 00\n",
      "\t\tAvg Score [100eps]: 1306.95 \t Steps: 1000\n",
      "\n",
      "Episode 680: \tActor Loss: 0.14 \tCritic Loss: 3.98 00\n",
      "\t\tAvg Score [100eps]: 1324.44 \t Steps: 1000\n",
      "\n",
      "Episode 690: \tActor Loss: 0.14 \tCritic Loss: 4.02 00\n",
      "\t\tAvg Score [100eps]: 1343.44 \t Steps: 1000\n",
      "\n",
      "Episode 700: \tActor Loss: 0.14 \tCritic Loss: 4.19 47\n",
      "\t\tAvg Score [100eps]: 1331.10 \t Steps: 2047\n",
      "\n",
      "Episode 710: \tActor Loss: 0.14 \tCritic Loss: 4.25 47\n",
      "\t\tAvg Score [100eps]: 1310.45 \t Steps: 2047\n",
      "\n",
      "Episode 720: \tActor Loss: 0.14 \tCritic Loss: 4.31 00\n",
      "\t\tAvg Score [100eps]: 1340.63 \t Steps: 1000\n",
      "\n",
      "Episode 730: \tActor Loss: 0.13 \tCritic Loss: 4.26 47\n",
      "\t\tAvg Score [100eps]: 1352.00 \t Steps: 2047\n",
      "\n",
      "Episode 740: \tActor Loss: 0.13 \tCritic Loss: 4.16 00\n",
      "\t\tAvg Score [100eps]: 1401.35 \t Steps: 1000\n",
      "\n",
      "Episode 750: \tActor Loss: 0.13 \tCritic Loss: 4.08 47\n",
      "\t\tAvg Score [100eps]: 1374.92 \t Steps: 2047\n",
      "\n",
      "Episode 760: \tActor Loss: 0.13 \tCritic Loss: 4.01 47\n",
      "\t\tAvg Score [100eps]: 1373.36 \t Steps: 2047\n",
      "\n",
      "Episode 770: \tActor Loss: 0.13 \tCritic Loss: 3.87 47\n",
      "\t\tAvg Score [100eps]: 1360.74 \t Steps: 2047\n",
      "\n",
      "Episode 780: \tActor Loss: 0.14 \tCritic Loss: 3.72 47\n",
      "\t\tAvg Score [100eps]: 1395.16 \t Steps: 2047\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 790: \tActor Loss: 0.14 \tCritic Loss: 3.56 00\n",
      "\t\tAvg Score [100eps]: 1374.48 \t Steps: 1000\n",
      "\n",
      "Episode 800: \tActor Loss: 0.15 \tCritic Loss: 3.37 47\n",
      "\t\tAvg Score [100eps]: 1324.21 \t Steps: 2047\n",
      "\n",
      "Episode 810: \tActor Loss: 0.21 \tCritic Loss: 3.22 00\n",
      "\t\tAvg Score [100eps]: 1361.30 \t Steps: 1000\n",
      "\n",
      "Episode 820: \tActor Loss: 0.22 \tCritic Loss: 3.33 00\n",
      "\t\tAvg Score [100eps]: 1379.98 \t Steps: 1000\n",
      "\n",
      "Episode 830: \tActor Loss: 0.22 \tCritic Loss: 3.18 47\n",
      "\t\tAvg Score [100eps]: 1374.59 \t Steps: 2047\n",
      "\n",
      "Episode 840: \tActor Loss: 0.22 \tCritic Loss: 3.07 00\n",
      "\t\tAvg Score [100eps]: 1389.83 \t Steps: 1000\n",
      "\n",
      "Episode 850: \tActor Loss: 0.23 \tCritic Loss: 3.00 00\n",
      "\t\tAvg Score [100eps]: 1389.59 \t Steps: 1000\n",
      "\n",
      "Episode 860: \tActor Loss: 0.25 \tCritic Loss: 2.97 47\n",
      "\t\tAvg Score [100eps]: 1351.93 \t Steps: 2047\n",
      "\n",
      "Episode 870: \tActor Loss: 0.26 \tCritic Loss: 2.99 47\n",
      "\t\tAvg Score [100eps]: 1378.15 \t Steps: 2047\n",
      "\n",
      "Episode 880: \tActor Loss: 0.26 \tCritic Loss: 2.91 00\n",
      "\t\tAvg Score [100eps]: 1254.35 \t Steps: 1000\n",
      "\n",
      "Episode 890: \tActor Loss: 0.27 \tCritic Loss: 2.84 47\n",
      "\t\tAvg Score [100eps]: 1389.94 \t Steps: 2047\n",
      "\n",
      "Episode 900: \tActor Loss: 0.28 \tCritic Loss: 2.80 47\n",
      "\t\tAvg Score [100eps]: 1373.02 \t Steps: 2047\n",
      "\n",
      "Episode 910: \tActor Loss: 0.23 \tCritic Loss: 2.90 00\n",
      "\t\tAvg Score [100eps]: 1394.07 \t Steps: 1000\n",
      "\n",
      "Episode 920: \tActor Loss: 0.22 \tCritic Loss: 2.79 47\n",
      "\t\tAvg Score [100eps]: 1413.79 \t Steps: 2047\n",
      "\n",
      "Episode 930: \tActor Loss: 0.23 \tCritic Loss: 2.74 00\n",
      "\t\tAvg Score [100eps]: 1397.84 \t Steps: 1000\n",
      "\n",
      "Episode 940: \tActor Loss: 0.24 \tCritic Loss: 2.61 00\n",
      "\t\tAvg Score [100eps]: 1366.20 \t Steps: 1000\n",
      "\n",
      "Episode 950: \tActor Loss: 0.24 \tCritic Loss: 2.53 47\n",
      "\t\tAvg Score [100eps]: 1410.73 \t Steps: 2047\n",
      "\n",
      "Episode 960: \tActor Loss: 0.22 \tCritic Loss: 2.56 47\n",
      "\t\tAvg Score [100eps]: 1389.58 \t Steps: 2047\n",
      "\n",
      "Episode 970: \tActor Loss: 0.23 \tCritic Loss: 2.58 00\n",
      "\t\tAvg Score [100eps]: 1427.62 \t Steps: 1000\n",
      "\n",
      "Episode 980: \tActor Loss: 0.23 \tCritic Loss: 2.54 00\n",
      "\t\tAvg Score [100eps]: 1332.99 \t Steps: 1000\n",
      "\n",
      "Episode 990: \tActor Loss: 0.23 \tCritic Loss: 2.48 47\n",
      "\t\tAvg Score [100eps]: 1295.65 \t Steps: 2047\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.24 \tCritic Loss: 2.44 47\n",
      "\t\tAvg Score [100eps]: 1127.78 \t Steps: 2047\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.25 \tCritic Loss: 2.32 47\n",
      "\t\tAvg Score [100eps]: 1004.55 \t Steps: 2047\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.26 \tCritic Loss: 2.24 47\n",
      "\t\tAvg Score [100eps]: 1135.70 \t Steps: 2047\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.27 \tCritic Loss: 2.24 47\n",
      "\t\tAvg Score [100eps]: 1037.52 \t Steps: 2047\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.28 \tCritic Loss: 2.24 47\n",
      "\t\tAvg Score [100eps]: 1210.17 \t Steps: 2047\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.29 \tCritic Loss: 2.29 47\n",
      "\t\tAvg Score [100eps]: 1230.83 \t Steps: 2047\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.30 \tCritic Loss: 2.26 00\n",
      "\t\tAvg Score [100eps]: 1436.58 \t Steps: 1000\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.31 \tCritic Loss: 2.24 00\n",
      "\t\tAvg Score [100eps]: 1464.72 \t Steps: 1000\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.31 \tCritic Loss: 2.34 47\n",
      "\t\tAvg Score [100eps]: 1515.75 \t Steps: 2047\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.31 \tCritic Loss: 2.48 00\n",
      "\t\tAvg Score [100eps]: 1494.72 \t Steps: 1000\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.31 \tCritic Loss: 2.42 47\n",
      "\t\tAvg Score [100eps]: 1383.89 \t Steps: 2047\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.31 \tCritic Loss: 2.41 00\n",
      "\t\tAvg Score [100eps]: 1490.33 \t Steps: 1000\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.31 \tCritic Loss: 2.47 47\n",
      "\t\tAvg Score [100eps]: 1472.07 \t Steps: 2047\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.30 \tCritic Loss: 2.49 00\n",
      "\t\tAvg Score [100eps]: 1500.75 \t Steps: 1000\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.30 \tCritic Loss: 2.55 47\n",
      "\t\tAvg Score [100eps]: 1113.78 \t Steps: 2047\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.29 \tCritic Loss: 2.54 77\n",
      "\t\tAvg Score [100eps]: 800.08 \t Steps: 2047\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.31 \tCritic Loss: 2.45 7\n",
      "\t\tAvg Score [100eps]: 963.93 \t Steps: 2047\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.32 \tCritic Loss: 2.33 77\n",
      "\t\tAvg Score [100eps]: 914.94 \t Steps: 2047\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.33 \tCritic Loss: 2.21 47\n",
      "\t\tAvg Score [100eps]: 1026.06 \t Steps: 2047\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.34 \tCritic Loss: 2.15 47\n",
      "\t\tAvg Score [100eps]: 1085.02 \t Steps: 2047\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.35 \tCritic Loss: 2.16 47\n",
      "\t\tAvg Score [100eps]: 1111.34 \t Steps: 2047\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.42 \tCritic Loss: 2.41 77\n",
      "\t\tAvg Score [100eps]: 768.33 \t Steps: 2047\n",
      "\n",
      "Episode 1220: \tActor Loss: 0.43 \tCritic Loss: 2.49 47\n",
      "\t\tAvg Score [100eps]: 1066.63 \t Steps: 2047\n",
      "\n",
      "Episode 1224\t Score [This Eps]: 979.02 \t Steps: 20477NaN next_states Found! Skipping this episode.\n",
      "Episode 1230: \tActor Loss: 0.43 \tCritic Loss: 2.44 7\n",
      "\t\tAvg Score [100eps]: 867.11 \t Steps: 2047\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.45 \tCritic Loss: 2.51 77\n",
      "\t\tAvg Score [100eps]: 757.77 \t Steps: 2047\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.45 \tCritic Loss: 2.51 7\n",
      "\t\tAvg Score [100eps]: 728.88 \t Steps: 2047\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.44 \tCritic Loss: 2.49 7\n",
      "\t\tAvg Score [100eps]: 888.60 \t Steps: 2047\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.44 \tCritic Loss: 2.50 77\n",
      "\t\tAvg Score [100eps]: 863.67 \t Steps: 2047\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.44 \tCritic Loss: 3.81 7\n",
      "\t\tAvg Score [100eps]: 245.57 \t Steps: 2047\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.45 \tCritic Loss: 5.25 7\n",
      "\t\tAvg Score [100eps]: 217.56 \t Steps: 2047\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.45 \tCritic Loss: 6.29 7\n",
      "\t\tAvg Score [100eps]: 116.28 \t Steps: 2047\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.42 \tCritic Loss: 6.61 7\n",
      "\t\tAvg Score [100eps]: 126.24 \t Steps: 2047\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.42 \tCritic Loss: 7.35 7\n",
      "\t\tAvg Score [100eps]: 125.89 \t Steps: 2047\n",
      "\n",
      "Episode 1325\t Score [This Eps]: 103.26 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "Episode 1330: \tActor Loss: 0.43 \tCritic Loss: 8.05 7\n",
      "\t\tAvg Score [100eps]: 103.46 \t Steps: 2047\n",
      "\n",
      "Episode 1334\t Score [This Eps]: 68.91 \t Steps: 20477NaN next_states Found! Skipping this episode.\n",
      "Episode 1340: \tActor Loss: 0.44 \tCritic Loss: 8.57 7\n",
      "\t\tAvg Score [100eps]: 104.93 \t Steps: 2047\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.46 \tCritic Loss: 8.90 7\n",
      "\t\tAvg Score [100eps]: 90.79 \t Steps: 2047\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.46 \tCritic Loss: 10.22 \n",
      "\t\tAvg Score [100eps]: 56.12 \t Steps: 2047\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.45 \tCritic Loss: 11.98 \n",
      "\t\tAvg Score [100eps]: 54.17 \t Steps: 2047\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.44 \tCritic Loss: 12.92 \n",
      "\t\tAvg Score [100eps]: 48.26 \t Steps: 2047\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.43 \tCritic Loss: 12.68 \n",
      "\t\tAvg Score [100eps]: 34.69 \t Steps: 2047\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.42 \tCritic Loss: 12.80 \n",
      "\t\tAvg Score [100eps]: 71.10 \t Steps: 2047\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.39 \tCritic Loss: 13.16 \n",
      "\t\tAvg Score [100eps]: 66.09 \t Steps: 2047\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.38 \tCritic Loss: 13.09 \n",
      "\t\tAvg Score [100eps]: 46.97 \t Steps: 2047\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.37 \tCritic Loss: 13.33 \n",
      "\t\tAvg Score [100eps]: 58.97 \t Steps: 2047\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.34 \tCritic Loss: 13.58 \n",
      "\t\tAvg Score [100eps]: 71.41 \t Steps: 2047\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.32 \tCritic Loss: 14.21 \n",
      "\t\tAvg Score [100eps]: 52.13 \t Steps: 2047\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.31 \tCritic Loss: 13.62 \n",
      "\t\tAvg Score [100eps]: 67.57 \t Steps: 2047\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.31 \tCritic Loss: 12.77 \n",
      "\t\tAvg Score [100eps]: 50.01 \t Steps: 2047\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.31 \tCritic Loss: 11.70 \n",
      "\t\tAvg Score [100eps]: 134.23 \t Steps: 2047\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.30 \tCritic Loss: 10.67 \n",
      "\t\tAvg Score [100eps]: 121.54 \t Steps: 2047\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.30 \tCritic Loss: 10.12 \n",
      "\t\tAvg Score [100eps]: 74.78 \t Steps: 2047\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.30 \tCritic Loss: 9.56 7\n",
      "\t\tAvg Score [100eps]: 153.20 \t Steps: 2047\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.29 \tCritic Loss: 8.89 7\n",
      "\t\tAvg Score [100eps]: 179.67 \t Steps: 2047\n",
      "\n",
      "Episode 1530: \tActor Loss: 0.30 \tCritic Loss: 8.16 7\n",
      "\t\tAvg Score [100eps]: 190.43 \t Steps: 2047\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.30 \tCritic Loss: 7.44 7\n",
      "\t\tAvg Score [100eps]: 207.18 \t Steps: 2047\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.30 \tCritic Loss: 6.65 7\n",
      "\t\tAvg Score [100eps]: 164.71 \t Steps: 2047\n",
      "\n",
      "Episode 1560: \tActor Loss: 0.30 \tCritic Loss: 6.21 7\n",
      "\t\tAvg Score [100eps]: 134.35 \t Steps: 2047\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.30 \tCritic Loss: 5.53 7\n",
      "\t\tAvg Score [100eps]: 134.78 \t Steps: 2047\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.31 \tCritic Loss: 5.10 7\n",
      "\t\tAvg Score [100eps]: 102.30 \t Steps: 2047\n",
      "\n",
      "Episode 1584\t Score [This Eps]: 127.21 \t Steps: 2047NaN next_states Found! Skipping this episode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1587\t Score [This Eps]: 93.14 \t Steps: 20477"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9fd58c7da64f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# REPORT NAN STATES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nNaN found in states. Skipping this episode.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mhasNaN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_any\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# Slow down beta decay\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.beta_decay = 0.999                     # How fast to tighten the clipping function\n",
    "params.beta_min = 0.001                       # Min eps to decay to \n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-05--23:18:42 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.08 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 17.65 \t Steps: 6143\n",
      "\n",
      "Episode 20: \tActor Loss: 0.06 \tCritic Loss: 0.15 \n",
      "\t\tAvg Score [100eps]: 51.73 \t Steps: 6143\n",
      "\n",
      "Episode 30: \tActor Loss: 0.11 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 73.54 \t Steps: 6143\n",
      "\n",
      "Episode 40: \tActor Loss: 0.15 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 64.65 \t Steps: 6143\n",
      "\n",
      "Episode 50: \tActor Loss: 0.22 \tCritic Loss: 0.28 \n",
      "\t\tAvg Score [100eps]: 40.17 \t Steps: 6143\n",
      "\n",
      "Episode 60: \tActor Loss: 0.30 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 41.53 \t Steps: 6143\n",
      "\n",
      "Episode 70: \tActor Loss: 0.39 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 19.83 \t Steps: 6143\n",
      "\n",
      "Episode 80: \tActor Loss: 0.48 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 73.60 \t Steps: 6143\n",
      "\n",
      "Episode 90: \tActor Loss: 0.53 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 47.29 \t Steps: 1000\n",
      "\n",
      "Episode 100: \tActor Loss: 0.54 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 55.73 \t Steps: 6143\n",
      "\n",
      "Episode 110: \tActor Loss: 0.62 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 41.81 \t Steps: 6143\n",
      "\n",
      "Episode 120: \tActor Loss: 0.74 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 13.98 \t Steps: 6143\n",
      "\n",
      "Episode 130: \tActor Loss: 0.90 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 9.88 \t Steps: 6143\n",
      "\n",
      "Episode 140: \tActor Loss: 1.41 \tCritic Loss: 0.26 3\n",
      "\t\tAvg Score [100eps]: 0.45 \t Steps: 6143\n",
      "\n",
      "Episode 150: \tActor Loss: 6.53 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 2.46 \t Steps: 6143\n",
      "\n",
      "Episode 160: \tActor Loss: 7.97 \tCritic Loss: 0.30 \n",
      "\t\tAvg Score [100eps]: 6.75 \t Steps: 6143\n",
      "\n",
      "Episode 170: \tActor Loss: 8.35 \tCritic Loss: 0.32 \n",
      "\t\tAvg Score [100eps]: 8.40 \t Steps: 6143\n",
      "\n",
      "Episode 180: \tActor Loss: 8.87 \tCritic Loss: 0.34 \n",
      "\t\tAvg Score [100eps]: 4.68 \t Steps: 6143\n",
      "\n",
      "Episode 190: \tActor Loss: 9.30 \tCritic Loss: 0.36 \n",
      "\t\tAvg Score [100eps]: 5.14 \t Steps: 6143\n",
      "\n",
      "Episode 200: \tActor Loss: 9.70 \tCritic Loss: 0.38 \n",
      "\t\tAvg Score [100eps]: 3.29 \t Steps: 6143\n",
      "\n",
      "Episode 210: \tActor Loss: 10.06 \tCritic Loss: 0.40 \n",
      "\t\tAvg Score [100eps]: 8.13 \t Steps: 6143\n",
      "\n",
      "Episode 220: \tActor Loss: 10.32 \tCritic Loss: 0.41 \n",
      "\t\tAvg Score [100eps]: 4.66 \t Steps: 6143\n",
      "\n",
      "Episode 230: \tActor Loss: 11.10 \tCritic Loss: 0.41 \n",
      "\t\tAvg Score [100eps]: 9.05 \t Steps: 6143\n",
      "\n",
      "Episode 240: \tActor Loss: 10.90 \tCritic Loss: 0.40 \n",
      "\t\tAvg Score [100eps]: 12.01 \t Steps: 6143\n",
      "\n",
      "Episode 250: \tActor Loss: 6.03 \tCritic Loss: 0.38 \n",
      "\t\tAvg Score [100eps]: 8.25 \t Steps: 6143\n",
      "\n",
      "Episode 260: \tActor Loss: 4.78 \tCritic Loss: 0.35 \n",
      "\t\tAvg Score [100eps]: 8.84 \t Steps: 6143\n",
      "\n",
      "Episode 270: \tActor Loss: 4.60 \tCritic Loss: 0.33 \n",
      "\t\tAvg Score [100eps]: 19.09 \t Steps: 6143\n",
      "\n",
      "Episode 280: \tActor Loss: 4.12 \tCritic Loss: 0.30 \n",
      "\t\tAvg Score [100eps]: 17.11 \t Steps: 6143\n",
      "\n",
      "Episode 290: \tActor Loss: 3.76 \tCritic Loss: 0.28 \n",
      "\t\tAvg Score [100eps]: 15.72 \t Steps: 6143\n",
      "\n",
      "Episode 300: \tActor Loss: 3.40 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 14.61 \t Steps: 6143\n",
      "\n",
      "Episode 310: \tActor Loss: 3.04 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 23.01 \t Steps: 6143\n",
      "\n",
      "Episode 320: \tActor Loss: 2.72 \tCritic Loss: 0.24 \n",
      "\t\tAvg Score [100eps]: 25.59 \t Steps: 6143\n",
      "\n",
      "Episode 330: \tActor Loss: 1.84 \tCritic Loss: 0.24 \n",
      "\t\tAvg Score [100eps]: 32.14 \t Steps: 6143\n",
      "\n",
      "Episode 340: \tActor Loss: 1.60 \tCritic Loss: 0.23 \n",
      "\t\tAvg Score [100eps]: 33.14 \t Steps: 6143\n",
      "\n",
      "Episode 350: \tActor Loss: 1.37 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 35.42 \t Steps: 6143\n",
      "\n",
      "Episode 360: \tActor Loss: 1.14 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 40.78 \t Steps: 6143\n",
      "\n",
      "Episode 370: \tActor Loss: 0.89 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 39.74 \t Steps: 6143\n",
      "\n",
      "Episode 380: \tActor Loss: 0.78 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 44.72 \t Steps: 6143\n",
      "\n",
      "Episode 390: \tActor Loss: 0.67 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 41.28 \t Steps: 6143\n",
      "\n",
      "Episode 400: \tActor Loss: 0.59 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 45.12 \t Steps: 6143\n",
      "\n",
      "Episode 410: \tActor Loss: 0.54 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 46.17 \t Steps: 6143\n",
      "\n",
      "Episode 420: \tActor Loss: 0.51 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 50.97 \t Steps: 6143\n",
      "\n",
      "Episode 430: \tActor Loss: 0.46 \tCritic Loss: 0.20 \n",
      "\t\tAvg Score [100eps]: 51.17 \t Steps: 6143\n",
      "\n",
      "Episode 440: \tActor Loss: 0.42 \tCritic Loss: 0.20 \n",
      "\t\tAvg Score [100eps]: 62.25 \t Steps: 6143\n",
      "\n",
      "Episode 450: \tActor Loss: 0.37 \tCritic Loss: 0.20 \n",
      "\t\tAvg Score [100eps]: 53.67 \t Steps: 6143\n",
      "\n",
      "Episode 460: \tActor Loss: 0.36 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 60.88 \t Steps: 6143\n",
      "\n",
      "Episode 470: \tActor Loss: 0.40 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 46.92 \t Steps: 6143\n",
      "\n",
      "Episode 480: \tActor Loss: 0.43 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 47.80 \t Steps: 6143\n",
      "\n",
      "Episode 490: \tActor Loss: 0.40 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 52.99 \t Steps: 6143\n",
      "\n",
      "Episode 500: \tActor Loss: 0.42 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 44.80 \t Steps: 6143\n",
      "\n",
      "Episode 510: \tActor Loss: 0.41 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 49.20 \t Steps: 6143\n",
      "\n",
      "Episode 520: \tActor Loss: 0.42 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 32.42 \t Steps: 6143\n",
      "\n",
      "Episode 530: \tActor Loss: 0.42 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 37.35 \t Steps: 6143\n",
      "\n",
      "Episode 540: \tActor Loss: 0.40 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 40.66 \t Steps: 6143\n",
      "\n",
      "Episode 550: \tActor Loss: 0.43 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 52.47 \t Steps: 6143\n",
      "\n",
      "Episode 560: \tActor Loss: 0.43 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 41.15 \t Steps: 6143\n",
      "\n",
      "Episode 570: \tActor Loss: 0.38 \tCritic Loss: 0.20 \n",
      "\t\tAvg Score [100eps]: 42.39 \t Steps: 6143\n",
      "\n",
      "Episode 580: \tActor Loss: 0.34 \tCritic Loss: 0.20 \n",
      "\t\tAvg Score [100eps]: 53.20 \t Steps: 6143\n",
      "\n",
      "Episode 590: \tActor Loss: 0.35 \tCritic Loss: 0.19 \n",
      "\t\tAvg Score [100eps]: 46.54 \t Steps: 6143\n",
      "\n",
      "Episode 600: \tActor Loss: 0.33 \tCritic Loss: 0.19 \n",
      "\t\tAvg Score [100eps]: 55.32 \t Steps: 6143\n",
      "\n",
      "Episode 610: \tActor Loss: 0.34 \tCritic Loss: 0.18 \n",
      "\t\tAvg Score [100eps]: 49.95 \t Steps: 6143\n",
      "\n",
      "Episode 620: \tActor Loss: 0.33 \tCritic Loss: 0.18 \n",
      "\t\tAvg Score [100eps]: 53.36 \t Steps: 6143\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5083c20955bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, resampled_action, std_scale)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# state, apply batch norm BEFORE activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#linear -> batchnorm -> activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_3a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_3a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         )\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m     return torch.batch_norm(\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m     )\n\u001b[0;32m   2284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# Increase max_t\n",
    "# Grad clip = disabled (DOESN'T WORK)\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 6144       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.gradient_clip = int(0)\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  1.0\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-06--11:28:58 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.04 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 34.53 \t Steps: 1000\n",
      "\n",
      "Episode 20: \tActor Loss: 0.07 \tCritic Loss: 0.46 1\n",
      "\t\tAvg Score [100eps]: 167.40 \t Steps: 3071\n",
      "\n",
      "Episode 30: \tActor Loss: 0.17 \tCritic Loss: 1.15 1\n",
      "\t\tAvg Score [100eps]: 173.11 \t Steps: 3071\n",
      "\n",
      "Episode 40: \tActor Loss: 0.22 \tCritic Loss: 1.68 1\n",
      "\t\tAvg Score [100eps]: 248.53 \t Steps: 3071\n",
      "\n",
      "Episode 50: \tActor Loss: 0.27 \tCritic Loss: 2.07 1\n",
      "\t\tAvg Score [100eps]: 282.07 \t Steps: 3071\n",
      "\n",
      "Episode 60: \tActor Loss: 0.28 \tCritic Loss: 2.37 1\n",
      "\t\tAvg Score [100eps]: 294.22 \t Steps: 3071\n",
      "\n",
      "Episode 70: \tActor Loss: 0.28 \tCritic Loss: 2.63 1\n",
      "\t\tAvg Score [100eps]: 315.08 \t Steps: 3071\n",
      "\n",
      "Episode 80: \tActor Loss: 0.26 \tCritic Loss: 2.84 1\n",
      "\t\tAvg Score [100eps]: 340.93 \t Steps: 3071\n",
      "\n",
      "Episode 90: \tActor Loss: 0.26 \tCritic Loss: 3.01 1\n",
      "\t\tAvg Score [100eps]: 341.28 \t Steps: 3071\n",
      "\n",
      "Episode 100: \tActor Loss: 0.27 \tCritic Loss: 3.07 1\n",
      "\t\tAvg Score [100eps]: 320.46 \t Steps: 3071\n",
      "\n",
      "Episode 110: \tActor Loss: 0.28 \tCritic Loss: 3.43 1\n",
      "\t\tAvg Score [100eps]: 355.15 \t Steps: 3071\n",
      "\n",
      "Episode 120: \tActor Loss: 0.30 \tCritic Loss: 3.64 1\n",
      "\t\tAvg Score [100eps]: 303.44 \t Steps: 3071\n",
      "\n",
      "Episode 130: \tActor Loss: 0.28 \tCritic Loss: 3.66 1\n",
      "\t\tAvg Score [100eps]: 361.89 \t Steps: 3071\n",
      "\n",
      "Episode 140: \tActor Loss: 0.27 \tCritic Loss: 3.62 1\n",
      "\t\tAvg Score [100eps]: 513.36 \t Steps: 3071\n",
      "\n",
      "Episode 150: \tActor Loss: 0.24 \tCritic Loss: 3.46 1\n",
      "\t\tAvg Score [100eps]: 293.92 \t Steps: 3071\n",
      "\n",
      "Episode 160: \tActor Loss: 0.23 \tCritic Loss: 3.25 1\n",
      "\t\tAvg Score [100eps]: 432.10 \t Steps: 3071\n",
      "\n",
      "Episode 170: \tActor Loss: 0.23 \tCritic Loss: 3.00 1\n",
      "\t\tAvg Score [100eps]: 514.06 \t Steps: 3071\n",
      "\n",
      "Episode 180: \tActor Loss: 0.25 \tCritic Loss: 2.74 1\n",
      "\t\tAvg Score [100eps]: 294.58 \t Steps: 3071\n",
      "\n",
      "Episode 190: \tActor Loss: 0.27 \tCritic Loss: 2.48 1\n",
      "\t\tAvg Score [100eps]: 268.32 \t Steps: 3071\n",
      "\n",
      "Episode 200: \tActor Loss: 0.28 \tCritic Loss: 2.26 1\n",
      "\t\tAvg Score [100eps]: 380.08 \t Steps: 3071\n",
      "\n",
      "Episode 210: \tActor Loss: 0.31 \tCritic Loss: 2.02 1\n",
      "\t\tAvg Score [100eps]: 457.45 \t Steps: 3071\n",
      "\n",
      "Episode 220: \tActor Loss: 0.33 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 467.61 \t Steps: 3071\n",
      "\n",
      "Episode 230: \tActor Loss: 0.45 \tCritic Loss: 1.73 1\n",
      "\t\tAvg Score [100eps]: 387.48 \t Steps: 3071\n",
      "\n",
      "Episode 240: \tActor Loss: 0.52 \tCritic Loss: 1.79 0\n",
      "\t\tAvg Score [100eps]: 477.82 \t Steps: 1000\n",
      "\n",
      "Episode 250: \tActor Loss: 0.61 \tCritic Loss: 2.05 1\n",
      "\t\tAvg Score [100eps]: 237.83 \t Steps: 3071\n",
      "\n",
      "Episode 260: \tActor Loss: 2.79 \tCritic Loss: 2.12 1\n",
      "\t\tAvg Score [100eps]: 254.45 \t Steps: 3071\n",
      "\n",
      "Episode 270: \tActor Loss: 161.99 \tCritic Loss: 2.56 \n",
      "\t\tAvg Score [100eps]: 34.97 \t Steps: 3071\n",
      "\n",
      "Episode 280: \tActor Loss: 522.75 \tCritic Loss: 3.17 \n",
      "\t\tAvg Score [100eps]: 1.10 \t Steps: 3071\n",
      "\n",
      "Episode 290: \tActor Loss: 631.73 \tCritic Loss: 3.82 \n",
      "\t\tAvg Score [100eps]: -0.24 \t Steps: 3071\n",
      "\n",
      "Episode 300: \tActor Loss: 2340.03 \tCritic Loss: 4.44 \n",
      "\t\tAvg Score [100eps]: -5.38 \t Steps: 3071\n",
      "\n",
      "Episode 310: \tActor Loss: 4025.50 \tCritic Loss: 5.13 \n",
      "\t\tAvg Score [100eps]: 1.00 \t Steps: 3071\n",
      "\n",
      "Episode 320: \tActor Loss: 6367.13 \tCritic Loss: 5.34 \n",
      "\t\tAvg Score [100eps]: 2.07 \t Steps: 3071\n",
      "\n",
      "Episode 330: \tActor Loss: 13543.50 \tCritic Loss: 5.40 \n",
      "\t\tAvg Score [100eps]: 1.96 \t Steps: 3071\n",
      "\n",
      "Episode 340: \tActor Loss: 17726.57 \tCritic Loss: 5.19 \n",
      "\t\tAvg Score [100eps]: 1.88 \t Steps: 3071\n",
      "\n",
      "Episode 350: \tActor Loss: 23551.01 \tCritic Loss: 4.79 \n",
      "\t\tAvg Score [100eps]: 1.77 \t Steps: 3071\n",
      "\n",
      "Episode 360: \tActor Loss: 59665.33 \tCritic Loss: 4.56 \n",
      "\t\tAvg Score [100eps]: 1.83 \t Steps: 3071\n",
      "\n",
      "Episode 370: \tActor Loss: 64127.36 \tCritic Loss: 3.99 \n",
      "\t\tAvg Score [100eps]: 1.83 \t Steps: 3071\n",
      "\n",
      "Episode 380: \tActor Loss: 66846.67 \tCritic Loss: 3.21 \n",
      "\t\tAvg Score [100eps]: 1.74 \t Steps: 3071\n",
      "\n",
      "Episode 390: \tActor Loss: 80813.40 \tCritic Loss: 2.41 \n",
      "\t\tAvg Score [100eps]: 1.33 \t Steps: 3071\n",
      "\n",
      "Episode 400: \tActor Loss: 81941.80 \tCritic Loss: 1.66 \n",
      "\t\tAvg Score [100eps]: 1.62 \t Steps: 3071\n",
      "\n",
      "Episode 410: \tActor Loss: 95617.65 \tCritic Loss: 0.86 \n",
      "\t\tAvg Score [100eps]: 1.45 \t Steps: 3071\n",
      "\n",
      "Episode 420: \tActor Loss: 97624.72 \tCritic Loss: 0.55 \n",
      "\t\tAvg Score [100eps]: 1.24 \t Steps: 3071\n",
      "\n",
      "Episode 430: \tActor Loss: 103643.64 \tCritic Loss: 0.34 \n",
      "\t\tAvg Score [100eps]: 1.26 \t Steps: 3071\n",
      "\n",
      "Episode 440: \tActor Loss: 102071.87 \tCritic Loss: 0.22 \n",
      "\t\tAvg Score [100eps]: 1.45 \t Steps: 3071\n",
      "\n",
      "Episode 450: \tActor Loss: 486728.61 \tCritic Loss: 0.16 \n",
      "\t\tAvg Score [100eps]: 1.16 \t Steps: 3071\n",
      "\n",
      "Episode 460: \tActor Loss: 459070.93 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 1.04 \t Steps: 3071\n",
      "\n",
      "Episode 470: \tActor Loss: 460334.45 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 1.09 \t Steps: 3071\n",
      "\n",
      "Episode 480: \tActor Loss: 460746.62 \tCritic Loss: 0.13 \n",
      "\t\tAvg Score [100eps]: 0.95 \t Steps: 3071\n",
      "\n",
      "Episode 490: \tActor Loss: 491019.42 \tCritic Loss: 0.12 \n",
      "\t\tAvg Score [100eps]: 0.93 \t Steps: 3071\n",
      "\n",
      "Episode 500: \tActor Loss: 490623.89 \tCritic Loss: 0.12 \n",
      "\t\tAvg Score [100eps]: 1.14 \t Steps: 3071\n",
      "\n",
      "Episode 510: \tActor Loss: 478686.59 \tCritic Loss: 0.11 \n",
      "\t\tAvg Score [100eps]: 1.01 \t Steps: 3071\n",
      "\n",
      "Episode 520: \tActor Loss: 478798.76 \tCritic Loss: 0.11 \n",
      "\t\tAvg Score [100eps]: 0.96 \t Steps: 3071\n",
      "\n",
      "Episode 530: \tActor Loss: 469524.60 \tCritic Loss: 0.10 \n",
      "\t\tAvg Score [100eps]: 0.88 \t Steps: 3071\n",
      "\n",
      "Episode 540: \tActor Loss: 474693.88 \tCritic Loss: 0.10 \n",
      "\t\tAvg Score [100eps]: 0.87 \t Steps: 3071\n",
      "\n",
      "Episode 550: \tActor Loss: 375921.21 \tCritic Loss: 0.09 \n",
      "\t\tAvg Score [100eps]: 0.81 \t Steps: 3071\n",
      "\n",
      "Episode 560: \tActor Loss: 534240.30 \tCritic Loss: 0.09 \n",
      "\t\tAvg Score [100eps]: 0.90 \t Steps: 3071\n",
      "\n",
      "Episode 570: \tActor Loss: 544269.59 \tCritic Loss: 0.09 \n",
      "\t\tAvg Score [100eps]: 0.82 \t Steps: 3071\n",
      "\n",
      "Episode 580: \tActor Loss: 544044.86 \tCritic Loss: 0.08 \n",
      "\t\tAvg Score [100eps]: 0.83 \t Steps: 3071\n",
      "\n",
      "Episode 590: \tActor Loss: 504691.41 \tCritic Loss: 0.08 \n",
      "\t\tAvg Score [100eps]: 0.66 \t Steps: 3071\n",
      "\n",
      "Episode 600: \tActor Loss: 508108.91 \tCritic Loss: 0.08 \n",
      "\t\tAvg Score [100eps]: 0.74 \t Steps: 3071\n",
      "\n",
      "Episode 610: \tActor Loss: 522014.33 \tCritic Loss: 0.08 \n",
      "\t\tAvg Score [100eps]: 0.65 \t Steps: 3071\n",
      "\n",
      "Episode 620: \tActor Loss: 519703.62 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 0.75 \t Steps: 3071\n",
      "\n",
      "Episode 630: \tActor Loss: 699094.09 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 0.64 \t Steps: 3071\n",
      "\n",
      "Episode 640: \tActor Loss: 1206645.14 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 0.64 \t Steps: 3071\n",
      "\n",
      "Episode 650: \tActor Loss: 918124.11 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 0.54 \t Steps: 3071\n",
      "\n",
      "Episode 660: \tActor Loss: 758900.35 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 0.62 \t Steps: 3071\n",
      "\n",
      "Episode 670: \tActor Loss: 790649.93 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 0.57 \t Steps: 3071\n",
      "\n",
      "Episode 680: \tActor Loss: 795167.35 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 0.59 \t Steps: 3071\n",
      "\n",
      "Episode 690: \tActor Loss: 799561.05 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 0.56 \t Steps: 3071\n",
      "\n",
      "Episode 700: \tActor Loss: 808900.07 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 0.63 \t Steps: 3071\n",
      "\n",
      "Episode 710: \tActor Loss: 795357.40 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 0.59 \t Steps: 3071\n",
      "\n",
      "Episode 720: \tActor Loss: 797490.41 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 0.54 \t Steps: 3071\n",
      "\n",
      "Episode 730: \tActor Loss: 620146.18 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 0.56 \t Steps: 3071\n",
      "\n",
      "Episode 740: \tActor Loss: 112744.60 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 0.62 \t Steps: 3071\n",
      "\n",
      "Episode 750: \tActor Loss: 118502.34 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 0.59 \t Steps: 3071\n",
      "\n",
      "Episode 760: \tActor Loss: 152366.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 0.49 \t Steps: 3071\n",
      "\n",
      "Episode 770: \tActor Loss: 122996.70 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.51 \t Steps: 3071\n",
      "\n",
      "Episode 780: \tActor Loss: 283267.09 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.49 \t Steps: 3071\n",
      "\n",
      "Episode 790: \tActor Loss: 275919.64 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.53 \t Steps: 3071\n",
      "\n",
      "Episode 800: \tActor Loss: 276277.05 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 810: \tActor Loss: 331876.40 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.45 \t Steps: 3071\n",
      "\n",
      "Episode 820: \tActor Loss: 331056.96 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 830: \tActor Loss: 346806.35 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.40 \t Steps: 3071\n",
      "\n",
      "Episode 840: \tActor Loss: 341691.09 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.53 \t Steps: 3071\n",
      "\n",
      "Episode 850: \tActor Loss: 336802.81 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.42 \t Steps: 3071\n",
      "\n",
      "Episode 860: \tActor Loss: 299562.32 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 0.51 \t Steps: 3071\n",
      "\n",
      "Episode 870: \tActor Loss: 288651.93 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 880: \tActor Loss: 123276.22 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 890: \tActor Loss: 129065.52 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.51 \t Steps: 3071\n",
      "\n",
      "Episode 900: \tActor Loss: 116960.26 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.45 \t Steps: 3071\n",
      "\n",
      "Episode 910: \tActor Loss: 59633.97 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.42 \t Steps: 3071\n",
      "\n",
      "Episode 920: \tActor Loss: 67231.60 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.50 \t Steps: 3071\n",
      "\n",
      "Episode 930: \tActor Loss: 51449.74 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.45 \t Steps: 3071\n",
      "\n",
      "Episode 940: \tActor Loss: 52683.08 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 950: \tActor Loss: 51819.26 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.50 \t Steps: 3071\n",
      "\n",
      "Episode 960: \tActor Loss: 52635.17 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.46 \t Steps: 3071\n",
      "\n",
      "Episode 970: \tActor Loss: 56489.50 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.46 \t Steps: 3071\n",
      "\n",
      "Episode 980: \tActor Loss: 60319.79 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.42 \t Steps: 3071\n",
      "\n",
      "Episode 990: \tActor Loss: 59057.73 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.48 \t Steps: 3071\n",
      "\n",
      "Episode 1000: \tActor Loss: 58593.19 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.43 \t Steps: 3071\n",
      "\n",
      "Episode 1010: \tActor Loss: 71136.55 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.46 \t Steps: 3071\n",
      "\n",
      "Episode 1020: \tActor Loss: 62381.75 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.49 \t Steps: 3071\n",
      "\n",
      "Episode 1030: \tActor Loss: 60243.89 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.46 \t Steps: 3071\n",
      "\n",
      "Episode 1040: \tActor Loss: 58650.20 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 0.42 \t Steps: 3071\n",
      "\n",
      "Episode 1047\t Score [This Eps]: 0.39 \t Steps: 3071"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-18e5f5fbe2ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;34m\"\"\"Returns actions for given state as per current policy.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# Increase max_t\n",
    "# Grad clip = disabled (DOESN'T WORK)\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 3072       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.lr_decay = 1.0\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-08--01:44:27 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 30.83 \t Steps: 1000\n",
      "\n",
      "Episode 20: \tActor Loss: 0.07 \tCritic Loss: 0.52 1\n",
      "\t\tAvg Score [100eps]: 176.91 \t Steps: 3071\n",
      "\n",
      "Episode 30: \tActor Loss: 0.11 \tCritic Loss: 1.62 0\n",
      "\t\tAvg Score [100eps]: 224.39 \t Steps: 1000\n",
      "\n",
      "Episode 40: \tActor Loss: 0.14 \tCritic Loss: 2.40 1\n",
      "\t\tAvg Score [100eps]: 303.90 \t Steps: 3071\n",
      "\n",
      "Episode 50: \tActor Loss: 0.16 \tCritic Loss: 2.97 1\n",
      "\t\tAvg Score [100eps]: 327.74 \t Steps: 3071\n",
      "\n",
      "Episode 53\t Score [This Eps]: 334.41 \t Steps: 3071NaN Reward Found! Skipping this episode.\n",
      "Episode 60: \tActor Loss: 0.16 \tCritic Loss: 3.56 1\n",
      "\t\tAvg Score [100eps]: 343.24 \t Steps: 3071\n",
      "\n",
      "Episode 70: \tActor Loss: 0.39 \tCritic Loss: 4.14 1\n",
      "\t\tAvg Score [100eps]: 387.32 \t Steps: 3071\n",
      "\n",
      "Episode 80: \tActor Loss: 0.36 \tCritic Loss: 4.34 1\n",
      "\t\tAvg Score [100eps]: 377.12 \t Steps: 3071\n",
      "\n",
      "Episode 90: \tActor Loss: 0.34 \tCritic Loss: 4.66 1\n",
      "\t\tAvg Score [100eps]: 390.63 \t Steps: 3071\n",
      "\n",
      "Episode 100: \tActor Loss: 0.32 \tCritic Loss: 4.91 1\n",
      "\t\tAvg Score [100eps]: 434.12 \t Steps: 3071\n",
      "\n",
      "Episode 110: \tActor Loss: 0.33 \tCritic Loss: 5.59 1\n",
      "\t\tAvg Score [100eps]: 447.37 \t Steps: 3071\n",
      "\n",
      "Episode 120: \tActor Loss: 0.34 \tCritic Loss: 6.28 0\n",
      "\t\tAvg Score [100eps]: 483.47 \t Steps: 1000\n",
      "\n",
      "Episode 130: \tActor Loss: 0.35 \tCritic Loss: 6.49 1\n",
      "\t\tAvg Score [100eps]: 474.53 \t Steps: 3071\n",
      "\n",
      "Episode 140: \tActor Loss: 0.34 \tCritic Loss: 6.80 0\n",
      "\t\tAvg Score [100eps]: 484.88 \t Steps: 1000\n",
      "\n",
      "Episode 150: \tActor Loss: 0.33 \tCritic Loss: 6.92 1\n",
      "\t\tAvg Score [100eps]: 535.45 \t Steps: 3071\n",
      "\n",
      "Episode 160: \tActor Loss: 0.32 \tCritic Loss: 6.92 1\n",
      "\t\tAvg Score [100eps]: 532.60 \t Steps: 3071\n",
      "\n",
      "Episode 170: \tActor Loss: 0.16 \tCritic Loss: 6.78 0\n",
      "\t\tAvg Score [100eps]: 521.65 \t Steps: 1000\n",
      "\n",
      "Episode 180: \tActor Loss: 0.16 \tCritic Loss: 6.84 1\n",
      "\t\tAvg Score [100eps]: 537.81 \t Steps: 3071\n",
      "\n",
      "Episode 190: \tActor Loss: 0.16 \tCritic Loss: 6.61 1\n",
      "\t\tAvg Score [100eps]: 504.13 \t Steps: 3071\n",
      "\n",
      "Episode 200: \tActor Loss: 0.16 \tCritic Loss: 6.40 0\n",
      "\t\tAvg Score [100eps]: 568.78 \t Steps: 1000\n",
      "\n",
      "Episode 210: \tActor Loss: 0.16 \tCritic Loss: 6.19 1\n",
      "\t\tAvg Score [100eps]: 606.48 \t Steps: 3071\n",
      "\n",
      "Episode 220: \tActor Loss: 0.17 \tCritic Loss: 5.93 1\n",
      "\t\tAvg Score [100eps]: 540.28 \t Steps: 3071\n",
      "\n",
      "Episode 230: \tActor Loss: 0.15 \tCritic Loss: 5.91 1\n",
      "\t\tAvg Score [100eps]: 624.47 \t Steps: 3071\n",
      "\n",
      "Episode 240: \tActor Loss: 0.15 \tCritic Loss: 5.59 1\n",
      "\t\tAvg Score [100eps]: 576.92 \t Steps: 3071\n",
      "\n",
      "Episode 250: \tActor Loss: 0.15 \tCritic Loss: 5.44 1\n",
      "\t\tAvg Score [100eps]: 603.35 \t Steps: 3071\n",
      "\n",
      "Episode 260: \tActor Loss: 0.15 \tCritic Loss: 5.26 1\n",
      "\t\tAvg Score [100eps]: 608.31 \t Steps: 3071\n",
      "\n",
      "Episode 270: \tActor Loss: 0.15 \tCritic Loss: 5.06 1\n",
      "\t\tAvg Score [100eps]: 594.98 \t Steps: 3071\n",
      "\n",
      "Episode 280: \tActor Loss: 0.15 \tCritic Loss: 4.77 0\n",
      "\t\tAvg Score [100eps]: 589.88 \t Steps: 1000\n",
      "\n",
      "Episode 290: \tActor Loss: 0.15 \tCritic Loss: 4.59 1\n",
      "\t\tAvg Score [100eps]: 545.87 \t Steps: 3071\n",
      "\n",
      "Episode 300: \tActor Loss: 0.17 \tCritic Loss: 4.48 1\n",
      "\t\tAvg Score [100eps]: 638.11 \t Steps: 3071\n",
      "\n",
      "Episode 310: \tActor Loss: 0.20 \tCritic Loss: 4.32 1\n",
      "\t\tAvg Score [100eps]: 656.11 \t Steps: 3071\n",
      "\n",
      "Episode 320: \tActor Loss: 0.20 \tCritic Loss: 4.20 1\n",
      "\t\tAvg Score [100eps]: 636.20 \t Steps: 3071\n",
      "\n",
      "Episode 330: \tActor Loss: 0.20 \tCritic Loss: 3.95 0\n",
      "\t\tAvg Score [100eps]: 649.45 \t Steps: 1000\n",
      "\n",
      "Episode 340: \tActor Loss: 0.21 \tCritic Loss: 3.83 1\n",
      "\t\tAvg Score [100eps]: 649.82 \t Steps: 3071\n",
      "\n",
      "Episode 350: \tActor Loss: 0.26 \tCritic Loss: 3.64 1\n",
      "\t\tAvg Score [100eps]: 594.70 \t Steps: 3071\n",
      "\n",
      "Episode 360: \tActor Loss: 0.27 \tCritic Loss: 3.43 1\n",
      "\t\tAvg Score [100eps]: 646.18 \t Steps: 3071\n",
      "\n",
      "Episode 370: \tActor Loss: 0.37 \tCritic Loss: 3.26 1\n",
      "\t\tAvg Score [100eps]: 672.97 \t Steps: 3071\n",
      "\n",
      "Episode 380: \tActor Loss: 0.38 \tCritic Loss: 3.24 1\n",
      "\t\tAvg Score [100eps]: 203.96 \t Steps: 3071\n",
      "\n",
      "Episode 390: \tActor Loss: 0.40 \tCritic Loss: 3.62 1\n",
      "\t\tAvg Score [100eps]: 469.16 \t Steps: 3071\n",
      "\n",
      "Episode 400: \tActor Loss: 0.40 \tCritic Loss: 3.59 1\n",
      "\t\tAvg Score [100eps]: 694.19 \t Steps: 3071\n",
      "\n",
      "Episode 410: \tActor Loss: 0.37 \tCritic Loss: 3.47 1\n",
      "\t\tAvg Score [100eps]: 578.85 \t Steps: 3071\n",
      "\n",
      "Episode 420: \tActor Loss: 0.37 \tCritic Loss: 3.37 1\n",
      "\t\tAvg Score [100eps]: 480.48 \t Steps: 3071\n",
      "\n",
      "Episode 430: \tActor Loss: 0.38 \tCritic Loss: 3.32 1\n",
      "\t\tAvg Score [100eps]: 658.99 \t Steps: 3071\n",
      "\n",
      "Episode 440: \tActor Loss: 0.38 \tCritic Loss: 3.24 1\n",
      "\t\tAvg Score [100eps]: 642.44 \t Steps: 3071\n",
      "\n",
      "Episode 450: \tActor Loss: 0.33 \tCritic Loss: 3.19 1\n",
      "\t\tAvg Score [100eps]: 658.90 \t Steps: 3071\n",
      "\n",
      "Episode 460: \tActor Loss: 0.33 \tCritic Loss: 3.17 1\n",
      "\t\tAvg Score [100eps]: 664.17 \t Steps: 3071\n",
      "\n",
      "Episode 470: \tActor Loss: 0.23 \tCritic Loss: 3.18 1\n",
      "\t\tAvg Score [100eps]: 680.10 \t Steps: 3071\n",
      "\n",
      "Episode 480: \tActor Loss: 0.29 \tCritic Loss: 3.05 1\n",
      "\t\tAvg Score [100eps]: 635.64 \t Steps: 3071\n",
      "\n",
      "Episode 490: \tActor Loss: 0.26 \tCritic Loss: 2.55 1\n",
      "\t\tAvg Score [100eps]: 702.23 \t Steps: 3071\n",
      "\n",
      "Episode 500: \tActor Loss: 0.26 \tCritic Loss: 2.40 1\n",
      "\t\tAvg Score [100eps]: 721.83 \t Steps: 3071\n",
      "\n",
      "Episode 510: \tActor Loss: 0.25 \tCritic Loss: 2.38 1\n",
      "\t\tAvg Score [100eps]: 720.54 \t Steps: 3071\n",
      "\n",
      "Episode 520: \tActor Loss: 0.25 \tCritic Loss: 2.35 1\n",
      "\t\tAvg Score [100eps]: 708.68 \t Steps: 3071\n",
      "\n",
      "Episode 530: \tActor Loss: 0.24 \tCritic Loss: 2.29 1\n",
      "\t\tAvg Score [100eps]: 753.39 \t Steps: 3071\n",
      "\n",
      "Episode 540: \tActor Loss: 0.25 \tCritic Loss: 2.27 1\n",
      "\t\tAvg Score [100eps]: 739.41 \t Steps: 3071\n",
      "\n",
      "Episode 550: \tActor Loss: 0.25 \tCritic Loss: 2.19 0\n",
      "\t\tAvg Score [100eps]: 743.26 \t Steps: 1000\n",
      "\n",
      "Episode 560: \tActor Loss: 0.25 \tCritic Loss: 2.13 1\n",
      "\t\tAvg Score [100eps]: 741.90 \t Steps: 3071\n",
      "\n",
      "Episode 570: \tActor Loss: 0.25 \tCritic Loss: 2.06 1\n",
      "\t\tAvg Score [100eps]: 740.43 \t Steps: 3071\n",
      "\n",
      "Episode 580: \tActor Loss: 0.18 \tCritic Loss: 2.03 1\n",
      "\t\tAvg Score [100eps]: 764.59 \t Steps: 3071\n",
      "\n",
      "Episode 590: \tActor Loss: 0.20 \tCritic Loss: 2.01 1\n",
      "\t\tAvg Score [100eps]: 805.94 \t Steps: 3071\n",
      "\n",
      "Episode 600: \tActor Loss: 0.19 \tCritic Loss: 1.98 1\n",
      "\t\tAvg Score [100eps]: 813.84 \t Steps: 3071\n",
      "\n",
      "Episode 610: \tActor Loss: 0.19 \tCritic Loss: 1.91 1\n",
      "\t\tAvg Score [100eps]: 784.96 \t Steps: 3071\n",
      "\n",
      "Episode 620: \tActor Loss: 0.19 \tCritic Loss: 1.86 1\n",
      "\t\tAvg Score [100eps]: 805.05 \t Steps: 3071\n",
      "\n",
      "Episode 630: \tActor Loss: 0.27 \tCritic Loss: 1.81 1\n",
      "\t\tAvg Score [100eps]: 740.70 \t Steps: 3071\n",
      "\n",
      "Episode 640: \tActor Loss: 0.27 \tCritic Loss: 1.76 1\n",
      "\t\tAvg Score [100eps]: 785.56 \t Steps: 3071\n",
      "\n",
      "Episode 650: \tActor Loss: 0.26 \tCritic Loss: 1.73 1\n",
      "\t\tAvg Score [100eps]: 810.23 \t Steps: 3071\n",
      "\n",
      "Episode 660: \tActor Loss: 0.27 \tCritic Loss: 1.67 0\n",
      "\t\tAvg Score [100eps]: 781.53 \t Steps: 1000\n",
      "\n",
      "Episode 670: \tActor Loss: 0.26 \tCritic Loss: 1.64 1\n",
      "\t\tAvg Score [100eps]: 760.76 \t Steps: 3071\n",
      "\n",
      "Episode 680: \tActor Loss: 0.27 \tCritic Loss: 1.61 1\n",
      "\t\tAvg Score [100eps]: 747.39 \t Steps: 3071\n",
      "\n",
      "Episode 690: \tActor Loss: 0.25 \tCritic Loss: 1.58 1\n",
      "\t\tAvg Score [100eps]: 725.41 \t Steps: 3071\n",
      "\n",
      "Episode 700: \tActor Loss: 0.24 \tCritic Loss: 1.54 1\n",
      "\t\tAvg Score [100eps]: 779.95 \t Steps: 3071\n",
      "\n",
      "Episode 710: \tActor Loss: 0.25 \tCritic Loss: 1.50 1\n",
      "\t\tAvg Score [100eps]: 739.63 \t Steps: 3071\n",
      "\n",
      "Episode 720: \tActor Loss: 0.25 \tCritic Loss: 1.47 1\n",
      "\t\tAvg Score [100eps]: 793.47 \t Steps: 3071\n",
      "\n",
      "Episode 730: \tActor Loss: 0.23 \tCritic Loss: 1.43 1\n",
      "\t\tAvg Score [100eps]: 810.18 \t Steps: 3071\n",
      "\n",
      "Episode 740: \tActor Loss: 0.23 \tCritic Loss: 1.39 1\n",
      "\t\tAvg Score [100eps]: 784.13 \t Steps: 3071\n",
      "\n",
      "Episode 750: \tActor Loss: 0.23 \tCritic Loss: 1.38 1\n",
      "\t\tAvg Score [100eps]: 808.28 \t Steps: 3071\n",
      "\n",
      "Episode 760: \tActor Loss: 0.22 \tCritic Loss: 1.37 1\n",
      "\t\tAvg Score [100eps]: 821.99 \t Steps: 3071\n",
      "\n",
      "Episode 770: \tActor Loss: 0.22 \tCritic Loss: 1.35 1\n",
      "\t\tAvg Score [100eps]: 794.78 \t Steps: 3071\n",
      "\n",
      "Episode 780: \tActor Loss: 0.22 \tCritic Loss: 1.33 0\n",
      "\t\tAvg Score [100eps]: 804.40 \t Steps: 1000\n",
      "\n",
      "Episode 790: \tActor Loss: 0.23 \tCritic Loss: 1.32 1\n",
      "\t\tAvg Score [100eps]: 851.52 \t Steps: 3071\n",
      "\n",
      "Episode 800: \tActor Loss: 0.23 \tCritic Loss: 1.31 1\n",
      "\t\tAvg Score [100eps]: 836.31 \t Steps: 3071\n",
      "\n",
      "Episode 810: \tActor Loss: 0.23 \tCritic Loss: 1.31 1\n",
      "\t\tAvg Score [100eps]: 819.87 \t Steps: 3071\n",
      "\n",
      "Episode 820: \tActor Loss: 0.22 \tCritic Loss: 1.29 1\n",
      "\t\tAvg Score [100eps]: 889.18 \t Steps: 3071\n",
      "\n",
      "Episode 830: \tActor Loss: 0.15 \tCritic Loss: 1.29 1\n",
      "\t\tAvg Score [100eps]: 897.13 \t Steps: 3071\n",
      "\n",
      "Episode 840: \tActor Loss: 0.15 \tCritic Loss: 1.29 1\n",
      "\t\tAvg Score [100eps]: 892.09 \t Steps: 3071\n",
      "\n",
      "Episode 850: \tActor Loss: 0.15 \tCritic Loss: 1.27 1\n",
      "\t\tAvg Score [100eps]: 897.96 \t Steps: 3071\n",
      "\n",
      "Episode 860: \tActor Loss: 0.14 \tCritic Loss: 1.26 1\n",
      "\t\tAvg Score [100eps]: 937.91 \t Steps: 3071\n",
      "\n",
      "Episode 870: \tActor Loss: 0.14 \tCritic Loss: 1.25 1\n",
      "\t\tAvg Score [100eps]: 874.53 \t Steps: 3071\n",
      "\n",
      "Episode 880: \tActor Loss: 0.14 \tCritic Loss: 1.26 1\n",
      "\t\tAvg Score [100eps]: 946.92 \t Steps: 3071\n",
      "\n",
      "Episode 890: \tActor Loss: 0.13 \tCritic Loss: 1.25 0\n",
      "\t\tAvg Score [100eps]: 908.98 \t Steps: 1000\n",
      "\n",
      "Episode 900: \tActor Loss: 0.12 \tCritic Loss: 1.24 1\n",
      "\t\tAvg Score [100eps]: 931.55 \t Steps: 3071\n",
      "\n",
      "Episode 910: \tActor Loss: 0.12 \tCritic Loss: 1.23 1\n",
      "\t\tAvg Score [100eps]: 980.92 \t Steps: 3071\n",
      "\n",
      "Episode 920: \tActor Loss: 0.13 \tCritic Loss: 1.23 11\n",
      "\t\tAvg Score [100eps]: 983.90 \t Steps: 3071\n",
      "\n",
      "Episode 930: \tActor Loss: 0.13 \tCritic Loss: 1.22 71\n",
      "\t\tAvg Score [100eps]: 1001.09 \t Steps: 3071\n",
      "\n",
      "Episode 940: \tActor Loss: 0.13 \tCritic Loss: 1.23 11\n",
      "\t\tAvg Score [100eps]: 975.60 \t Steps: 3071\n",
      "\n",
      "Episode 950: \tActor Loss: 0.13 \tCritic Loss: 1.24 11\n",
      "\t\tAvg Score [100eps]: 929.52 \t Steps: 3071\n",
      "\n",
      "Episode 960: \tActor Loss: 0.13 \tCritic Loss: 1.22 1\n",
      "\t\tAvg Score [100eps]: 990.86 \t Steps: 3071\n",
      "\n",
      "Episode 970: \tActor Loss: 0.20 \tCritic Loss: 1.23 00\n",
      "\t\tAvg Score [100eps]: 1022.71 \t Steps: 1000\n",
      "\n",
      "Episode 980: \tActor Loss: 0.20 \tCritic Loss: 1.23 71\n",
      "\t\tAvg Score [100eps]: 1043.92 \t Steps: 3071\n",
      "\n",
      "Episode 990: \tActor Loss: 0.20 \tCritic Loss: 1.25 71\n",
      "\t\tAvg Score [100eps]: 1045.98 \t Steps: 3071\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.21 \tCritic Loss: 1.26 71\n",
      "\t\tAvg Score [100eps]: 1054.24 \t Steps: 3071\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.23 \tCritic Loss: 1.26 00\n",
      "\t\tAvg Score [100eps]: 1063.40 \t Steps: 1000\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.23 \tCritic Loss: 1.27 71\n",
      "\t\tAvg Score [100eps]: 1091.11 \t Steps: 3071\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.22 \tCritic Loss: 1.27 71\n",
      "\t\tAvg Score [100eps]: 1082.49 \t Steps: 3071\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.22 \tCritic Loss: 1.26 71\n",
      "\t\tAvg Score [100eps]: 1050.88 \t Steps: 3071\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.23 \tCritic Loss: 1.25 71\n",
      "\t\tAvg Score [100eps]: 1102.23 \t Steps: 3071\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.23 \tCritic Loss: 1.27 71\n",
      "\t\tAvg Score [100eps]: 1113.25 \t Steps: 3071\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.16 \tCritic Loss: 1.28 00\n",
      "\t\tAvg Score [100eps]: 1098.45 \t Steps: 1000\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.16 \tCritic Loss: 1.29 71\n",
      "\t\tAvg Score [100eps]: 1117.03 \t Steps: 3071\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.16 \tCritic Loss: 1.28 71\n",
      "\t\tAvg Score [100eps]: 1124.34 \t Steps: 3071\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.15 \tCritic Loss: 1.29 71\n",
      "\t\tAvg Score [100eps]: 1086.10 \t Steps: 3071\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.13 \tCritic Loss: 1.31 00\n",
      "\t\tAvg Score [100eps]: 1195.06 \t Steps: 1000\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.13 \tCritic Loss: 1.32 71\n",
      "\t\tAvg Score [100eps]: 1195.67 \t Steps: 3071\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.13 \tCritic Loss: 1.33 71\n",
      "\t\tAvg Score [100eps]: 1181.70 \t Steps: 3071\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.14 \tCritic Loss: 1.35 71\n",
      "\t\tAvg Score [100eps]: 1219.85 \t Steps: 3071\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.14 \tCritic Loss: 1.36 71\n",
      "\t\tAvg Score [100eps]: 1128.99 \t Steps: 3071\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.14 \tCritic Loss: 1.35 71\n",
      "\t\tAvg Score [100eps]: 1147.45 \t Steps: 3071\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.14 \tCritic Loss: 1.35 00\n",
      "\t\tAvg Score [100eps]: 1156.78 \t Steps: 1000\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.13 \tCritic Loss: 1.36 71\n",
      "\t\tAvg Score [100eps]: 1216.84 \t Steps: 3071\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.13 \tCritic Loss: 1.38 00\n",
      "\t\tAvg Score [100eps]: 1189.45 \t Steps: 1000\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.14 \tCritic Loss: 1.40 71\n",
      "\t\tAvg Score [100eps]: 1132.80 \t Steps: 3071\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.14 \tCritic Loss: 1.39 71\n",
      "\t\tAvg Score [100eps]: 1208.85 \t Steps: 3071\n",
      "\n",
      "Episode 1220: \tActor Loss: 0.14 \tCritic Loss: 1.41 71\n",
      "\t\tAvg Score [100eps]: 1119.16 \t Steps: 3071\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.14 \tCritic Loss: 1.42 71\n",
      "\t\tAvg Score [100eps]: 1183.31 \t Steps: 3071\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.12 \tCritic Loss: 1.43 71\n",
      "\t\tAvg Score [100eps]: 1197.31 \t Steps: 3071\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.12 \tCritic Loss: 1.44 71\n",
      "\t\tAvg Score [100eps]: 1139.43 \t Steps: 3071\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.12 \tCritic Loss: 1.45 00\n",
      "\t\tAvg Score [100eps]: 1270.39 \t Steps: 1000\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.15 \tCritic Loss: 1.46 71\n",
      "\t\tAvg Score [100eps]: 1249.13 \t Steps: 3071\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.15 \tCritic Loss: 1.49 71\n",
      "\t\tAvg Score [100eps]: 1161.14 \t Steps: 3071\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.16 \tCritic Loss: 1.54 71\n",
      "\t\tAvg Score [100eps]: 1214.57 \t Steps: 3071\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.17 \tCritic Loss: 1.54 71\n",
      "\t\tAvg Score [100eps]: 1208.47 \t Steps: 3071\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.17 \tCritic Loss: 1.56 71\n",
      "\t\tAvg Score [100eps]: 1282.06 \t Steps: 3071\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.17 \tCritic Loss: 1.56 71\n",
      "\t\tAvg Score [100eps]: 1245.90 \t Steps: 3071\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.18 \tCritic Loss: 1.57 71\n",
      "\t\tAvg Score [100eps]: 1193.57 \t Steps: 3071\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.18 \tCritic Loss: 1.63 71\n",
      "\t\tAvg Score [100eps]: 1309.02 \t Steps: 3071\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.19 \tCritic Loss: 1.82 71\n",
      "\t\tAvg Score [100eps]: 1253.83 \t Steps: 3071\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.19 \tCritic Loss: 1.84 71\n",
      "\t\tAvg Score [100eps]: 1266.71 \t Steps: 3071\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.16 \tCritic Loss: 1.85 71\n",
      "\t\tAvg Score [100eps]: 1328.77 \t Steps: 3071\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.17 \tCritic Loss: 1.89 71\n",
      "\t\tAvg Score [100eps]: 1248.62 \t Steps: 3071\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.16 \tCritic Loss: 1.91 71\n",
      "\t\tAvg Score [100eps]: 1212.87 \t Steps: 3071\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.14 \tCritic Loss: 1.93 00\n",
      "\t\tAvg Score [100eps]: 1354.86 \t Steps: 1000\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.14 \tCritic Loss: 1.94 71\n",
      "\t\tAvg Score [100eps]: 1362.01 \t Steps: 3071\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.14 \tCritic Loss: 1.94 71\n",
      "\t\tAvg Score [100eps]: 1315.99 \t Steps: 3071\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.13 \tCritic Loss: 1.98 00\n",
      "\t\tAvg Score [100eps]: 1301.55 \t Steps: 1000\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.13 \tCritic Loss: 1.99 00\n",
      "\t\tAvg Score [100eps]: 1354.26 \t Steps: 1000\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.13 \tCritic Loss: 1.88 71\n",
      "\t\tAvg Score [100eps]: 1349.29 \t Steps: 3071\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.13 \tCritic Loss: 1.87 71\n",
      "\t\tAvg Score [100eps]: 1374.52 \t Steps: 3071\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.13 \tCritic Loss: 1.89 71\n",
      "\t\tAvg Score [100eps]: 1312.16 \t Steps: 3071\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.12 \tCritic Loss: 1.89 71\n",
      "\t\tAvg Score [100eps]: 1355.61 \t Steps: 3071\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.13 \tCritic Loss: 1.86 00\n",
      "\t\tAvg Score [100eps]: 1382.99 \t Steps: 1000\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.19 \tCritic Loss: 1.91 71\n",
      "\t\tAvg Score [100eps]: 1200.49 \t Steps: 3071\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.19 \tCritic Loss: 1.95 00\n",
      "\t\tAvg Score [100eps]: 1297.70 \t Steps: 1000\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.20 \tCritic Loss: 1.96 71\n",
      "\t\tAvg Score [100eps]: 1300.73 \t Steps: 3071\n",
      "\n",
      "Episode 1530: \tActor Loss: 0.20 \tCritic Loss: 2.01 71\n",
      "\t\tAvg Score [100eps]: 1324.11 \t Steps: 3071\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.20 \tCritic Loss: 1.97 71\n",
      "\t\tAvg Score [100eps]: 1342.64 \t Steps: 3071\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.20 \tCritic Loss: 1.94 71\n",
      "\t\tAvg Score [100eps]: 1402.64 \t Steps: 3071\n",
      "\n",
      "Episode 1560: \tActor Loss: 0.20 \tCritic Loss: 1.99 71\n",
      "\t\tAvg Score [100eps]: 1382.21 \t Steps: 3071\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.20 \tCritic Loss: 1.98 71\n",
      "\t\tAvg Score [100eps]: 1360.77 \t Steps: 3071\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.20 \tCritic Loss: 1.95 00\n",
      "\t\tAvg Score [100eps]: 1410.33 \t Steps: 1000\n",
      "\n",
      "Episode 1590: \tActor Loss: 0.19 \tCritic Loss: 1.94 71\n",
      "\t\tAvg Score [100eps]: 1288.33 \t Steps: 3071\n",
      "\n",
      "Episode 1600: \tActor Loss: 0.13 \tCritic Loss: 1.94 71\n",
      "\t\tAvg Score [100eps]: 1437.93 \t Steps: 3071\n",
      "\n",
      "Episode 1610: \tActor Loss: 0.13 \tCritic Loss: 1.95 71\n",
      "\t\tAvg Score [100eps]: 1481.05 \t Steps: 3071\n",
      "\n",
      "Episode 1620: \tActor Loss: 0.13 \tCritic Loss: 1.99 71\n",
      "\t\tAvg Score [100eps]: 1321.89 \t Steps: 3071\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1630: \tActor Loss: 0.13 \tCritic Loss: 1.95 00\n",
      "\t\tAvg Score [100eps]: 1471.01 \t Steps: 1000\n",
      "\n",
      "Episode 1640: \tActor Loss: 0.13 \tCritic Loss: 1.98 71\n",
      "\t\tAvg Score [100eps]: 1277.06 \t Steps: 3071\n",
      "\n",
      "Episode 1650: \tActor Loss: 0.13 \tCritic Loss: 2.04 71\n",
      "\t\tAvg Score [100eps]: 1307.78 \t Steps: 3071\n",
      "\n",
      "Episode 1660: \tActor Loss: 0.14 \tCritic Loss: 2.06 71\n",
      "\t\tAvg Score [100eps]: 1412.43 \t Steps: 3071\n",
      "\n",
      "Episode 1670: \tActor Loss: 0.14 \tCritic Loss: 2.09 71\n",
      "\t\tAvg Score [100eps]: 1412.35 \t Steps: 3071\n",
      "\n",
      "Episode 1680: \tActor Loss: 0.14 \tCritic Loss: 2.12 71\n",
      "\t\tAvg Score [100eps]: 1195.13 \t Steps: 3071\n",
      "\n",
      "Episode 1690: \tActor Loss: 0.14 \tCritic Loss: 2.19 71\n",
      "\t\tAvg Score [100eps]: 1325.19 \t Steps: 3071\n",
      "\n",
      "Episode 1700: \tActor Loss: 0.15 \tCritic Loss: 2.20 71\n",
      "\t\tAvg Score [100eps]: 1063.32 \t Steps: 3071\n",
      "\n",
      "Episode 1710: \tActor Loss: 0.15 \tCritic Loss: 2.24 71\n",
      "\t\tAvg Score [100eps]: 1185.12 \t Steps: 3071\n",
      "\n",
      "Episode 1720: \tActor Loss: 0.16 \tCritic Loss: 2.26 71\n",
      "\t\tAvg Score [100eps]: 1254.52 \t Steps: 3071\n",
      "\n",
      "Episode 1730: \tActor Loss: 0.17 \tCritic Loss: 2.32 71\n",
      "\t\tAvg Score [100eps]: 1353.86 \t Steps: 3071\n",
      "\n",
      "Episode 1740: \tActor Loss: 0.17 \tCritic Loss: 2.40 71\n",
      "\t\tAvg Score [100eps]: 1238.56 \t Steps: 3071\n",
      "\n",
      "Episode 1750: \tActor Loss: 0.18 \tCritic Loss: 2.42 71\n",
      "\t\tAvg Score [100eps]: 1314.72 \t Steps: 3071\n",
      "\n",
      "Episode 1760: \tActor Loss: 0.18 \tCritic Loss: 2.43 71\n",
      "\t\tAvg Score [100eps]: 1321.90 \t Steps: 3071\n",
      "\n",
      "Episode 1770: \tActor Loss: 0.19 \tCritic Loss: 2.48 71\n",
      "\t\tAvg Score [100eps]: 1268.90 \t Steps: 3071\n",
      "\n",
      "Episode 1780: \tActor Loss: 0.19 \tCritic Loss: 2.52 71\n",
      "\t\tAvg Score [100eps]: 1356.67 \t Steps: 3071\n",
      "\n",
      "Episode 1790: \tActor Loss: 0.19 \tCritic Loss: 2.50 71\n",
      "\t\tAvg Score [100eps]: 1487.85 \t Steps: 3071\n",
      "\n",
      "Episode 1800: \tActor Loss: 0.19 \tCritic Loss: 2.49 71\n",
      "\t\tAvg Score [100eps]: 1432.13 \t Steps: 3071\n",
      "\n",
      "Episode 1810: \tActor Loss: 0.18 \tCritic Loss: 2.43 71\n",
      "\t\tAvg Score [100eps]: 1425.51 \t Steps: 3071\n",
      "\n",
      "Episode 1820: \tActor Loss: 0.18 \tCritic Loss: 2.40 71\n",
      "\t\tAvg Score [100eps]: 1441.38 \t Steps: 3071\n",
      "\n",
      "Episode 1830: \tActor Loss: 0.18 \tCritic Loss: 2.37 71\n",
      "\t\tAvg Score [100eps]: 1344.25 \t Steps: 3071\n",
      "\n",
      "Episode 1840: \tActor Loss: 0.17 \tCritic Loss: 2.38 71\n",
      "\t\tAvg Score [100eps]: 1312.45 \t Steps: 3071\n",
      "\n",
      "Episode 1850: \tActor Loss: 0.17 \tCritic Loss: 2.35 71\n",
      "\t\tAvg Score [100eps]: 1454.70 \t Steps: 3071\n",
      "\n",
      "Episode 1860: \tActor Loss: 0.17 \tCritic Loss: 2.41 71\n",
      "\t\tAvg Score [100eps]: 1390.06 \t Steps: 3071\n",
      "\n",
      "Episode 1870: \tActor Loss: 0.17 \tCritic Loss: 2.39 00\n",
      "\t\tAvg Score [100eps]: 1474.43 \t Steps: 1000\n",
      "\n",
      "Episode 1880: \tActor Loss: 0.17 \tCritic Loss: 2.41 71\n",
      "\t\tAvg Score [100eps]: 1434.43 \t Steps: 3071\n",
      "\n",
      "Episode 1890: \tActor Loss: 0.17 \tCritic Loss: 2.45 71\n",
      "\t\tAvg Score [100eps]: 1559.02 \t Steps: 3071\n",
      "\n",
      "Episode 1900: \tActor Loss: 0.17 \tCritic Loss: 2.52 71\n",
      "\t\tAvg Score [100eps]: 1416.98 \t Steps: 3071\n",
      "\n",
      "Episode 1910: \tActor Loss: 0.17 \tCritic Loss: 2.61 71\n",
      "\t\tAvg Score [100eps]: 1390.81 \t Steps: 3071\n",
      "\n",
      "Episode 1920: \tActor Loss: 0.17 \tCritic Loss: 2.66 71\n",
      "\t\tAvg Score [100eps]: 1419.93 \t Steps: 3071\n",
      "\n",
      "Episode 1930: \tActor Loss: 0.17 \tCritic Loss: 2.72 71\n",
      "\t\tAvg Score [100eps]: 1370.86 \t Steps: 3071\n",
      "\n",
      "Episode 1940: \tActor Loss: 0.17 \tCritic Loss: 2.71 71\n",
      "\t\tAvg Score [100eps]: 1292.30 \t Steps: 3071\n",
      "\n",
      "Episode 1950: \tActor Loss: 0.18 \tCritic Loss: 2.76 11\n",
      "\t\tAvg Score [100eps]: 989.43 \t Steps: 3071\n",
      "\n",
      "Episode 1960: \tActor Loss: 0.18 \tCritic Loss: 2.83 71\n",
      "\t\tAvg Score [100eps]: 1142.10 \t Steps: 3071\n",
      "\n",
      "Episode 1970: \tActor Loss: 0.19 \tCritic Loss: 2.85 71\n",
      "\t\tAvg Score [100eps]: 1267.46 \t Steps: 3071\n",
      "\n",
      "Episode 1980: \tActor Loss: 0.19 \tCritic Loss: 2.87 71\n",
      "\t\tAvg Score [100eps]: 1337.73 \t Steps: 3071\n",
      "\n",
      "Episode 1983\t Score [This Eps]: 1285.07 \t Steps: 3071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-99096d027bf4>\", line 29, in <module>\n",
      "    ppo(params, logger)\n",
      "  File \"<ipython-input-7-c11e12c69666>\", line 27, in ppo\n",
      "    actions, log_probs, _, values = agent.act(states, agent.std_scale)\n",
      "  File \"scripts\\ppo_agent.py\", line 70, in act\n",
      "    action, log_prob, entropy, value = self.ppo_ac_net(state, std_scale=std_scale)  # stdev cannot = 0\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"scripts\\model.py\", line 257, in forward\n",
      "    log_prob, _, resampled_action, entropy = self.actor(s, resampled_action=action, std_scale=std_scale)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"scripts\\model.py\", line 149, in forward\n",
      "    s = self.PReLU(self.fc_1a(self.bn_1a(s))) #linear -> batchnorm -> activation\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 178, in forward\n",
      "    self.eps,\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\", line 2282, in batch_norm\n",
      "    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-99096d027bf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, resampled_action, std_scale)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# state, apply batch norm BEFORE activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#linear -> batchnorm -> activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2281\u001b[0m     return torch.batch_norm(\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# Increase std_scale_decay\n",
    "# Results: Negligible outcome\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 3072       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.std_scale_decay = 0.999\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.00015\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-08--20:40:26 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.08 \tCritic Loss: 0.16 \n",
      "\t\tAvg Score [100eps]: 65.45 \t Steps: 3071\n",
      "\n",
      "Episode 20: \tActor Loss: 0.19 \tCritic Loss: 0.80 1\n",
      "\t\tAvg Score [100eps]: 199.17 \t Steps: 3071\n",
      "\n",
      "Episode 30: \tActor Loss: 0.22 \tCritic Loss: 1.52 1\n",
      "\t\tAvg Score [100eps]: 327.36 \t Steps: 3071\n",
      "\n",
      "Episode 40: \tActor Loss: 0.24 \tCritic Loss: 1.83 1\n",
      "\t\tAvg Score [100eps]: 366.82 \t Steps: 3071\n",
      "\n",
      "Episode 50: \tActor Loss: 0.26 \tCritic Loss: 2.01 1\n",
      "\t\tAvg Score [100eps]: 311.27 \t Steps: 3071\n",
      "\n",
      "Episode 60: \tActor Loss: 0.29 \tCritic Loss: 1.99 1\n",
      "\t\tAvg Score [100eps]: 380.85 \t Steps: 3071\n",
      "\n",
      "Episode 70: \tActor Loss: 0.29 \tCritic Loss: 1.86 1\n",
      "\t\tAvg Score [100eps]: 351.40 \t Steps: 3071\n",
      "\n",
      "Episode 80: \tActor Loss: 0.36 \tCritic Loss: 1.73 1\n",
      "\t\tAvg Score [100eps]: 428.44 \t Steps: 3071\n",
      "\n",
      "Episode 90: \tActor Loss: 0.36 \tCritic Loss: 1.63 1\n",
      "\t\tAvg Score [100eps]: 493.03 \t Steps: 3071\n",
      "\n",
      "Episode 100: \tActor Loss: 0.35 \tCritic Loss: 1.54 1\n",
      "\t\tAvg Score [100eps]: 649.58 \t Steps: 3071\n",
      "\n",
      "Episode 110: \tActor Loss: 0.39 \tCritic Loss: 1.61 1\n",
      "\t\tAvg Score [100eps]: 478.50 \t Steps: 3071\n",
      "\n",
      "Episode 120: \tActor Loss: 0.43 \tCritic Loss: 1.57 1\n",
      "\t\tAvg Score [100eps]: 622.44 \t Steps: 3071\n",
      "\n",
      "Episode 130: \tActor Loss: 0.45 \tCritic Loss: 1.39 1\n",
      "\t\tAvg Score [100eps]: 610.47 \t Steps: 3071\n",
      "\n",
      "Episode 140: \tActor Loss: 0.46 \tCritic Loss: 1.21 1\n",
      "\t\tAvg Score [100eps]: 531.18 \t Steps: 3071\n",
      "\n",
      "Episode 150: \tActor Loss: 0.74 \tCritic Loss: 1.05 1\n",
      "\t\tAvg Score [100eps]: 744.34 \t Steps: 3071\n",
      "\n",
      "Episode 160: \tActor Loss: 0.72 \tCritic Loss: 0.98 1\n",
      "\t\tAvg Score [100eps]: 746.52 \t Steps: 3071\n",
      "\n",
      "Episode 170: \tActor Loss: 0.73 \tCritic Loss: 1.00 1\n",
      "\t\tAvg Score [100eps]: 853.58 \t Steps: 3071\n",
      "\n",
      "Episode 171\t Score [This Eps]: 779.61 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 180: \tActor Loss: 0.68 \tCritic Loss: 1.05 1\n",
      "\t\tAvg Score [100eps]: 905.01 \t Steps: 3071\n",
      "\n",
      "Episode 190: \tActor Loss: 0.67 \tCritic Loss: 1.09 1\n",
      "\t\tAvg Score [100eps]: 855.76 \t Steps: 3071\n",
      "\n",
      "Episode 200: \tActor Loss: 0.67 \tCritic Loss: 1.13 1\n",
      "\t\tAvg Score [100eps]: 785.71 \t Steps: 3071\n",
      "\n",
      "Episode 210: \tActor Loss: 0.69 \tCritic Loss: 1.16 1\n",
      "\t\tAvg Score [100eps]: 953.46 \t Steps: 3071\n",
      "\n",
      "Episode 220: \tActor Loss: 0.64 \tCritic Loss: 1.23 71\n",
      "\t\tAvg Score [100eps]: 1001.16 \t Steps: 3071\n",
      "\n",
      "Episode 230: \tActor Loss: 0.61 \tCritic Loss: 1.25 11\n",
      "\t\tAvg Score [100eps]: 963.82 \t Steps: 3071\n",
      "\n",
      "Episode 240: \tActor Loss: 0.59 \tCritic Loss: 1.30 71\n",
      "\t\tAvg Score [100eps]: 1003.28 \t Steps: 3071\n",
      "\n",
      "Episode 250: \tActor Loss: 0.30 \tCritic Loss: 1.32 1\n",
      "\t\tAvg Score [100eps]: 958.99 \t Steps: 3071\n",
      "\n",
      "Episode 260: \tActor Loss: 0.37 \tCritic Loss: 1.33 71\n",
      "\t\tAvg Score [100eps]: 1016.89 \t Steps: 3071\n",
      "\n",
      "Episode 270: \tActor Loss: 0.36 \tCritic Loss: 1.37 10\n",
      "\t\tAvg Score [100eps]: 817.48 \t Steps: 3071\n",
      "\n",
      "Episode 280: \tActor Loss: 0.35 \tCritic Loss: 1.38 71\n",
      "\t\tAvg Score [100eps]: 1005.16 \t Steps: 3071\n",
      "\n",
      "Episode 290: \tActor Loss: 0.34 \tCritic Loss: 1.41 00\n",
      "\t\tAvg Score [100eps]: 1056.12 \t Steps: 1000\n",
      "\n",
      "Episode 300: \tActor Loss: 0.33 \tCritic Loss: 1.43 11\n",
      "\t\tAvg Score [100eps]: 819.32 \t Steps: 3071\n",
      "\n",
      "Episode 310: \tActor Loss: 0.29 \tCritic Loss: 1.48 00\n",
      "\t\tAvg Score [100eps]: 1075.22 \t Steps: 1000\n",
      "\n",
      "Episode 320: \tActor Loss: 0.28 \tCritic Loss: 1.46 71\n",
      "\t\tAvg Score [100eps]: 1022.53 \t Steps: 3071\n",
      "\n",
      "Episode 330: \tActor Loss: 0.28 \tCritic Loss: 1.49 00\n",
      "\t\tAvg Score [100eps]: 1140.89 \t Steps: 1000\n",
      "\n",
      "Episode 340: \tActor Loss: 0.27 \tCritic Loss: 1.47 11\n",
      "\t\tAvg Score [100eps]: 893.74 \t Steps: 3071\n",
      "\n",
      "Episode 350: \tActor Loss: 0.26 \tCritic Loss: 1.48 71\n",
      "\t\tAvg Score [100eps]: 1114.51 \t Steps: 3071\n",
      "\n",
      "Episode 360: \tActor Loss: 0.18 \tCritic Loss: 1.49 71\n",
      "\t\tAvg Score [100eps]: 1119.23 \t Steps: 3071\n",
      "\n",
      "Episode 370: \tActor Loss: 0.18 \tCritic Loss: 1.47 71\n",
      "\t\tAvg Score [100eps]: 1187.33 \t Steps: 3071\n",
      "\n",
      "Episode 380: \tActor Loss: 0.18 \tCritic Loss: 1.49 71\n",
      "\t\tAvg Score [100eps]: 1217.49 \t Steps: 3071\n",
      "\n",
      "Episode 390: \tActor Loss: 0.18 \tCritic Loss: 1.52 00\n",
      "\t\tAvg Score [100eps]: 1260.45 \t Steps: 1000\n",
      "\n",
      "Episode 400: \tActor Loss: 0.17 \tCritic Loss: 1.58 00\n",
      "\t\tAvg Score [100eps]: 1226.67 \t Steps: 1000\n",
      "\n",
      "Episode 410: \tActor Loss: 0.17 \tCritic Loss: 1.58 11\n",
      "\t\tAvg Score [100eps]: 818.95 \t Steps: 3071\n",
      "\n",
      "Episode 420: \tActor Loss: 0.17 \tCritic Loss: 1.65 00\n",
      "\t\tAvg Score [100eps]: 1282.75 \t Steps: 1000\n",
      "\n",
      "Episode 430: \tActor Loss: 0.17 \tCritic Loss: 1.64 71\n",
      "\t\tAvg Score [100eps]: 1049.00 \t Steps: 3071\n",
      "\n",
      "Episode 440: \tActor Loss: 0.17 \tCritic Loss: 1.68 71\n",
      "\t\tAvg Score [100eps]: 1360.09 \t Steps: 3071\n",
      "\n",
      "Episode 450: \tActor Loss: 0.18 \tCritic Loss: 1.73 71\n",
      "\t\tAvg Score [100eps]: 1121.55 \t Steps: 3071\n",
      "\n",
      "Episode 460: \tActor Loss: 0.17 \tCritic Loss: 1.79 71\n",
      "\t\tAvg Score [100eps]: 1374.54 \t Steps: 3071\n",
      "\n",
      "Episode 470: \tActor Loss: 0.19 \tCritic Loss: 1.82 71\n",
      "\t\tAvg Score [100eps]: 1214.26 \t Steps: 3071\n",
      "\n",
      "Episode 480: \tActor Loss: 0.21 \tCritic Loss: 1.80 00\n",
      "\t\tAvg Score [100eps]: 1363.25 \t Steps: 1000\n",
      "\n",
      "Episode 490: \tActor Loss: 0.20 \tCritic Loss: 1.80 00\n",
      "\t\tAvg Score [100eps]: 1327.43 \t Steps: 1000\n",
      "\n",
      "Episode 500: \tActor Loss: 0.21 \tCritic Loss: 1.79 00\n",
      "\t\tAvg Score [100eps]: 1352.53 \t Steps: 1000\n",
      "\n",
      "Episode 510: \tActor Loss: 0.21 \tCritic Loss: 1.81 71\n",
      "\t\tAvg Score [100eps]: 1238.40 \t Steps: 3071\n",
      "\n",
      "Episode 520: \tActor Loss: 0.24 \tCritic Loss: 1.78 71\n",
      "\t\tAvg Score [100eps]: 1402.37 \t Steps: 3071\n",
      "\n",
      "Episode 530: \tActor Loss: 0.24 \tCritic Loss: 1.82 71\n",
      "\t\tAvg Score [100eps]: 1365.68 \t Steps: 3071\n",
      "\n",
      "Episode 540: \tActor Loss: 0.24 \tCritic Loss: 1.89 11\n",
      "\t\tAvg Score [100eps]: 743.39 \t Steps: 3071\n",
      "\n",
      "Episode 550: \tActor Loss: 0.23 \tCritic Loss: 1.91 71\n",
      "\t\tAvg Score [100eps]: 1472.63 \t Steps: 3071\n",
      "\n",
      "Episode 560: \tActor Loss: 0.23 \tCritic Loss: 1.89 71\n",
      "\t\tAvg Score [100eps]: 1328.81 \t Steps: 3071\n",
      "\n",
      "Episode 570: \tActor Loss: 0.21 \tCritic Loss: 2.00 11\n",
      "\t\tAvg Score [100eps]: 837.44 \t Steps: 3071\n",
      "\n",
      "Episode 580: \tActor Loss: 0.19 \tCritic Loss: 2.05 71\n",
      "\t\tAvg Score [100eps]: 1535.77 \t Steps: 3071\n",
      "\n",
      "Episode 590: \tActor Loss: 0.19 \tCritic Loss: 2.07 71\n",
      "\t\tAvg Score [100eps]: 1236.98 \t Steps: 3071\n",
      "\n",
      "Episode 600: \tActor Loss: 0.19 \tCritic Loss: 2.11 71\n",
      "\t\tAvg Score [100eps]: 1257.39 \t Steps: 3071\n",
      "\n",
      "Episode 610: \tActor Loss: 0.18 \tCritic Loss: 2.14 71\n",
      "\t\tAvg Score [100eps]: 1462.01 \t Steps: 3071\n",
      "\n",
      "Episode 620: \tActor Loss: 0.16 \tCritic Loss: 2.23 71\n",
      "\t\tAvg Score [100eps]: 1069.67 \t Steps: 3071\n",
      "\n",
      "Episode 630: \tActor Loss: 0.16 \tCritic Loss: 2.26 00\n",
      "\t\tAvg Score [100eps]: 1468.93 \t Steps: 1000\n",
      "\n",
      "Episode 640: \tActor Loss: 0.16 \tCritic Loss: 2.21 11\n",
      "\t\tAvg Score [100eps]: 874.02 \t Steps: 3071\n",
      "\n",
      "Episode 650: \tActor Loss: 0.16 \tCritic Loss: 2.27 00\n",
      "\t\tAvg Score [100eps]: 1448.71 \t Steps: 1000\n",
      "\n",
      "Episode 660: \tActor Loss: 0.16 \tCritic Loss: 2.30 71\n",
      "\t\tAvg Score [100eps]: 1358.34 \t Steps: 3071\n",
      "\n",
      "Episode 670: \tActor Loss: 0.17 \tCritic Loss: 2.96 11\n",
      "\t\tAvg Score [100eps]: 882.39 \t Steps: 3071\n",
      "\n",
      "Episode 680: \tActor Loss: 0.18 \tCritic Loss: 3.05 71\n",
      "\t\tAvg Score [100eps]: 1400.22 \t Steps: 3071\n",
      "\n",
      "Episode 690: \tActor Loss: 0.18 \tCritic Loss: 3.07 71\n",
      "\t\tAvg Score [100eps]: 1463.23 \t Steps: 3071\n",
      "\n",
      "Episode 700: \tActor Loss: 0.17 \tCritic Loss: 3.02 71\n",
      "\t\tAvg Score [100eps]: 1379.79 \t Steps: 3071\n",
      "\n",
      "Episode 710: \tActor Loss: 0.17 \tCritic Loss: 2.99 71\n",
      "\t\tAvg Score [100eps]: 1400.70 \t Steps: 3071\n",
      "\n",
      "Episode 720: \tActor Loss: 0.17 \tCritic Loss: 2.94 71\n",
      "\t\tAvg Score [100eps]: 1456.16 \t Steps: 3071\n",
      "\n",
      "Episode 730: \tActor Loss: 0.17 \tCritic Loss: 2.90 71\n",
      "\t\tAvg Score [100eps]: 1381.01 \t Steps: 3071\n",
      "\n",
      "Episode 740: \tActor Loss: 0.17 \tCritic Loss: 2.86 71\n",
      "\t\tAvg Score [100eps]: 1389.42 \t Steps: 3071\n",
      "\n",
      "Episode 750: \tActor Loss: 0.18 \tCritic Loss: 2.89 71\n",
      "\t\tAvg Score [100eps]: 1087.89 \t Steps: 3071\n",
      "\n",
      "Episode 760: \tActor Loss: 0.18 \tCritic Loss: 2.87 71\n",
      "\t\tAvg Score [100eps]: 1426.14 \t Steps: 3071\n",
      "\n",
      "Episode 770: \tActor Loss: 0.17 \tCritic Loss: 2.11 71\n",
      "\t\tAvg Score [100eps]: 1451.05 \t Steps: 3071\n",
      "\n",
      "Episode 780: \tActor Loss: 0.16 \tCritic Loss: 1.98 71\n",
      "\t\tAvg Score [100eps]: 1584.62 \t Steps: 3071\n",
      "\n",
      "Episode 790: \tActor Loss: 0.18 \tCritic Loss: 2.05 00\n",
      "\t\tAvg Score [100eps]: 1044.68 \t Steps: 1000\n",
      "\n",
      "Episode 800: \tActor Loss: 0.19 \tCritic Loss: 2.06 00\n",
      "\t\tAvg Score [100eps]: 1346.75 \t Steps: 1000\n",
      "\n",
      "Episode 810: \tActor Loss: 0.19 \tCritic Loss: 2.08 71\n",
      "\t\tAvg Score [100eps]: 1388.46 \t Steps: 3071\n",
      "\n",
      "Episode 820: \tActor Loss: 0.20 \tCritic Loss: 2.15 00\n",
      "\t\tAvg Score [100eps]: 1510.98 \t Steps: 1000\n",
      "\n",
      "Episode 830: \tActor Loss: 0.20 \tCritic Loss: 2.29 11\n",
      "\t\tAvg Score [100eps]: 982.50 \t Steps: 3071\n",
      "\n",
      "Episode 840: \tActor Loss: 0.20 \tCritic Loss: 2.39 71\n",
      "\t\tAvg Score [100eps]: 1659.53 \t Steps: 3071\n",
      "\n",
      "Episode 850: \tActor Loss: 0.22 \tCritic Loss: 2.32 71\n",
      "\t\tAvg Score [100eps]: 1506.46 \t Steps: 3071\n",
      "\n",
      "Episode 860: \tActor Loss: 0.23 \tCritic Loss: 2.34 00\n",
      "\t\tAvg Score [100eps]: 1596.88 \t Steps: 1000\n",
      "\n",
      "Episode 870: \tActor Loss: 0.23 \tCritic Loss: 2.36 00\n",
      "\t\tAvg Score [100eps]: 1553.88 \t Steps: 1000\n",
      "\n",
      "Episode 880: \tActor Loss: 0.22 \tCritic Loss: 2.41 71\n",
      "\t\tAvg Score [100eps]: 1713.55 \t Steps: 3071\n",
      "\n",
      "Episode 890: \tActor Loss: 0.21 \tCritic Loss: 2.33 71\n",
      "\t\tAvg Score [100eps]: 1581.81 \t Steps: 3071\n",
      "\n",
      "Episode 900: \tActor Loss: 0.22 \tCritic Loss: 2.37 71\n",
      "\t\tAvg Score [100eps]: 1589.91 \t Steps: 3071\n",
      "\n",
      "Episode 910: \tActor Loss: 0.22 \tCritic Loss: 2.39 71\n",
      "\t\tAvg Score [100eps]: 1530.44 \t Steps: 3071\n",
      "\n",
      "Episode 920: \tActor Loss: 0.21 \tCritic Loss: 2.33 00\n",
      "\t\tAvg Score [100eps]: 1470.84 \t Steps: 1000\n",
      "\n",
      "Episode 930: \tActor Loss: 0.21 \tCritic Loss: 2.23 71\n",
      "\t\tAvg Score [100eps]: 1721.94 \t Steps: 3071\n",
      "\n",
      "Episode 940: \tActor Loss: 0.35 \tCritic Loss: 2.16 00\n",
      "\t\tAvg Score [100eps]: 1691.37 \t Steps: 1000\n",
      "\n",
      "Episode 950: \tActor Loss: 0.34 \tCritic Loss: 2.16 71\n",
      "\t\tAvg Score [100eps]: 1681.62 \t Steps: 3071\n",
      "\n",
      "Episode 960: \tActor Loss: 0.34 \tCritic Loss: 2.18 00\n",
      "\t\tAvg Score [100eps]: 1741.08 \t Steps: 1000\n",
      "\n",
      "Episode 970: \tActor Loss: 0.33 \tCritic Loss: 2.23 00\n",
      "\t\tAvg Score [100eps]: 1773.72 \t Steps: 1000\n",
      "\n",
      "Episode 980: \tActor Loss: 0.34 \tCritic Loss: 2.23 00\n",
      "\t\tAvg Score [100eps]: 1735.74 \t Steps: 1000\n",
      "\n",
      "Episode 990: \tActor Loss: 0.35 \tCritic Loss: 2.27 00\n",
      "\t\tAvg Score [100eps]: 1642.58 \t Steps: 1000\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.36 \tCritic Loss: 2.29 00\n",
      "\t\tAvg Score [100eps]: 1696.42 \t Steps: 1000\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.36 \tCritic Loss: 2.32 00\n",
      "\t\tAvg Score [100eps]: 1733.78 \t Steps: 1000\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.36 \tCritic Loss: 2.40 71\n",
      "\t\tAvg Score [100eps]: 1803.35 \t Steps: 3071\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.36 \tCritic Loss: 2.47 00\n",
      "\t\tAvg Score [100eps]: 1795.50 \t Steps: 1000\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.22 \tCritic Loss: 2.56 00\n",
      "\t\tAvg Score [100eps]: 1649.03 \t Steps: 1000\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.21 \tCritic Loss: 2.62 00\n",
      "\t\tAvg Score [100eps]: 1728.03 \t Steps: 1000\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.21 \tCritic Loss: 2.69 00\n",
      "\t\tAvg Score [100eps]: 1759.89 \t Steps: 1000\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.21 \tCritic Loss: 2.73 00\n",
      "\t\tAvg Score [100eps]: 1651.85 \t Steps: 1000\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.21 \tCritic Loss: 2.79 00\n",
      "\t\tAvg Score [100eps]: 1685.91 \t Steps: 1000\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.21 \tCritic Loss: 2.84 71\n",
      "\t\tAvg Score [100eps]: 1671.48 \t Steps: 3071\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.20 \tCritic Loss: 4.89 11\n",
      "\t\tAvg Score [100eps]: 284.20 \t Steps: 3071\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.21 \tCritic Loss: 6.46 71\n",
      "\t\tAvg Score [100eps]: 1259.38 \t Steps: 3071\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.23 \tCritic Loss: 6.52 00\n",
      "\t\tAvg Score [100eps]: 1664.81 \t Steps: 1000\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.24 \tCritic Loss: 6.54 00\n",
      "\t\tAvg Score [100eps]: 1305.81 \t Steps: 1000\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.26 \tCritic Loss: 14.55 1\n",
      "\t\tAvg Score [100eps]: 18.99 \t Steps: 3071\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.28 \tCritic Loss: 24.20 \n",
      "\t\tAvg Score [100eps]: 90.20 \t Steps: 3071\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.29 \tCritic Loss: 30.36 \n",
      "\t\tAvg Score [100eps]: 394.57 \t Steps: 3071\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.30 \tCritic Loss: 34.16 \n",
      "\t\tAvg Score [100eps]: 163.03 \t Steps: 3071\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.32 \tCritic Loss: 42.06 \n",
      "\t\tAvg Score [100eps]: 75.14 \t Steps: 3071\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.33 \tCritic Loss: 50.80 \n",
      "\t\tAvg Score [100eps]: 52.48 \t Steps: 3071\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.33 \tCritic Loss: 57.41 \n",
      "\t\tAvg Score [100eps]: 30.14 \t Steps: 3071\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.33 \tCritic Loss: 62.68 \n",
      "\t\tAvg Score [100eps]: 65.49 \t Steps: 3071\n",
      "\n",
      "Episode 1220: \tActor Loss: 0.32 \tCritic Loss: 65.35 \n",
      "\t\tAvg Score [100eps]: 391.99 \t Steps: 3071\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.32 \tCritic Loss: 68.35 \n",
      "\t\tAvg Score [100eps]: 378.54 \t Steps: 3071\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.32 \tCritic Loss: 63.64 \n",
      "\t\tAvg Score [100eps]: 424.70 \t Steps: 3071\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.31 \tCritic Loss: 57.19 \n",
      "\t\tAvg Score [100eps]: 439.44 \t Steps: 1000\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.31 \tCritic Loss: 53.37 \n",
      "\t\tAvg Score [100eps]: 476.01 \t Steps: 1000\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.31 \tCritic Loss: 50.79 \n",
      "\t\tAvg Score [100eps]: 506.08 \t Steps: 3071\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.32 \tCritic Loss: 43.96 \n",
      "\t\tAvg Score [100eps]: 607.34 \t Steps: 1000\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.31 \tCritic Loss: 35.91 \n",
      "\t\tAvg Score [100eps]: 639.53 \t Steps: 1000\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.58 \tCritic Loss: 28.07 \n",
      "\t\tAvg Score [100eps]: 619.73 \t Steps: 1000\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.59 \tCritic Loss: 22.14 \n",
      "\t\tAvg Score [100eps]: 591.12 \t Steps: 1000\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.59 \tCritic Loss: 19.97 \n",
      "\t\tAvg Score [100eps]: 626.27 \t Steps: 1000\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.59 \tCritic Loss: 17.46 \n",
      "\t\tAvg Score [100eps]: 634.95 \t Steps: 3071\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.60 \tCritic Loss: 14.80 \n",
      "\t\tAvg Score [100eps]: 586.06 \t Steps: 1000\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.60 \tCritic Loss: 12.72 \n",
      "\t\tAvg Score [100eps]: 504.47 \t Steps: 1000\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.60 \tCritic Loss: 10.79 \n",
      "\t\tAvg Score [100eps]: 604.28 \t Steps: 1000\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.60 \tCritic Loss: 9.86 0\n",
      "\t\tAvg Score [100eps]: 614.23 \t Steps: 1000\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.60 \tCritic Loss: 9.01 0\n",
      "\t\tAvg Score [100eps]: 639.75 \t Steps: 1000\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.60 \tCritic Loss: 8.52 0\n",
      "\t\tAvg Score [100eps]: 613.88 \t Steps: 1000\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.33 \tCritic Loss: 7.70 0\n",
      "\t\tAvg Score [100eps]: 708.15 \t Steps: 1000\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.34 \tCritic Loss: 6.85 1\n",
      "\t\tAvg Score [100eps]: 700.16 \t Steps: 3071\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.34 \tCritic Loss: 6.47 0\n",
      "\t\tAvg Score [100eps]: 747.54 \t Steps: 1000\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.34 \tCritic Loss: 6.04 1\n",
      "\t\tAvg Score [100eps]: 754.37 \t Steps: 3071\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.33 \tCritic Loss: 5.74 0\n",
      "\t\tAvg Score [100eps]: 674.25 \t Steps: 1000\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.34 \tCritic Loss: 5.28 0\n",
      "\t\tAvg Score [100eps]: 716.76 \t Steps: 1000\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.33 \tCritic Loss: 6.13 0\n",
      "\t\tAvg Score [100eps]: 707.85 \t Steps: 1000\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.33 \tCritic Loss: 7.74 0\n",
      "\t\tAvg Score [100eps]: 621.99 \t Steps: 1000\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.32 \tCritic Loss: 9.85 0\n",
      "\t\tAvg Score [100eps]: 529.74 \t Steps: 1000\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.32 \tCritic Loss: 11.22 \n",
      "\t\tAvg Score [100eps]: 439.55 \t Steps: 1000\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.32 \tCritic Loss: 12.74 \n",
      "\t\tAvg Score [100eps]: 553.83 \t Steps: 1000\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.31 \tCritic Loss: 14.39 \n",
      "\t\tAvg Score [100eps]: 474.24 \t Steps: 1000\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.31 \tCritic Loss: 16.18 \n",
      "\t\tAvg Score [100eps]: 511.10 \t Steps: 3071\n",
      "\n",
      "Episode 1525\t Score [This Eps]: 361.09 \t Steps: 1000NaN next_states Found! Skipping this episode.\n",
      "Episode 1530: \tActor Loss: 0.30 \tCritic Loss: 17.96 \n",
      "\t\tAvg Score [100eps]: 428.94 \t Steps: 3071\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.30 \tCritic Loss: 19.69 \n",
      "\t\tAvg Score [100eps]: 550.04 \t Steps: 1000\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.30 \tCritic Loss: 21.03 \n",
      "\t\tAvg Score [100eps]: 426.62 \t Steps: 1000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-41e01d72f4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, resampled_action, std_scale)\u001b[0m\n\u001b[0;32m    158\u001b[0m         dist = torch.distributions.Normal(action_mean, F.hardtanh(self.std,\n\u001b[0;32m    159\u001b[0m                                                                   \u001b[0mmin_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                                                                   max_val=0.5*std_scale))\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# sample from the prob distribution just generated again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresampled_action\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\distributions\\normal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# skip checking lazily-constructed args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# Increase starting Learning Rate\n",
    "# Results: \n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 3072       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.lr = 1.5e-4\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.00015\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-09--08:30:22 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.14 \n",
      "\t\tAvg Score [100eps]: 50.40 \t Steps: 3071\n",
      "\n",
      "Episode 20: \tActor Loss: 0.14 \tCritic Loss: 0.97 1\n",
      "\t\tAvg Score [100eps]: 252.01 \t Steps: 3071\n",
      "\n",
      "Episode 30: \tActor Loss: 0.18 \tCritic Loss: 2.15 1\n",
      "\t\tAvg Score [100eps]: 287.21 \t Steps: 3071\n",
      "\n",
      "Episode 40: \tActor Loss: 0.19 \tCritic Loss: 3.03 1\n",
      "\t\tAvg Score [100eps]: 357.20 \t Steps: 3071\n",
      "\n",
      "Episode 50: \tActor Loss: 0.25 \tCritic Loss: 3.22 1\n",
      "\t\tAvg Score [100eps]: 385.54 \t Steps: 3071\n",
      "\n",
      "Episode 60: \tActor Loss: 0.24 \tCritic Loss: 3.42 0\n",
      "\t\tAvg Score [100eps]: 455.49 \t Steps: 1000\n",
      "\n",
      "Episode 70: \tActor Loss: 0.22 \tCritic Loss: 3.54 1\n",
      "\t\tAvg Score [100eps]: 514.51 \t Steps: 3071\n",
      "\n",
      "Episode 80: \tActor Loss: 0.22 \tCritic Loss: 3.47 1\n",
      "\t\tAvg Score [100eps]: 548.15 \t Steps: 3071\n",
      "\n",
      "Episode 90: \tActor Loss: 0.21 \tCritic Loss: 3.50 1\n",
      "\t\tAvg Score [100eps]: 572.60 \t Steps: 3071\n",
      "\n",
      "Episode 100: \tActor Loss: 0.20 \tCritic Loss: 3.44 0\n",
      "\t\tAvg Score [100eps]: 620.01 \t Steps: 1000\n",
      "\n",
      "Episode 110: \tActor Loss: 0.22 \tCritic Loss: 3.68 1\n",
      "\t\tAvg Score [100eps]: 657.24 \t Steps: 3071\n",
      "\n",
      "Episode 120: \tActor Loss: 0.21 \tCritic Loss: 3.72 1\n",
      "\t\tAvg Score [100eps]: 708.95 \t Steps: 3071\n",
      "\n",
      "Episode 130: \tActor Loss: 0.20 \tCritic Loss: 3.45 1\n",
      "\t\tAvg Score [100eps]: 641.30 \t Steps: 3071\n",
      "\n",
      "Episode 140: \tActor Loss: 0.19 \tCritic Loss: 3.05 1\n",
      "\t\tAvg Score [100eps]: 710.78 \t Steps: 3071\n",
      "\n",
      "Episode 150: \tActor Loss: 0.16 \tCritic Loss: 2.83 1\n",
      "\t\tAvg Score [100eps]: 663.61 \t Steps: 3071\n",
      "\n",
      "Episode 160: \tActor Loss: 0.15 \tCritic Loss: 2.57 1\n",
      "\t\tAvg Score [100eps]: 823.48 \t Steps: 3071\n",
      "\n",
      "Episode 170: \tActor Loss: 0.16 \tCritic Loss: 2.29 1\n",
      "\t\tAvg Score [100eps]: 707.22 \t Steps: 3071\n",
      "\n",
      "Episode 180: \tActor Loss: 0.17 \tCritic Loss: 2.15 1\n",
      "\t\tAvg Score [100eps]: 570.31 \t Steps: 3071\n",
      "\n",
      "Episode 190: \tActor Loss: 0.17 \tCritic Loss: 1.94 1\n",
      "\t\tAvg Score [100eps]: 577.05 \t Steps: 3071\n",
      "\n",
      "Episode 200: \tActor Loss: 0.17 \tCritic Loss: 1.81 1\n",
      "\t\tAvg Score [100eps]: 710.63 \t Steps: 3071\n",
      "\n",
      "Episode 210: \tActor Loss: 0.18 \tCritic Loss: 1.79 1\n",
      "\t\tAvg Score [100eps]: 676.68 \t Steps: 3071\n",
      "\n",
      "Episode 220: \tActor Loss: 0.18 \tCritic Loss: 1.79 1\n",
      "\t\tAvg Score [100eps]: 492.82 \t Steps: 3071\n",
      "\n",
      "Episode 230: \tActor Loss: 0.18 \tCritic Loss: 1.78 1\n",
      "\t\tAvg Score [100eps]: 848.89 \t Steps: 3071\n",
      "\n",
      "Episode 240: \tActor Loss: 0.19 \tCritic Loss: 1.79 0\n",
      "\t\tAvg Score [100eps]: 992.04 \t Steps: 1000\n",
      "\n",
      "Episode 250: \tActor Loss: 0.20 \tCritic Loss: 1.79 10\n",
      "\t\tAvg Score [100eps]: 726.29 \t Steps: 3071\n",
      "\n",
      "Episode 260: \tActor Loss: 0.19 \tCritic Loss: 1.79 0\n",
      "\t\tAvg Score [100eps]: 949.51 \t Steps: 1000\n",
      "\n",
      "Episode 270: \tActor Loss: 0.19 \tCritic Loss: 1.80 1\n",
      "\t\tAvg Score [100eps]: 778.18 \t Steps: 3071\n",
      "\n",
      "Episode 280: \tActor Loss: 0.18 \tCritic Loss: 1.83 00\n",
      "\t\tAvg Score [100eps]: 1002.10 \t Steps: 1000\n",
      "\n",
      "Episode 286\t Score [This Eps]: 1041.61 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 290: \tActor Loss: 0.18 \tCritic Loss: 1.86 1\n",
      "\t\tAvg Score [100eps]: 552.68 \t Steps: 3071\n",
      "\n",
      "Episode 300: \tActor Loss: 0.19 \tCritic Loss: 1.90 1\n",
      "\t\tAvg Score [100eps]: 777.34 \t Steps: 3071\n",
      "\n",
      "Episode 310: \tActor Loss: 0.19 \tCritic Loss: 1.92 00\n",
      "\t\tAvg Score [100eps]: 1039.36 \t Steps: 1000\n",
      "\n",
      "Episode 320: \tActor Loss: 0.18 \tCritic Loss: 1.86 11\n",
      "\t\tAvg Score [100eps]: 995.31 \t Steps: 3071\n",
      "\n",
      "Episode 330: \tActor Loss: 0.18 \tCritic Loss: 1.87 0\n",
      "\t\tAvg Score [100eps]: 972.23 \t Steps: 1000\n",
      "\n",
      "Episode 340: \tActor Loss: 0.17 \tCritic Loss: 1.89 1\n",
      "\t\tAvg Score [100eps]: 878.07 \t Steps: 3071\n",
      "\n",
      "Episode 348\t Score [This Eps]: 880.43 \t Steps: 30711NaN next_states Found! Skipping this episode.\n",
      "Episode 350: \tActor Loss: 0.16 \tCritic Loss: 1.91 1\n",
      "\t\tAvg Score [100eps]: 559.40 \t Steps: 3071\n",
      "\n",
      "Episode 360: \tActor Loss: 0.17 \tCritic Loss: 1.95 71\n",
      "\t\tAvg Score [100eps]: 1032.81 \t Steps: 3071\n",
      "\n",
      "Episode 370: \tActor Loss: 0.17 \tCritic Loss: 1.99 1\n",
      "\t\tAvg Score [100eps]: 890.53 \t Steps: 3071\n",
      "\n",
      "Episode 380: \tActor Loss: 0.17 \tCritic Loss: 1.99 71\n",
      "\t\tAvg Score [100eps]: 1072.49 \t Steps: 3071\n",
      "\n",
      "Episode 390: \tActor Loss: 0.17 \tCritic Loss: 1.98 71\n",
      "\t\tAvg Score [100eps]: 1096.45 \t Steps: 3071\n",
      "\n",
      "Episode 400: \tActor Loss: 0.17 \tCritic Loss: 2.00 71\n",
      "\t\tAvg Score [100eps]: 1063.30 \t Steps: 3071\n",
      "\n",
      "Episode 410: \tActor Loss: 0.17 \tCritic Loss: 1.99 00\n",
      "\t\tAvg Score [100eps]: 1128.92 \t Steps: 1000\n",
      "\n",
      "Episode 420: \tActor Loss: 0.17 \tCritic Loss: 1.99 71\n",
      "\t\tAvg Score [100eps]: 1155.18 \t Steps: 3071\n",
      "\n",
      "Episode 430: \tActor Loss: 0.17 \tCritic Loss: 2.03 11\n",
      "\t\tAvg Score [100eps]: 938.02 \t Steps: 3071\n",
      "\n",
      "Episode 440: \tActor Loss: 0.17 \tCritic Loss: 2.09 11\n",
      "\t\tAvg Score [100eps]: 944.14 \t Steps: 3071\n",
      "\n",
      "Episode 450: \tActor Loss: 0.18 \tCritic Loss: 2.09 71\n",
      "\t\tAvg Score [100eps]: 1225.46 \t Steps: 3071\n",
      "\n",
      "Episode 460: \tActor Loss: 0.17 \tCritic Loss: 2.09 71\n",
      "\t\tAvg Score [100eps]: 1181.18 \t Steps: 3071\n",
      "\n",
      "Episode 470: \tActor Loss: 0.18 \tCritic Loss: 2.13 71\n",
      "\t\tAvg Score [100eps]: 1233.46 \t Steps: 3071\n",
      "\n",
      "Episode 480: \tActor Loss: 0.17 \tCritic Loss: 2.16 71\n",
      "\t\tAvg Score [100eps]: 1094.72 \t Steps: 3071\n",
      "\n",
      "Episode 490: \tActor Loss: 0.17 \tCritic Loss: 2.19 71\n",
      "\t\tAvg Score [100eps]: 1208.38 \t Steps: 3071\n",
      "\n",
      "Episode 500: \tActor Loss: 0.16 \tCritic Loss: 2.21 71\n",
      "\t\tAvg Score [100eps]: 1268.36 \t Steps: 3071\n",
      "\n",
      "Episode 510: \tActor Loss: 0.16 \tCritic Loss: 2.28 71\n",
      "\t\tAvg Score [100eps]: 1158.68 \t Steps: 3071\n",
      "\n",
      "Episode 520: \tActor Loss: 0.15 \tCritic Loss: 2.33 71\n",
      "\t\tAvg Score [100eps]: 1223.48 \t Steps: 3071\n",
      "\n",
      "Episode 530: \tActor Loss: 0.15 \tCritic Loss: 2.36 71\n",
      "\t\tAvg Score [100eps]: 1218.06 \t Steps: 3071\n",
      "\n",
      "Episode 540: \tActor Loss: 0.15 \tCritic Loss: 2.35 71\n",
      "\t\tAvg Score [100eps]: 1272.45 \t Steps: 3071\n",
      "\n",
      "Episode 550: \tActor Loss: 0.14 \tCritic Loss: 2.37 71\n",
      "\t\tAvg Score [100eps]: 1259.71 \t Steps: 3071\n",
      "\n",
      "Episode 560: \tActor Loss: 0.14 \tCritic Loss: 2.43 00\n",
      "\t\tAvg Score [100eps]: 1306.64 \t Steps: 1000\n",
      "\n",
      "Episode 570: \tActor Loss: 0.12 \tCritic Loss: 2.50 71\n",
      "\t\tAvg Score [100eps]: 1257.28 \t Steps: 3071\n",
      "\n",
      "Episode 580: \tActor Loss: 0.12 \tCritic Loss: 2.61 00\n",
      "\t\tAvg Score [100eps]: 1386.43 \t Steps: 1000\n",
      "\n",
      "Episode 590: \tActor Loss: 0.12 \tCritic Loss: 2.70 71\n",
      "\t\tAvg Score [100eps]: 1396.25 \t Steps: 3071\n",
      "\n",
      "Episode 600: \tActor Loss: 0.12 \tCritic Loss: 2.77 71\n",
      "\t\tAvg Score [100eps]: 1426.66 \t Steps: 3071\n",
      "\n",
      "Episode 610: \tActor Loss: 0.12 \tCritic Loss: 2.89 71\n",
      "\t\tAvg Score [100eps]: 1453.47 \t Steps: 3071\n",
      "\n",
      "Episode 620: \tActor Loss: 0.12 \tCritic Loss: 3.04 71\n",
      "\t\tAvg Score [100eps]: 1421.94 \t Steps: 3071\n",
      "\n",
      "Episode 630: \tActor Loss: 0.12 \tCritic Loss: 3.16 71\n",
      "\t\tAvg Score [100eps]: 1417.46 \t Steps: 3071\n",
      "\n",
      "Episode 640: \tActor Loss: 0.12 \tCritic Loss: 3.25 71\n",
      "\t\tAvg Score [100eps]: 1477.25 \t Steps: 3071\n",
      "\n",
      "Episode 650: \tActor Loss: 0.12 \tCritic Loss: 3.35 71\n",
      "\t\tAvg Score [100eps]: 1442.47 \t Steps: 3071\n",
      "\n",
      "Episode 660: \tActor Loss: 0.12 \tCritic Loss: 3.45 71\n",
      "\t\tAvg Score [100eps]: 1594.93 \t Steps: 3071\n",
      "\n",
      "Episode 670: \tActor Loss: 0.12 \tCritic Loss: 3.50 71\n",
      "\t\tAvg Score [100eps]: 1524.15 \t Steps: 3071\n",
      "\n",
      "Episode 680: \tActor Loss: 0.13 \tCritic Loss: 3.47 71\n",
      "\t\tAvg Score [100eps]: 1339.60 \t Steps: 3071\n",
      "\n",
      "Episode 690: \tActor Loss: 0.13 \tCritic Loss: 3.45 71\n",
      "\t\tAvg Score [100eps]: 1321.05 \t Steps: 3071\n",
      "\n",
      "Episode 700: \tActor Loss: 0.13 \tCritic Loss: 3.50 71\n",
      "\t\tAvg Score [100eps]: 1505.71 \t Steps: 3071\n",
      "\n",
      "Episode 710: \tActor Loss: 0.13 \tCritic Loss: 3.44 71\n",
      "\t\tAvg Score [100eps]: 1474.58 \t Steps: 3071\n",
      "\n",
      "Episode 720: \tActor Loss: 0.13 \tCritic Loss: 3.47 00\n",
      "\t\tAvg Score [100eps]: 1594.82 \t Steps: 1000\n",
      "\n",
      "Episode 730: \tActor Loss: 0.13 \tCritic Loss: 3.49 71\n",
      "\t\tAvg Score [100eps]: 1526.25 \t Steps: 3071\n",
      "\n",
      "Episode 740: \tActor Loss: 0.13 \tCritic Loss: 3.52 71\n",
      "\t\tAvg Score [100eps]: 1396.93 \t Steps: 3071\n",
      "\n",
      "Episode 750: \tActor Loss: 0.13 \tCritic Loss: 3.53 71\n",
      "\t\tAvg Score [100eps]: 1509.08 \t Steps: 3071\n",
      "\n",
      "Episode 760: \tActor Loss: 0.13 \tCritic Loss: 3.51 71\n",
      "\t\tAvg Score [100eps]: 1540.93 \t Steps: 3071\n",
      "\n",
      "Episode 770: \tActor Loss: 0.14 \tCritic Loss: 3.69 00\n",
      "\t\tAvg Score [100eps]: 1616.67 \t Steps: 1000\n",
      "\n",
      "Episode 780: \tActor Loss: 0.14 \tCritic Loss: 3.79 71\n",
      "\t\tAvg Score [100eps]: 1343.63 \t Steps: 3071\n",
      "\n",
      "Episode 790: \tActor Loss: 0.15 \tCritic Loss: 3.86 71\n",
      "\t\tAvg Score [100eps]: 1415.49 \t Steps: 3071\n",
      "\n",
      "Episode 800: \tActor Loss: 0.16 \tCritic Loss: 3.99 71\n",
      "\t\tAvg Score [100eps]: 1180.99 \t Steps: 3071\n",
      "\n",
      "Episode 810: \tActor Loss: 0.16 \tCritic Loss: 4.12 71\n",
      "\t\tAvg Score [100eps]: 1411.53 \t Steps: 3071\n",
      "\n",
      "Episode 820: \tActor Loss: 0.17 \tCritic Loss: 4.16 11\n",
      "\t\tAvg Score [100eps]: 802.56 \t Steps: 3071\n",
      "\n",
      "Episode 830: \tActor Loss: 0.18 \tCritic Loss: 4.23 71\n",
      "\t\tAvg Score [100eps]: 1249.37 \t Steps: 3071\n",
      "\n",
      "Episode 835\t Score [This Eps]: 1218.56 \t Steps: 3071NaN Reward Found! Skipping this episode.\n",
      "Episode 840: \tActor Loss: 0.18 \tCritic Loss: 4.33 71\n",
      "\t\tAvg Score [100eps]: 1501.10 \t Steps: 3071\n",
      "\n",
      "Episode 850: \tActor Loss: 0.19 \tCritic Loss: 4.49 71\n",
      "\t\tAvg Score [100eps]: 1222.19 \t Steps: 3071\n",
      "\n",
      "Episode 860: \tActor Loss: 0.20 \tCritic Loss: 4.61 11\n",
      "\t\tAvg Score [100eps]: 502.01 \t Steps: 3071\n",
      "\n",
      "Episode 870: \tActor Loss: 0.20 \tCritic Loss: 4.56 11\n",
      "\t\tAvg Score [100eps]: 828.89 \t Steps: 3071\n",
      "\n",
      "Episode 880: \tActor Loss: 0.20 \tCritic Loss: 4.57 71\n",
      "\t\tAvg Score [100eps]: 1492.68 \t Steps: 3071\n",
      "\n",
      "Episode 890: \tActor Loss: 0.21 \tCritic Loss: 4.65 71\n",
      "\t\tAvg Score [100eps]: 1595.20 \t Steps: 3071\n",
      "\n",
      "Episode 900: \tActor Loss: 0.20 \tCritic Loss: 4.62 71\n",
      "\t\tAvg Score [100eps]: 1576.48 \t Steps: 3071\n",
      "\n",
      "Episode 910: \tActor Loss: 0.21 \tCritic Loss: 4.61 71\n",
      "\t\tAvg Score [100eps]: 1524.35 \t Steps: 3071\n",
      "\n",
      "Episode 920: \tActor Loss: 0.22 \tCritic Loss: 4.64 11\n",
      "\t\tAvg Score [100eps]: 661.61 \t Steps: 3071\n",
      "\n",
      "Episode 930: \tActor Loss: 0.22 \tCritic Loss: 4.57 11\n",
      "\t\tAvg Score [100eps]: 863.85 \t Steps: 3071\n",
      "\n",
      "Episode 940: \tActor Loss: 0.22 \tCritic Loss: 4.53 1\n",
      "\t\tAvg Score [100eps]: 704.01 \t Steps: 3071\n",
      "\n",
      "Episode 950: \tActor Loss: 0.23 \tCritic Loss: 4.60 1\n",
      "\t\tAvg Score [100eps]: 674.11 \t Steps: 3071\n",
      "\n",
      "Episode 960: \tActor Loss: 0.24 \tCritic Loss: 5.29 00\n",
      "\t\tAvg Score [100eps]: 1215.29 \t Steps: 1000\n",
      "\n",
      "Episode 970: \tActor Loss: 0.24 \tCritic Loss: 5.39 71\n",
      "\t\tAvg Score [100eps]: 1410.39 \t Steps: 3071\n",
      "\n",
      "Episode 980: \tActor Loss: 0.24 \tCritic Loss: 5.40 71\n",
      "\t\tAvg Score [100eps]: 1476.80 \t Steps: 3071\n",
      "\n",
      "Episode 990: \tActor Loss: 0.25 \tCritic Loss: 5.39 00\n",
      "\t\tAvg Score [100eps]: 1431.86 \t Steps: 1000\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.25 \tCritic Loss: 5.36 71\n",
      "\t\tAvg Score [100eps]: 1286.18 \t Steps: 3071\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.25 \tCritic Loss: 5.33 71\n",
      "\t\tAvg Score [100eps]: 1139.33 \t Steps: 3071\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.25 \tCritic Loss: 5.31 71\n",
      "\t\tAvg Score [100eps]: 1055.95 \t Steps: 3071\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.25 \tCritic Loss: 5.49 00\n",
      "\t\tAvg Score [100eps]: 1294.49 \t Steps: 1000\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.26 \tCritic Loss: 5.40 71\n",
      "\t\tAvg Score [100eps]: 1337.24 \t Steps: 3071\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.26 \tCritic Loss: 5.22 71\n",
      "\t\tAvg Score [100eps]: 1407.77 \t Steps: 3071\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.25 \tCritic Loss: 4.42 00\n",
      "\t\tAvg Score [100eps]: 1324.87 \t Steps: 1000\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.25 \tCritic Loss: 4.29 71\n",
      "\t\tAvg Score [100eps]: 1133.07 \t Steps: 3071\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.25 \tCritic Loss: 4.26 71\n",
      "\t\tAvg Score [100eps]: 1372.40 \t Steps: 3071\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.27 \tCritic Loss: 4.28 11\n",
      "\t\tAvg Score [100eps]: 730.64 \t Steps: 3071\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.28 \tCritic Loss: 4.26 71\n",
      "\t\tAvg Score [100eps]: 1136.04 \t Steps: 3071\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.28 \tCritic Loss: 4.23 71\n",
      "\t\tAvg Score [100eps]: 1358.83 \t Steps: 3071\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.28 \tCritic Loss: 4.17 71\n",
      "\t\tAvg Score [100eps]: 1031.93 \t Steps: 3071\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.29 \tCritic Loss: 4.00 1\n",
      "\t\tAvg Score [100eps]: 896.60 \t Steps: 3071\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.30 \tCritic Loss: 4.02 1\n",
      "\t\tAvg Score [100eps]: 539.27 \t Steps: 3071\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.30 \tCritic Loss: 3.99 1\n",
      "\t\tAvg Score [100eps]: 803.89 \t Steps: 3071\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.31 \tCritic Loss: 3.94 1\n",
      "\t\tAvg Score [100eps]: 837.72 \t Steps: 3071\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.32 \tCritic Loss: 3.83 11\n",
      "\t\tAvg Score [100eps]: 961.67 \t Steps: 3071\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.33 \tCritic Loss: 3.75 00\n",
      "\t\tAvg Score [100eps]: 1333.47 \t Steps: 1000\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.31 \tCritic Loss: 3.73 00\n",
      "\t\tAvg Score [100eps]: 1536.41 \t Steps: 1000\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.32 \tCritic Loss: 3.77 00\n",
      "\t\tAvg Score [100eps]: 1380.65 \t Steps: 1000\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.32 \tCritic Loss: 3.81 00\n",
      "\t\tAvg Score [100eps]: 1369.13 \t Steps: 1000\n",
      "\n",
      "Episode 1220: \tActor Loss: 0.33 \tCritic Loss: 3.80 11\n",
      "\t\tAvg Score [100eps]: 915.71 \t Steps: 3071\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.34 \tCritic Loss: 4.15 1\n",
      "\t\tAvg Score [100eps]: 368.01 \t Steps: 3071\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.36 \tCritic Loss: 4.39 1\n",
      "\t\tAvg Score [100eps]: 396.70 \t Steps: 3071\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.38 \tCritic Loss: 4.42 1\n",
      "\t\tAvg Score [100eps]: 330.37 \t Steps: 3071\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.39 \tCritic Loss: 4.81 1\n",
      "\t\tAvg Score [100eps]: 44.49 \t Steps: 3071\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.40 \tCritic Loss: 5.11 1\n",
      "\t\tAvg Score [100eps]: 128.02 \t Steps: 3071\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.40 \tCritic Loss: 5.19 1\n",
      "\t\tAvg Score [100eps]: 181.19 \t Steps: 3071\n",
      "\n",
      "Episode 1281\t Score [This Eps]: 234.85 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 1290: \tActor Loss: 0.40 \tCritic Loss: 5.33 1\n",
      "\t\tAvg Score [100eps]: 371.16 \t Steps: 3071\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.42 \tCritic Loss: 5.21 1\n",
      "\t\tAvg Score [100eps]: 585.97 \t Steps: 3071\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.42 \tCritic Loss: 5.09 1\n",
      "\t\tAvg Score [100eps]: 435.20 \t Steps: 3071\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.41 \tCritic Loss: 5.81 1\n",
      "\t\tAvg Score [100eps]: 159.01 \t Steps: 3071\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.40 \tCritic Loss: 5.81 1\n",
      "\t\tAvg Score [100eps]: 453.35 \t Steps: 3071\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.39 \tCritic Loss: 5.57 1\n",
      "\t\tAvg Score [100eps]: 270.50 \t Steps: 3071\n",
      "\n",
      "Episode 1342\t Score [This Eps]: 128.59 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 1347\t Score [This Eps]: 64.15 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 1350: \tActor Loss: 0.38 \tCritic Loss: 6.33 1\n",
      "\t\tAvg Score [100eps]: 69.14 \t Steps: 3071\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.37 \tCritic Loss: 7.01 1\n",
      "\t\tAvg Score [100eps]: 86.36 \t Steps: 3071\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.36 \tCritic Loss: 7.16 1\n",
      "\t\tAvg Score [100eps]: 96.34 \t Steps: 3071\n",
      "\n",
      "Episode 1374\t Score [This Eps]: 75.56 \t Steps: 30711NaN next_states Found! Skipping this episode.\n",
      "Episode 1380: \tActor Loss: 0.36 \tCritic Loss: 7.49 1\n",
      "\t\tAvg Score [100eps]: 123.35 \t Steps: 3071\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.35 \tCritic Loss: 7.88 1\n",
      "\t\tAvg Score [100eps]: 88.73 \t Steps: 3071\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.34 \tCritic Loss: 8.28 1\n",
      "\t\tAvg Score [100eps]: 102.28 \t Steps: 3071\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.33 \tCritic Loss: 8.62 1\n",
      "\t\tAvg Score [100eps]: 136.19 \t Steps: 3071\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.33 \tCritic Loss: 8.34 1\n",
      "\t\tAvg Score [100eps]: 107.88 \t Steps: 3071\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.32 \tCritic Loss: 8.15 1\n",
      "\t\tAvg Score [100eps]: 130.04 \t Steps: 3071\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.31 \tCritic Loss: 8.25 1\n",
      "\t\tAvg Score [100eps]: 128.71 \t Steps: 3071\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.30 \tCritic Loss: 14.67 \n",
      "\t\tAvg Score [100eps]: 85.84 \t Steps: 3071\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.29 \tCritic Loss: 14.39 \n",
      "\t\tAvg Score [100eps]: 135.43 \t Steps: 3071\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.29 \tCritic Loss: 13.63 \n",
      "\t\tAvg Score [100eps]: 186.49 \t Steps: 3071\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.30 \tCritic Loss: 12.96 \n",
      "\t\tAvg Score [100eps]: 643.75 \t Steps: 3071\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.31 \tCritic Loss: 12.68 \n",
      "\t\tAvg Score [100eps]: 751.27 \t Steps: 3071\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.32 \tCritic Loss: 12.56 \n",
      "\t\tAvg Score [100eps]: 910.32 \t Steps: 3071\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.36 \tCritic Loss: 12.56 1\n",
      "\t\tAvg Score [100eps]: 81.51 \t Steps: 3071\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.37 \tCritic Loss: 12.88 \n",
      "\t\tAvg Score [100eps]: 123.68 \t Steps: 3071\n",
      "\n",
      "Episode 1521\t Score [This Eps]: 137.02 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 1530: \tActor Loss: 0.38 \tCritic Loss: 13.24 \n",
      "\t\tAvg Score [100eps]: 909.22 \t Steps: 3071\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.39 \tCritic Loss: 13.28 \n",
      "\t\tAvg Score [100eps]: 773.26 \t Steps: 3071\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.39 \tCritic Loss: 6.81 1\n",
      "\t\tAvg Score [100eps]: 763.04 \t Steps: 3071\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1560: \tActor Loss: 0.40 \tCritic Loss: 6.99 11\n",
      "\t\tAvg Score [100eps]: 910.74 \t Steps: 3071\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.41 \tCritic Loss: 7.29 1\n",
      "\t\tAvg Score [100eps]: 286.80 \t Steps: 3071\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.41 \tCritic Loss: 7.41 1\n",
      "\t\tAvg Score [100eps]: 418.17 \t Steps: 3071\n",
      "\n",
      "Episode 1590: \tActor Loss: 0.41 \tCritic Loss: 7.18 1\n",
      "\t\tAvg Score [100eps]: 207.48 \t Steps: 3071\n",
      "\n",
      "Episode 1600: \tActor Loss: 0.42 \tCritic Loss: 7.28 1\n",
      "\t\tAvg Score [100eps]: 78.72 \t Steps: 3071\n",
      "\n",
      "Episode 1608\t Score [This Eps]: 77.93 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 1610: \tActor Loss: 0.39 \tCritic Loss: 7.30 1\n",
      "\t\tAvg Score [100eps]: 110.44 \t Steps: 3071\n",
      "\n",
      "Episode 1620: \tActor Loss: 0.40 \tCritic Loss: 6.84 1\n",
      "\t\tAvg Score [100eps]: 143.55 \t Steps: 3071\n",
      "\n",
      "Episode 1630: \tActor Loss: 0.40 \tCritic Loss: 6.22 \n",
      "\t\tAvg Score [100eps]: 62.47 \t Steps: 3071\n",
      "\n",
      "Episode 1640: \tActor Loss: 0.40 \tCritic Loss: 6.01 1\n",
      "\t\tAvg Score [100eps]: 91.57 \t Steps: 3071\n",
      "\n",
      "Episode 1650: \tActor Loss: 0.40 \tCritic Loss: 5.60 1\n",
      "\t\tAvg Score [100eps]: 313.26 \t Steps: 3071\n",
      "\n",
      "Episode 1660: \tActor Loss: 0.41 \tCritic Loss: 5.06 1\n",
      "\t\tAvg Score [100eps]: 320.52 \t Steps: 3071\n",
      "\n",
      "Episode 1670: \tActor Loss: 0.41 \tCritic Loss: 5.01 1\n",
      "\t\tAvg Score [100eps]: 417.97 \t Steps: 3071\n",
      "\n",
      "Episode 1680: \tActor Loss: 0.41 \tCritic Loss: 5.22 1\n",
      "\t\tAvg Score [100eps]: 681.54 \t Steps: 3071\n",
      "\n",
      "Episode 1690: \tActor Loss: 0.40 \tCritic Loss: 5.44 1\n",
      "\t\tAvg Score [100eps]: 676.65 \t Steps: 3071\n",
      "\n",
      "Episode 1700: \tActor Loss: 0.39 \tCritic Loss: 5.42 11\n",
      "\t\tAvg Score [100eps]: 705.97 \t Steps: 3071\n",
      "\n",
      "Episode 1710: \tActor Loss: 0.38 \tCritic Loss: 4.98 1\n",
      "\t\tAvg Score [100eps]: 579.25 \t Steps: 3071\n",
      "\n",
      "Episode 1720: \tActor Loss: 0.37 \tCritic Loss: 4.80 1\n",
      "\t\tAvg Score [100eps]: 689.97 \t Steps: 3071\n",
      "\n",
      "Episode 1730: \tActor Loss: 0.36 \tCritic Loss: 4.64 1\n",
      "\t\tAvg Score [100eps]: 722.35 \t Steps: 3071\n",
      "\n",
      "Episode 1740: \tActor Loss: 0.36 \tCritic Loss: 4.41 1\n",
      "\t\tAvg Score [100eps]: 874.07 \t Steps: 3071\n",
      "\n",
      "Episode 1750: \tActor Loss: 0.35 \tCritic Loss: 4.14 0\n",
      "\t\tAvg Score [100eps]: 826.82 \t Steps: 1000\n",
      "\n",
      "Episode 1760: \tActor Loss: 0.34 \tCritic Loss: 3.87 0\n",
      "\t\tAvg Score [100eps]: 841.44 \t Steps: 1000\n",
      "\n",
      "Episode 1770: \tActor Loss: 0.34 \tCritic Loss: 3.55 0\n",
      "\t\tAvg Score [100eps]: 853.24 \t Steps: 1000\n",
      "\n",
      "Episode 1780: \tActor Loss: 0.34 \tCritic Loss: 3.19 1\n",
      "\t\tAvg Score [100eps]: 867.50 \t Steps: 3071\n",
      "\n",
      "Episode 1790: \tActor Loss: 0.34 \tCritic Loss: 2.86 0\n",
      "\t\tAvg Score [100eps]: 861.69 \t Steps: 1000\n",
      "\n",
      "Episode 1800: \tActor Loss: 0.34 \tCritic Loss: 2.42 1\n",
      "\t\tAvg Score [100eps]: 730.84 \t Steps: 3071\n",
      "\n",
      "Episode 1810: \tActor Loss: 0.33 \tCritic Loss: 2.28 0\n",
      "\t\tAvg Score [100eps]: 909.08 \t Steps: 1000\n",
      "\n",
      "Episode 1820: \tActor Loss: 0.33 \tCritic Loss: 2.18 0\n",
      "\t\tAvg Score [100eps]: 846.64 \t Steps: 1000\n",
      "\n",
      "Episode 1830: \tActor Loss: 0.33 \tCritic Loss: 2.09 0\n",
      "\t\tAvg Score [100eps]: 753.30 \t Steps: 1000\n",
      "\n",
      "Episode 1840: \tActor Loss: 0.33 \tCritic Loss: 2.04 0\n",
      "\t\tAvg Score [100eps]: 788.86 \t Steps: 1000\n",
      "\n",
      "Episode 1850: \tActor Loss: 0.33 \tCritic Loss: 1.98 0\n",
      "\t\tAvg Score [100eps]: 694.25 \t Steps: 1000\n",
      "\n",
      "Episode 1860: \tActor Loss: 0.34 \tCritic Loss: 1.96 0\n",
      "\t\tAvg Score [100eps]: 701.16 \t Steps: 1000\n",
      "\n",
      "Episode 1870: \tActor Loss: 0.33 \tCritic Loss: 1.94 0\n",
      "\t\tAvg Score [100eps]: 773.16 \t Steps: 1000\n",
      "\n",
      "Episode 1880: \tActor Loss: 0.33 \tCritic Loss: 1.94 1\n",
      "\t\tAvg Score [100eps]: 809.39 \t Steps: 3071\n",
      "\n",
      "Episode 1890: \tActor Loss: 0.33 \tCritic Loss: 1.95 0\n",
      "\t\tAvg Score [100eps]: 720.67 \t Steps: 1000\n",
      "\n",
      "Episode 1900: \tActor Loss: 0.33 \tCritic Loss: 1.96 1\n",
      "\t\tAvg Score [100eps]: 661.96 \t Steps: 3071\n",
      "\n",
      "Episode 1910: \tActor Loss: 0.33 \tCritic Loss: 1.97 1\n",
      "\t\tAvg Score [100eps]: 658.93 \t Steps: 3071\n",
      "\n",
      "Episode 1920: \tActor Loss: 0.33 \tCritic Loss: 1.98 1\n",
      "\t\tAvg Score [100eps]: 611.37 \t Steps: 3071\n",
      "\n",
      "Episode 1930: \tActor Loss: 0.34 \tCritic Loss: 2.00 1\n",
      "\t\tAvg Score [100eps]: 467.05 \t Steps: 3071\n",
      "\n",
      "Episode 1940: \tActor Loss: 0.33 \tCritic Loss: 2.02 1\n",
      "\t\tAvg Score [100eps]: 533.56 \t Steps: 3071\n",
      "\n",
      "Episode 1950: \tActor Loss: 0.33 \tCritic Loss: 2.01 1\n",
      "\t\tAvg Score [100eps]: 548.99 \t Steps: 3071\n",
      "\n",
      "Episode 1960: \tActor Loss: 0.33 \tCritic Loss: 1.98 1\n",
      "\t\tAvg Score [100eps]: 576.05 \t Steps: 3071\n",
      "\n",
      "Episode 1970: \tActor Loss: 0.33 \tCritic Loss: 1.95 0\n",
      "\t\tAvg Score [100eps]: 581.99 \t Steps: 1000\n",
      "\n",
      "Episode 1980: \tActor Loss: 0.33 \tCritic Loss: 1.89 1\n",
      "\t\tAvg Score [100eps]: 466.58 \t Steps: 3071\n",
      "\n",
      "Episode 1990: \tActor Loss: 0.33 \tCritic Loss: 1.85 1\n",
      "\t\tAvg Score [100eps]: 393.90 \t Steps: 3071\n",
      "\n",
      "Episode 2000: \tActor Loss: 0.33 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 364.35 \t Steps: 3071\n",
      "\n",
      "Episode 2010: \tActor Loss: 0.33 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 219.57 \t Steps: 3071\n",
      "\n",
      "Episode 2020: \tActor Loss: 0.33 \tCritic Loss: 1.83 1\n",
      "\t\tAvg Score [100eps]: 326.63 \t Steps: 3071\n",
      "\n",
      "Episode 2030: \tActor Loss: 0.33 \tCritic Loss: 1.81 1\n",
      "\t\tAvg Score [100eps]: 298.67 \t Steps: 3071\n",
      "\n",
      "Episode 2040: \tActor Loss: 0.33 \tCritic Loss: 1.80 1\n",
      "\t\tAvg Score [100eps]: 263.05 \t Steps: 3071\n",
      "\n",
      "Episode 2049\t Score [This Eps]: 273.20 \t Steps: 3071NaN next_states Found! Skipping this episode.\n",
      "Episode 2060: \tActor Loss: 0.33 \tCritic Loss: 1.82 1\n",
      "\t\tAvg Score [100eps]: 260.90 \t Steps: 3071\n",
      "\n",
      "Episode 2070: \tActor Loss: 0.33 \tCritic Loss: 1.83 1\n",
      "\t\tAvg Score [100eps]: 419.94 \t Steps: 3071\n",
      "\n",
      "Episode 2080: \tActor Loss: 0.33 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 260.36 \t Steps: 3071\n",
      "\n",
      "Episode 2090: \tActor Loss: 0.33 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 192.98 \t Steps: 3071\n",
      "\n",
      "Episode 2100: \tActor Loss: 0.34 \tCritic Loss: 1.85 1\n",
      "\t\tAvg Score [100eps]: 266.53 \t Steps: 3071\n",
      "\n",
      "Episode 2110: \tActor Loss: 0.34 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 242.82 \t Steps: 3071\n",
      "\n",
      "Episode 2120: \tActor Loss: 0.34 \tCritic Loss: 1.82 1\n",
      "\t\tAvg Score [100eps]: 308.65 \t Steps: 3071\n",
      "\n",
      "Episode 2130: \tActor Loss: 0.34 \tCritic Loss: 1.81 1\n",
      "\t\tAvg Score [100eps]: 254.44 \t Steps: 3071\n",
      "\n",
      "Episode 2140: \tActor Loss: 0.34 \tCritic Loss: 1.79 1\n",
      "\t\tAvg Score [100eps]: 251.42 \t Steps: 3071\n",
      "\n",
      "Episode 2150: \tActor Loss: 0.34 \tCritic Loss: 1.82 1\n",
      "\t\tAvg Score [100eps]: 152.69 \t Steps: 3071\n",
      "\n",
      "Episode 2160: \tActor Loss: 0.34 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 137.93 \t Steps: 3071\n",
      "\n",
      "Episode 2170: \tActor Loss: 0.34 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 135.80 \t Steps: 3071\n",
      "\n",
      "Episode 2180: \tActor Loss: 0.34 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 137.49 \t Steps: 3071\n",
      "\n",
      "Episode 2190: \tActor Loss: 0.34 \tCritic Loss: 1.86 1\n",
      "\t\tAvg Score [100eps]: 168.43 \t Steps: 3071\n",
      "\n",
      "Episode 2200: \tActor Loss: 0.34 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 127.95 \t Steps: 3071\n",
      "\n",
      "Episode 2210: \tActor Loss: 0.34 \tCritic Loss: 1.84 1\n",
      "\t\tAvg Score [100eps]: 184.35 \t Steps: 3071\n",
      "\n",
      "Episode 2211\t Score [This Eps]: 249.00 \t Steps: 3071NaN Reward Found! Skipping this episode.\n",
      "Episode 2220: \tActor Loss: 0.35 \tCritic Loss: 1.86 1\n",
      "\t\tAvg Score [100eps]: 271.94 \t Steps: 3071\n",
      "\n",
      "Episode 2230: \tActor Loss: 0.35 \tCritic Loss: 1.88 1\n",
      "\t\tAvg Score [100eps]: 464.13 \t Steps: 3071\n",
      "\n",
      "Episode 2240: \tActor Loss: 0.35 \tCritic Loss: 1.90 1\n",
      "\t\tAvg Score [100eps]: 229.92 \t Steps: 3071\n",
      "\n",
      "Episode 2250: \tActor Loss: 0.35 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 250.11 \t Steps: 3071\n",
      "\n",
      "Episode 2260: \tActor Loss: 0.35 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 389.33 \t Steps: 3071\n",
      "\n",
      "Episode 2270: \tActor Loss: 0.35 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 510.90 \t Steps: 3071\n",
      "\n",
      "Episode 2280: \tActor Loss: 0.35 \tCritic Loss: 1.88 1\n",
      "\t\tAvg Score [100eps]: 566.32 \t Steps: 3071\n",
      "\n",
      "Episode 2290: \tActor Loss: 0.35 \tCritic Loss: 1.88 1\n",
      "\t\tAvg Score [100eps]: 590.02 \t Steps: 3071\n",
      "\n",
      "Episode 2300: \tActor Loss: 0.35 \tCritic Loss: 1.88 1\n",
      "\t\tAvg Score [100eps]: 620.31 \t Steps: 3071\n",
      "\n",
      "Episode 2310: \tActor Loss: 0.34 \tCritic Loss: 1.87 1\n",
      "\t\tAvg Score [100eps]: 587.66 \t Steps: 3071\n",
      "\n",
      "Episode 2320: \tActor Loss: 0.34 \tCritic Loss: 1.83 1\n",
      "\t\tAvg Score [100eps]: 599.75 \t Steps: 3071\n",
      "\n",
      "Episode 2330: \tActor Loss: 0.34 \tCritic Loss: 1.79 1\n",
      "\t\tAvg Score [100eps]: 563.24 \t Steps: 3071\n",
      "\n",
      "Episode 2340: \tActor Loss: 0.34 \tCritic Loss: 1.76 1\n",
      "\t\tAvg Score [100eps]: 585.45 \t Steps: 3071\n",
      "\n",
      "Episode 2350: \tActor Loss: 0.33 \tCritic Loss: 1.73 1\n",
      "\t\tAvg Score [100eps]: 586.12 \t Steps: 3071\n",
      "\n",
      "Episode 2360: \tActor Loss: 0.33 \tCritic Loss: 1.70 1\n",
      "\t\tAvg Score [100eps]: 661.85 \t Steps: 3071\n",
      "\n",
      "Episode 2370: \tActor Loss: 0.33 \tCritic Loss: 1.66 1\n",
      "\t\tAvg Score [100eps]: 630.02 \t Steps: 3071\n",
      "\n",
      "Episode 2380: \tActor Loss: 0.33 \tCritic Loss: 1.61 1\n",
      "\t\tAvg Score [100eps]: 550.71 \t Steps: 3071\n",
      "\n",
      "Episode 2390: \tActor Loss: 0.33 \tCritic Loss: 1.58 1\n",
      "\t\tAvg Score [100eps]: 523.14 \t Steps: 3071\n",
      "\n",
      "Episode 2400: \tActor Loss: 0.33 \tCritic Loss: 1.56 1\n",
      "\t\tAvg Score [100eps]: 530.75 \t Steps: 3071\n",
      "\n",
      "Episode 2410: \tActor Loss: 0.33 \tCritic Loss: 1.53 1\n",
      "\t\tAvg Score [100eps]: 595.34 \t Steps: 3071\n",
      "\n",
      "Episode 2420: \tActor Loss: 0.33 \tCritic Loss: 1.53 1\n",
      "\t\tAvg Score [100eps]: 694.50 \t Steps: 3071\n",
      "\n",
      "Episode 2430: \tActor Loss: 0.33 \tCritic Loss: 1.51 1\n",
      "\t\tAvg Score [100eps]: 670.08 \t Steps: 3071\n",
      "\n",
      "Episode 2440: \tActor Loss: 0.33 \tCritic Loss: 1.51 1\n",
      "\t\tAvg Score [100eps]: 647.35 \t Steps: 3071\n",
      "\n",
      "Episode 2450: \tActor Loss: 0.33 \tCritic Loss: 1.50 1\n",
      "\t\tAvg Score [100eps]: 696.70 \t Steps: 3071\n",
      "\n",
      "Episode 2460: \tActor Loss: 0.33 \tCritic Loss: 1.50 1\n",
      "\t\tAvg Score [100eps]: 679.66 \t Steps: 3071\n",
      "\n",
      "Episode 2470: \tActor Loss: 0.33 \tCritic Loss: 1.50 1\n",
      "\t\tAvg Score [100eps]: 698.07 \t Steps: 3071\n",
      "\n",
      "Episode 2480: \tActor Loss: 0.33 \tCritic Loss: 1.53 0\n",
      "\t\tAvg Score [100eps]: 821.75 \t Steps: 1000\n",
      "\n",
      "Episode 2490: \tActor Loss: 0.33 \tCritic Loss: 1.52 1\n",
      "\t\tAvg Score [100eps]: 766.67 \t Steps: 3071\n",
      "\n",
      "Episode 2500: \tActor Loss: 0.33 \tCritic Loss: 1.55 1\n",
      "\t\tAvg Score [100eps]: 793.24 \t Steps: 3071\n",
      "\n",
      "Episode 2510: \tActor Loss: 0.33 \tCritic Loss: 1.55 1\n",
      "\t\tAvg Score [100eps]: 787.43 \t Steps: 3071\n",
      "\n",
      "Episode 2520: \tActor Loss: 0.33 \tCritic Loss: 1.54 1\n",
      "\t\tAvg Score [100eps]: 712.45 \t Steps: 3071\n",
      "\n",
      "Episode 2530: \tActor Loss: 0.33 \tCritic Loss: 1.54 1\n",
      "\t\tAvg Score [100eps]: 728.88 \t Steps: 3071\n",
      "\n",
      "Episode 2540: \tActor Loss: 0.32 \tCritic Loss: 1.56 1\n",
      "\t\tAvg Score [100eps]: 705.24 \t Steps: 3071\n",
      "\n",
      "Episode 2550: \tActor Loss: 0.32 \tCritic Loss: 1.54 0\n",
      "\t\tAvg Score [100eps]: 691.53 \t Steps: 1000\n",
      "\n",
      "Episode 2560: \tActor Loss: 0.32 \tCritic Loss: 1.53 1\n",
      "\t\tAvg Score [100eps]: 775.39 \t Steps: 3071\n",
      "\n",
      "Episode 2570: \tActor Loss: 0.32 \tCritic Loss: 1.53 0\n",
      "\t\tAvg Score [100eps]: 757.98 \t Steps: 1000\n",
      "\n",
      "Episode 2580: \tActor Loss: 0.32 \tCritic Loss: 1.48 1\n",
      "\t\tAvg Score [100eps]: 807.92 \t Steps: 3071\n",
      "\n",
      "Episode 2590: \tActor Loss: 0.32 \tCritic Loss: 1.47 0\n",
      "\t\tAvg Score [100eps]: 816.59 \t Steps: 1000\n",
      "\n",
      "Episode 2600: \tActor Loss: 0.32 \tCritic Loss: 1.47 1\n",
      "\t\tAvg Score [100eps]: 864.59 \t Steps: 3071\n",
      "\n",
      "Episode 2610: \tActor Loss: 0.32 \tCritic Loss: 1.46 1\n",
      "\t\tAvg Score [100eps]: 849.95 \t Steps: 3071\n",
      "\n",
      "Episode 2620: \tActor Loss: 0.32 \tCritic Loss: 1.44 0\n",
      "\t\tAvg Score [100eps]: 837.97 \t Steps: 1000\n",
      "\n",
      "Episode 2630: \tActor Loss: 0.32 \tCritic Loss: 1.43 0\n",
      "\t\tAvg Score [100eps]: 819.76 \t Steps: 1000\n",
      "\n",
      "Episode 2640: \tActor Loss: 0.32 \tCritic Loss: 1.42 1\n",
      "\t\tAvg Score [100eps]: 807.57 \t Steps: 3071\n",
      "\n",
      "Episode 2650: \tActor Loss: 0.32 \tCritic Loss: 1.43 1\n",
      "\t\tAvg Score [100eps]: 852.42 \t Steps: 3071\n",
      "\n",
      "Episode 2660: \tActor Loss: 0.32 \tCritic Loss: 1.41 0\n",
      "\t\tAvg Score [100eps]: 781.04 \t Steps: 1000\n",
      "\n",
      "Episode 2670: \tActor Loss: 0.32 \tCritic Loss: 1.40 0\n",
      "\t\tAvg Score [100eps]: 756.03 \t Steps: 1000\n",
      "\n",
      "Episode 2680: \tActor Loss: 0.32 \tCritic Loss: 1.41 1\n",
      "\t\tAvg Score [100eps]: 757.67 \t Steps: 3071\n",
      "\n",
      "Episode 2690: \tActor Loss: 0.32 \tCritic Loss: 1.42 0\n",
      "\t\tAvg Score [100eps]: 865.10 \t Steps: 1000\n",
      "\n",
      "Episode 2700: \tActor Loss: 0.32 \tCritic Loss: 1.38 0\n",
      "\t\tAvg Score [100eps]: 834.41 \t Steps: 1000\n",
      "\n",
      "Episode 2710: \tActor Loss: 0.32 \tCritic Loss: 1.37 0\n",
      "\t\tAvg Score [100eps]: 794.73 \t Steps: 1000\n",
      "\n",
      "Episode 2720: \tActor Loss: 0.32 \tCritic Loss: 1.36 0\n",
      "\t\tAvg Score [100eps]: 778.76 \t Steps: 1000\n",
      "\n",
      "Episode 2730: \tActor Loss: 0.32 \tCritic Loss: 1.37 1\n",
      "\t\tAvg Score [100eps]: 768.48 \t Steps: 3071\n",
      "\n",
      "Episode 2740: \tActor Loss: 0.32 \tCritic Loss: 1.36 1\n",
      "\t\tAvg Score [100eps]: 636.92 \t Steps: 3071\n",
      "\n",
      "Episode 2750: \tActor Loss: 0.32 \tCritic Loss: 1.33 1\n",
      "\t\tAvg Score [100eps]: 583.36 \t Steps: 3071\n",
      "\n",
      "Episode 2760: \tActor Loss: 0.32 \tCritic Loss: 1.31 1\n",
      "\t\tAvg Score [100eps]: 577.44 \t Steps: 3071\n",
      "\n",
      "Episode 2770: \tActor Loss: 0.32 \tCritic Loss: 1.27 1\n",
      "\t\tAvg Score [100eps]: 570.10 \t Steps: 3071\n",
      "\n",
      "Episode 2780: \tActor Loss: 0.32 \tCritic Loss: 1.24 1\n",
      "\t\tAvg Score [100eps]: 537.10 \t Steps: 3071\n",
      "\n",
      "Episode 2790: \tActor Loss: 0.32 \tCritic Loss: 1.20 1\n",
      "\t\tAvg Score [100eps]: 551.03 \t Steps: 3071\n",
      "\n",
      "Episode 2800: \tActor Loss: 0.32 \tCritic Loss: 1.17 0\n",
      "\t\tAvg Score [100eps]: 513.49 \t Steps: 1000\n",
      "\n",
      "Episode 2810: \tActor Loss: 0.32 \tCritic Loss: 1.14 1\n",
      "\t\tAvg Score [100eps]: 535.21 \t Steps: 3071\n",
      "\n",
      "Episode 2820: \tActor Loss: 0.32 \tCritic Loss: 1.09 1\n",
      "\t\tAvg Score [100eps]: 531.40 \t Steps: 3071\n",
      "\n",
      "Episode 2830: \tActor Loss: 0.32 \tCritic Loss: 1.05 1\n",
      "\t\tAvg Score [100eps]: 492.23 \t Steps: 3071\n",
      "\n",
      "Episode 2840: \tActor Loss: 0.32 \tCritic Loss: 0.99 1\n",
      "\t\tAvg Score [100eps]: 532.10 \t Steps: 3071\n",
      "\n",
      "Episode 2850: \tActor Loss: 0.32 \tCritic Loss: 0.96 1\n",
      "\t\tAvg Score [100eps]: 488.51 \t Steps: 3071\n",
      "\n",
      "Episode 2860: \tActor Loss: 0.32 \tCritic Loss: 0.94 1\n",
      "\t\tAvg Score [100eps]: 464.05 \t Steps: 3071\n",
      "\n",
      "Episode 2870: \tActor Loss: 0.32 \tCritic Loss: 0.92 1\n",
      "\t\tAvg Score [100eps]: 437.59 \t Steps: 3071\n",
      "\n",
      "Episode 2880: \tActor Loss: 0.32 \tCritic Loss: 0.89 1\n",
      "\t\tAvg Score [100eps]: 468.18 \t Steps: 3071\n",
      "\n",
      "Episode 2890: \tActor Loss: 0.32 \tCritic Loss: 0.87 1\n",
      "\t\tAvg Score [100eps]: 476.10 \t Steps: 3071\n",
      "\n",
      "Episode 2900: \tActor Loss: 0.32 \tCritic Loss: 0.86 1\n",
      "\t\tAvg Score [100eps]: 457.48 \t Steps: 3071\n",
      "\n",
      "Episode 2910: \tActor Loss: 0.32 \tCritic Loss: 0.83 1\n",
      "\t\tAvg Score [100eps]: 473.61 \t Steps: 3071\n",
      "\n",
      "Episode 2920: \tActor Loss: 0.32 \tCritic Loss: 0.82 1\n",
      "\t\tAvg Score [100eps]: 436.07 \t Steps: 3071\n",
      "\n",
      "Episode 2930: \tActor Loss: 0.32 \tCritic Loss: 0.79 1\n",
      "\t\tAvg Score [100eps]: 432.90 \t Steps: 3071\n",
      "\n",
      "Episode 2940: \tActor Loss: 0.32 \tCritic Loss: 0.78 1\n",
      "\t\tAvg Score [100eps]: 388.29 \t Steps: 3071\n",
      "\n",
      "Episode 2950: \tActor Loss: 0.33 \tCritic Loss: 0.76 1\n",
      "\t\tAvg Score [100eps]: 376.93 \t Steps: 3071\n",
      "\n",
      "Episode 2960: \tActor Loss: 0.33 \tCritic Loss: 0.75 1\n",
      "\t\tAvg Score [100eps]: 381.65 \t Steps: 3071\n",
      "\n",
      "Episode 2970: \tActor Loss: 0.33 \tCritic Loss: 0.74 1\n",
      "\t\tAvg Score [100eps]: 357.43 \t Steps: 3071\n",
      "\n",
      "Episode 2980: \tActor Loss: 0.33 \tCritic Loss: 0.73 0\n",
      "\t\tAvg Score [100eps]: 384.85 \t Steps: 1000\n",
      "\n",
      "Episode 2990: \tActor Loss: 0.33 \tCritic Loss: 0.72 1\n",
      "\t\tAvg Score [100eps]: 343.52 \t Steps: 3071\n",
      "\n",
      "Episode 3000: \tActor Loss: 0.33 \tCritic Loss: 0.71 1\n",
      "\t\tAvg Score [100eps]: 396.75 \t Steps: 3071\n",
      "\n",
      "Episode 3010: \tActor Loss: 0.33 \tCritic Loss: 0.72 0\n",
      "\t\tAvg Score [100eps]: 324.91 \t Steps: 1000\n",
      "\n",
      "Episode 3020: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 322.00 \t Steps: 3071\n",
      "\n",
      "Episode 3030: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 294.44 \t Steps: 3071\n",
      "\n",
      "Episode 3040: \tActor Loss: 0.33 \tCritic Loss: 0.73 0\n",
      "\t\tAvg Score [100eps]: 330.95 \t Steps: 1000\n",
      "\n",
      "Episode 3050: \tActor Loss: 0.33 \tCritic Loss: 0.72 1\n",
      "\t\tAvg Score [100eps]: 315.51 \t Steps: 3071\n",
      "\n",
      "Episode 3060: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 272.57 \t Steps: 3071\n",
      "\n",
      "Episode 3070: \tActor Loss: 0.33 \tCritic Loss: 0.74 0\n",
      "\t\tAvg Score [100eps]: 284.50 \t Steps: 1000\n",
      "\n",
      "Episode 3080: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 291.17 \t Steps: 3071\n",
      "\n",
      "Episode 3090: \tActor Loss: 0.33 \tCritic Loss: 0.74 0\n",
      "\t\tAvg Score [100eps]: 240.50 \t Steps: 1000\n",
      "\n",
      "Episode 3100: \tActor Loss: 0.33 \tCritic Loss: 0.75 1\n",
      "\t\tAvg Score [100eps]: 234.88 \t Steps: 3071\n",
      "\n",
      "Episode 3110: \tActor Loss: 0.33 \tCritic Loss: 0.75 1\n",
      "\t\tAvg Score [100eps]: 216.52 \t Steps: 3071\n",
      "\n",
      "Episode 3120: \tActor Loss: 0.33 \tCritic Loss: 0.74 1\n",
      "\t\tAvg Score [100eps]: 199.82 \t Steps: 3071\n",
      "\n",
      "Episode 3130: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 226.84 \t Steps: 3071\n",
      "\n",
      "Episode 3140: \tActor Loss: 0.33 \tCritic Loss: 0.71 1\n",
      "\t\tAvg Score [100eps]: 190.05 \t Steps: 3071\n",
      "\n",
      "Episode 3150: \tActor Loss: 0.33 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 198.91 \t Steps: 3071\n",
      "\n",
      "Episode 3160: \tActor Loss: 0.33 \tCritic Loss: 0.70 1\n",
      "\t\tAvg Score [100eps]: 178.13 \t Steps: 3071\n",
      "\n",
      "Episode 3170: \tActor Loss: 0.33 \tCritic Loss: 0.69 1\n",
      "\t\tAvg Score [100eps]: 225.73 \t Steps: 3071\n",
      "\n",
      "Episode 3180: \tActor Loss: 0.33 \tCritic Loss: 0.70 1\n",
      "\t\tAvg Score [100eps]: 152.15 \t Steps: 3071\n",
      "\n",
      "Episode 3190: \tActor Loss: 0.33 \tCritic Loss: 0.67 1\n",
      "\t\tAvg Score [100eps]: 212.61 \t Steps: 3071\n",
      "\n",
      "Episode 3200: \tActor Loss: 0.33 \tCritic Loss: 0.64 1\n",
      "\t\tAvg Score [100eps]: 172.08 \t Steps: 3071\n",
      "\n",
      "Episode 3210: \tActor Loss: 0.33 \tCritic Loss: 0.62 1\n",
      "\t\tAvg Score [100eps]: 144.85 \t Steps: 3071\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3220: \tActor Loss: 0.33 \tCritic Loss: 0.60 1\n",
      "\t\tAvg Score [100eps]: 177.14 \t Steps: 3071\n",
      "\n",
      "Episode 3230: \tActor Loss: 0.33 \tCritic Loss: 0.60 1\n",
      "\t\tAvg Score [100eps]: 141.40 \t Steps: 3071\n",
      "\n",
      "Episode 3240: \tActor Loss: 0.33 \tCritic Loss: 0.59 1\n",
      "\t\tAvg Score [100eps]: 140.87 \t Steps: 3071\n",
      "\n",
      "Episode 3250: \tActor Loss: 0.33 \tCritic Loss: 0.57 1\n",
      "\t\tAvg Score [100eps]: 137.26 \t Steps: 3071\n",
      "\n",
      "Episode 3260: \tActor Loss: 0.33 \tCritic Loss: 0.56 1\n",
      "\t\tAvg Score [100eps]: 144.89 \t Steps: 3071\n",
      "\n",
      "Episode 3270: \tActor Loss: 0.33 \tCritic Loss: 0.54 1\n",
      "\t\tAvg Score [100eps]: 125.20 \t Steps: 3071\n",
      "\n",
      "Episode 3280: \tActor Loss: 0.33 \tCritic Loss: 0.51 0\n",
      "\t\tAvg Score [100eps]: 124.01 \t Steps: 1000\n",
      "\n",
      "Episode 3290: \tActor Loss: 0.33 \tCritic Loss: 0.52 1\n",
      "\t\tAvg Score [100eps]: 110.80 \t Steps: 3071\n",
      "\n",
      "Episode 3300: \tActor Loss: 0.33 \tCritic Loss: 0.52 0\n",
      "\t\tAvg Score [100eps]: 103.65 \t Steps: 1000\n",
      "\n",
      "Episode 3310: \tActor Loss: 0.33 \tCritic Loss: 0.51 1\n",
      "\t\tAvg Score [100eps]: 116.54 \t Steps: 3071\n",
      "\n",
      "Episode 3320: \tActor Loss: 0.33 \tCritic Loss: 0.50 1\n",
      "\t\tAvg Score [100eps]: 94.77 \t Steps: 3071\n",
      "\n",
      "Episode 3330: \tActor Loss: 0.33 \tCritic Loss: 0.49 1\n",
      "\t\tAvg Score [100eps]: 103.04 \t Steps: 3071\n",
      "\n",
      "Episode 3340: \tActor Loss: 0.33 \tCritic Loss: 0.47 1\n",
      "\t\tAvg Score [100eps]: 88.91 \t Steps: 1000\n",
      "\n",
      "Episode 3350: \tActor Loss: 0.33 \tCritic Loss: 0.46 \n",
      "\t\tAvg Score [100eps]: 88.70 \t Steps: 3071\n",
      "\n",
      "Episode 3360: \tActor Loss: 0.33 \tCritic Loss: 0.45 \n",
      "\t\tAvg Score [100eps]: 85.71 \t Steps: 3071\n",
      "\n",
      "Episode 3370: \tActor Loss: 0.33 \tCritic Loss: 0.45 \n",
      "\t\tAvg Score [100eps]: 92.98 \t Steps: 3071\n",
      "\n",
      "Episode 3380: \tActor Loss: 0.33 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 94.24 \t Steps: 3071\n",
      "\n",
      "Episode 3390: \tActor Loss: 0.33 \tCritic Loss: 0.43 \n",
      "\t\tAvg Score [100eps]: 89.58 \t Steps: 3071\n",
      "\n",
      "Episode 3400: \tActor Loss: 0.33 \tCritic Loss: 0.41 \n",
      "\t\tAvg Score [100eps]: 94.25 \t Steps: 1000\n",
      "\n",
      "Episode 3410: \tActor Loss: 0.33 \tCritic Loss: 0.41 \n",
      "\t\tAvg Score [100eps]: 78.43 \t Steps: 3071\n",
      "\n",
      "Episode 3420: \tActor Loss: 0.33 \tCritic Loss: 0.40 \n",
      "\t\tAvg Score [100eps]: 79.73 \t Steps: 1000\n",
      "\n",
      "Episode 3430: \tActor Loss: 0.33 \tCritic Loss: 0.40 \n",
      "\t\tAvg Score [100eps]: 83.97 \t Steps: 3071\n",
      "\n",
      "Episode 3440: \tActor Loss: 0.33 \tCritic Loss: 0.39 \n",
      "\t\tAvg Score [100eps]: 74.53 \t Steps: 3071\n",
      "\n",
      "Episode 3450: \tActor Loss: 0.33 \tCritic Loss: 0.39 \n",
      "\t\tAvg Score [100eps]: 85.63 \t Steps: 3071\n",
      "\n",
      "Episode 3460: \tActor Loss: 0.33 \tCritic Loss: 0.38 \n",
      "\t\tAvg Score [100eps]: 82.77 \t Steps: 3071\n",
      "\n",
      "Episode 3470: \tActor Loss: 0.33 \tCritic Loss: 0.37 \n",
      "\t\tAvg Score [100eps]: 77.84 \t Steps: 3071\n",
      "\n",
      "Episode 3480: \tActor Loss: 0.33 \tCritic Loss: 0.37 \n",
      "\t\tAvg Score [100eps]: 80.35 \t Steps: 1000\n",
      "\n",
      "Episode 3490: \tActor Loss: 0.33 \tCritic Loss: 0.36 \n",
      "\t\tAvg Score [100eps]: 82.64 \t Steps: 3071\n",
      "\n",
      "Episode 3500: \tActor Loss: 0.33 \tCritic Loss: 0.36 \n",
      "\t\tAvg Score [100eps]: 69.25 \t Steps: 3071\n",
      "\n",
      "Episode 3510: \tActor Loss: 0.33 \tCritic Loss: 0.35 \n",
      "\t\tAvg Score [100eps]: 92.02 \t Steps: 1000\n",
      "\n",
      "Episode 3520: \tActor Loss: 0.33 \tCritic Loss: 0.34 \n",
      "\t\tAvg Score [100eps]: 92.88 \t Steps: 1000\n",
      "\n",
      "Episode 3530: \tActor Loss: 0.33 \tCritic Loss: 0.33 \n",
      "\t\tAvg Score [100eps]: 93.32 \t Steps: 1000\n",
      "\n",
      "Episode 3540: \tActor Loss: 0.33 \tCritic Loss: 0.32 \n",
      "\t\tAvg Score [100eps]: 95.83 \t Steps: 3071\n",
      "\n",
      "Episode 3550: \tActor Loss: 0.33 \tCritic Loss: 0.32 \n",
      "\t\tAvg Score [100eps]: 94.31 \t Steps: 3071\n",
      "\n",
      "Episode 3560: \tActor Loss: 0.33 \tCritic Loss: 0.31 \n",
      "\t\tAvg Score [100eps]: 97.70 \t Steps: 1000\n",
      "\n",
      "Episode 3570: \tActor Loss: 0.33 \tCritic Loss: 0.31 \n",
      "\t\tAvg Score [100eps]: 89.57 \t Steps: 1000\n",
      "\n",
      "Episode 3580: \tActor Loss: 0.33 \tCritic Loss: 0.30 \n",
      "\t\tAvg Score [100eps]: 92.94 \t Steps: 1000\n",
      "\n",
      "Episode 3590: \tActor Loss: 0.33 \tCritic Loss: 0.29 0\n",
      "\t\tAvg Score [100eps]: 89.86 \t Steps: 1000\n",
      "\n",
      "Episode 3600: \tActor Loss: 0.33 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 95.01 \t Steps: 3071\n",
      "\n",
      "Episode 3610: \tActor Loss: 0.33 \tCritic Loss: 0.27 0\n",
      "\t\tAvg Score [100eps]: 93.00 \t Steps: 3071\n",
      "\n",
      "Episode 3620: \tActor Loss: 0.33 \tCritic Loss: 0.26 0\n",
      "\t\tAvg Score [100eps]: 111.08 \t Steps: 1000\n",
      "\n",
      "Episode 3630: \tActor Loss: 0.33 \tCritic Loss: 0.24 0\n",
      "\t\tAvg Score [100eps]: 94.66 \t Steps: 1000\n",
      "\n",
      "Episode 3640: \tActor Loss: 0.33 \tCritic Loss: 0.24 0\n",
      "\t\tAvg Score [100eps]: 98.78 \t Steps: 1000\n",
      "\n",
      "Episode 3650: \tActor Loss: 0.33 \tCritic Loss: 0.22 1\n",
      "\t\tAvg Score [100eps]: 102.01 \t Steps: 3071\n",
      "\n",
      "Episode 3660: \tActor Loss: 0.33 \tCritic Loss: 0.21 0\n",
      "\t\tAvg Score [100eps]: 106.16 \t Steps: 1000\n",
      "\n",
      "Episode 3670: \tActor Loss: 0.33 \tCritic Loss: 0.20 1\n",
      "\t\tAvg Score [100eps]: 107.68 \t Steps: 3071\n",
      "\n",
      "Episode 3680: \tActor Loss: 0.33 \tCritic Loss: 0.19 1\n",
      "\t\tAvg Score [100eps]: 104.04 \t Steps: 3071\n",
      "\n",
      "Episode 3690: \tActor Loss: 0.33 \tCritic Loss: 0.18 0\n",
      "\t\tAvg Score [100eps]: 109.65 \t Steps: 1000\n",
      "\n",
      "Episode 3700: \tActor Loss: 0.33 \tCritic Loss: 0.18 0\n",
      "\t\tAvg Score [100eps]: 108.72 \t Steps: 1000\n",
      "\n",
      "Episode 3710: \tActor Loss: 0.33 \tCritic Loss: 0.17 0\n",
      "\t\tAvg Score [100eps]: 110.71 \t Steps: 1000\n",
      "\n",
      "Episode 3720: \tActor Loss: 0.33 \tCritic Loss: 0.17 0\n",
      "\t\tAvg Score [100eps]: 112.04 \t Steps: 1000\n",
      "\n",
      "Episode 3730: \tActor Loss: 0.32 \tCritic Loss: 0.16 1\n",
      "\t\tAvg Score [100eps]: 100.68 \t Steps: 3071\n",
      "\n",
      "Episode 3740: \tActor Loss: 0.32 \tCritic Loss: 0.16 0\n",
      "\t\tAvg Score [100eps]: 118.63 \t Steps: 1000\n",
      "\n",
      "Episode 3750: \tActor Loss: 0.32 \tCritic Loss: 0.16 0\n",
      "\t\tAvg Score [100eps]: 115.35 \t Steps: 1000\n",
      "\n",
      "Episode 3760: \tActor Loss: 0.32 \tCritic Loss: 0.16 0\n",
      "\t\tAvg Score [100eps]: 119.20 \t Steps: 1000\n",
      "\n",
      "Episode 3770: \tActor Loss: 0.32 \tCritic Loss: 0.15 0\n",
      "\t\tAvg Score [100eps]: 119.55 \t Steps: 1000\n",
      "\n",
      "Episode 3780: \tActor Loss: 0.33 \tCritic Loss: 0.15 1\n",
      "\t\tAvg Score [100eps]: 120.84 \t Steps: 3071\n",
      "\n",
      "Episode 3790: \tActor Loss: 0.33 \tCritic Loss: 0.15 0\n",
      "\t\tAvg Score [100eps]: 130.42 \t Steps: 1000\n",
      "\n",
      "Episode 3800: \tActor Loss: 0.33 \tCritic Loss: 0.15 0\n",
      "\t\tAvg Score [100eps]: 115.76 \t Steps: 1000\n",
      "\n",
      "Episode 3810: \tActor Loss: 0.33 \tCritic Loss: 0.15 0\n",
      "\t\tAvg Score [100eps]: 119.77 \t Steps: 1000\n",
      "\n",
      "Episode 3820: \tActor Loss: 0.33 \tCritic Loss: 0.15 0\n",
      "\t\tAvg Score [100eps]: 118.44 \t Steps: 1000\n",
      "\n",
      "Episode 3830: \tActor Loss: 0.33 \tCritic Loss: 0.14 0\n",
      "\t\tAvg Score [100eps]: 131.19 \t Steps: 1000\n",
      "\n",
      "Episode 3840: \tActor Loss: 0.33 \tCritic Loss: 0.14 0\n",
      "\t\tAvg Score [100eps]: 123.77 \t Steps: 1000\n",
      "\n",
      "Episode 3850: \tActor Loss: 0.33 \tCritic Loss: 0.14 0\n",
      "\t\tAvg Score [100eps]: 127.52 \t Steps: 1000\n",
      "\n",
      "Episode 3860: \tActor Loss: 0.33 \tCritic Loss: 0.13 0\n",
      "\t\tAvg Score [100eps]: 117.94 \t Steps: 1000\n",
      "\n",
      "Episode 3870: \tActor Loss: 0.33 \tCritic Loss: 0.13 0\n",
      "\t\tAvg Score [100eps]: 117.17 \t Steps: 1000\n",
      "\n",
      "Episode 3880: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 109.77 \t Steps: 1000\n",
      "\n",
      "Episode 3890: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 102.39 \t Steps: 1000\n",
      "\n",
      "Episode 3900: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 119.81 \t Steps: 1000\n",
      "\n",
      "Episode 3910: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 128.14 \t Steps: 1000\n",
      "\n",
      "Episode 3920: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 117.60 \t Steps: 1000\n",
      "\n",
      "Episode 3930: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 121.54 \t Steps: 1000\n",
      "\n",
      "Episode 3940: \tActor Loss: 0.33 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 114.98 \t Steps: 1000\n",
      "\n",
      "Episode 3950: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 119.76 \t Steps: 1000\n",
      "\n",
      "Episode 3960: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 105.91 \t Steps: 1000\n",
      "\n",
      "Episode 3970: \tActor Loss: 0.33 \tCritic Loss: 0.12 0\n",
      "\t\tAvg Score [100eps]: 109.51 \t Steps: 1000\n",
      "\n",
      "Episode 3980: \tActor Loss: 0.33 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 112.66 \t Steps: 1000\n",
      "\n",
      "Episode 3990: \tActor Loss: 0.33 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 118.84 \t Steps: 1000\n",
      "\n",
      "Episode 4000: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 107.69 \t Steps: 1000\n",
      "\n",
      "Episode 4010: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 104.51 \t Steps: 1000\n",
      "\n",
      "Episode 4020: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 113.12 \t Steps: 1000\n",
      "\n",
      "Episode 4030: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 114.57 \t Steps: 1000\n",
      "\n",
      "Episode 4040: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 112.10 \t Steps: 1000\n",
      "\n",
      "Episode 4050: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 110.60 \t Steps: 1000\n",
      "\n",
      "Episode 4060: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 110.13 \t Steps: 1000\n",
      "\n",
      "Episode 4070: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 106.78 \t Steps: 1000\n",
      "\n",
      "Episode 4080: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 107.61 \t Steps: 1000\n",
      "\n",
      "Episode 4090: \tActor Loss: 0.32 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 111.04 \t Steps: 1000\n",
      "\n",
      "Episode 4100: \tActor Loss: 0.33 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 112.40 \t Steps: 1000\n",
      "\n",
      "Episode 4110: \tActor Loss: 0.33 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 109.71 \t Steps: 1000\n",
      "\n",
      "Episode 4120: \tActor Loss: 0.33 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 117.27 \t Steps: 1000\n",
      "\n",
      "Episode 4130: \tActor Loss: 0.33 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 125.83 \t Steps: 1000\n",
      "\n",
      "Episode 4140: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 133.85 \t Steps: 1000\n",
      "\n",
      "Episode 4150: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 132.83 \t Steps: 1000\n",
      "\n",
      "Episode 4160: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 131.53 \t Steps: 1000\n",
      "\n",
      "Episode 4170: \tActor Loss: 0.32 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 129.77 \t Steps: 1000\n",
      "\n",
      "Episode 4180: \tActor Loss: 0.31 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 130.13 \t Steps: 1000\n",
      "\n",
      "Episode 4190: \tActor Loss: 0.31 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 124.93 \t Steps: 1000\n",
      "\n",
      "Episode 4200: \tActor Loss: 0.30 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 126.74 \t Steps: 1000\n",
      "\n",
      "Episode 4210: \tActor Loss: 0.30 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 120.90 \t Steps: 1000\n",
      "\n",
      "Episode 4220: \tActor Loss: 0.30 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 121.69 \t Steps: 1000\n",
      "\n",
      "Episode 4230: \tActor Loss: 0.30 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 118.45 \t Steps: 1000\n",
      "\n",
      "Episode 4240: \tActor Loss: 0.30 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 120.38 \t Steps: 1000\n",
      "\n",
      "Episode 4250: \tActor Loss: 0.29 \tCritic Loss: 0.11 0\n",
      "\t\tAvg Score [100eps]: 115.04 \t Steps: 1000\n",
      "\n",
      "Episode 4260: \tActor Loss: 0.29 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 115.91 \t Steps: 1000\n",
      "\n",
      "Episode 4270: \tActor Loss: 0.29 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 117.06 \t Steps: 1000\n",
      "\n",
      "Episode 4280: \tActor Loss: 0.29 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 112.00 \t Steps: 1000\n",
      "\n",
      "Episode 4290: \tActor Loss: 0.29 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 113.86 \t Steps: 1000\n",
      "\n",
      "Episode 4300: \tActor Loss: 0.29 \tCritic Loss: 0.10 0\n",
      "\t\tAvg Score [100eps]: 110.77 \t Steps: 1000\n",
      "\n",
      "Episode 4310: \tActor Loss: 0.28 \tCritic Loss: 0.09 0\n",
      "\t\tAvg Score [100eps]: 109.59 \t Steps: 1000\n",
      "\n",
      "Episode 4320: \tActor Loss: 0.28 \tCritic Loss: 0.09 0\n",
      "\t\tAvg Score [100eps]: 110.91 \t Steps: 1000\n",
      "\n",
      "Episode 4330: \tActor Loss: 0.28 \tCritic Loss: 0.09 0\n",
      "\t\tAvg Score [100eps]: 109.85 \t Steps: 1000\n",
      "\n",
      "Episode 4340: \tActor Loss: 0.27 \tCritic Loss: 0.08 0\n",
      "\t\tAvg Score [100eps]: 111.58 \t Steps: 1000\n",
      "\n",
      "Episode 4350: \tActor Loss: 0.27 \tCritic Loss: 0.08 0\n",
      "\t\tAvg Score [100eps]: 110.09 \t Steps: 1000\n",
      "\n",
      "Episode 4360: \tActor Loss: 0.27 \tCritic Loss: 0.08 0\n",
      "\t\tAvg Score [100eps]: 109.35 \t Steps: 1000\n",
      "\n",
      "Episode 4370: \tActor Loss: 0.27 \tCritic Loss: 0.08 0\n",
      "\t\tAvg Score [100eps]: 109.30 \t Steps: 1000\n",
      "\n",
      "Episode 4380: \tActor Loss: 0.26 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 107.89 \t Steps: 1000\n",
      "\n",
      "Episode 4390: \tActor Loss: 0.26 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 110.38 \t Steps: 1000\n",
      "\n",
      "Episode 4400: \tActor Loss: 0.26 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 108.46 \t Steps: 1000\n",
      "\n",
      "Episode 4410: \tActor Loss: 0.26 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 103.53 \t Steps: 1000\n",
      "\n",
      "Episode 4420: \tActor Loss: 0.26 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 101.31 \t Steps: 1000\n",
      "\n",
      "Episode 4430: \tActor Loss: 0.25 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 102.11 \t Steps: 1000\n",
      "\n",
      "Episode 4440: \tActor Loss: 0.25 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 97.19 \t Steps: 1000\n",
      "\n",
      "Episode 4450: \tActor Loss: 0.25 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 97.61 \t Steps: 1000\n",
      "\n",
      "Episode 4460: \tActor Loss: 0.25 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 98.59 \t Steps: 1000\n",
      "\n",
      "Episode 4470: \tActor Loss: 0.25 \tCritic Loss: 0.07 0\n",
      "\t\tAvg Score [100eps]: 94.71 \t Steps: 1000\n",
      "\n",
      "Episode 4480: \tActor Loss: 0.25 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 96.41 \t Steps: 1000\n",
      "\n",
      "Episode 4490: \tActor Loss: 0.25 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 95.55 \t Steps: 1000\n",
      "\n",
      "Episode 4500: \tActor Loss: 0.25 \tCritic Loss: 0.07 \n",
      "\t\tAvg Score [100eps]: 96.57 \t Steps: 1000\n",
      "\n",
      "Episode 4510: \tActor Loss: 0.24 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 95.22 \t Steps: 1000\n",
      "\n",
      "Episode 4520: \tActor Loss: 0.24 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 93.74 \t Steps: 1000\n",
      "\n",
      "Episode 4530: \tActor Loss: 0.24 \tCritic Loss: 0.06 \n",
      "\t\tAvg Score [100eps]: 94.57 \t Steps: 1000\n",
      "\n",
      "Episode 4540: \tActor Loss: 0.23 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 94.85 \t Steps: 1000\n",
      "\n",
      "Episode 4550: \tActor Loss: 0.23 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 94.54 \t Steps: 1000\n",
      "\n",
      "Episode 4560: \tActor Loss: 0.23 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 93.28 \t Steps: 1000\n",
      "\n",
      "Episode 4570: \tActor Loss: 0.22 \tCritic Loss: 0.05 \n",
      "\t\tAvg Score [100eps]: 93.13 \t Steps: 1000\n",
      "\n",
      "Episode 4580: \tActor Loss: 0.22 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 93.27 \t Steps: 1000\n",
      "\n",
      "Episode 4590: \tActor Loss: 0.21 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 93.14 \t Steps: 1000\n",
      "\n",
      "Episode 4600: \tActor Loss: 0.21 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 93.43 \t Steps: 1000\n",
      "\n",
      "Episode 4610: \tActor Loss: 0.21 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 91.86 \t Steps: 1000\n",
      "\n",
      "Episode 4620: \tActor Loss: 0.21 \tCritic Loss: 0.04 \n",
      "\t\tAvg Score [100eps]: 92.75 \t Steps: 1000\n",
      "\n",
      "Episode 4630: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 93.48 \t Steps: 1000\n",
      "\n",
      "Episode 4640: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 92.64 \t Steps: 1000\n",
      "\n",
      "Episode 4650: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 93.51 \t Steps: 1000\n",
      "\n",
      "Episode 4660: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 92.98 \t Steps: 1000\n",
      "\n",
      "Episode 4670: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 92.00 \t Steps: 1000\n",
      "\n",
      "Episode 4680: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 92.79 \t Steps: 1000\n",
      "\n",
      "Episode 4690: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 92.28 \t Steps: 1000\n",
      "\n",
      "Episode 4700: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 90.85 \t Steps: 1000\n",
      "\n",
      "Episode 4710: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 91.06 \t Steps: 1000\n",
      "\n",
      "Episode 4720: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 89.74 \t Steps: 1000\n",
      "\n",
      "Episode 4730: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 89.36 \t Steps: 1000\n",
      "\n",
      "Episode 4740: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 87.35 \t Steps: 1000\n",
      "\n",
      "Episode 4750: \tActor Loss: 0.21 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 89.36 \t Steps: 1000\n",
      "\n",
      "Episode 4760: \tActor Loss: 0.21 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 86.08 \t Steps: 1000\n",
      "\n",
      "Episode 4770: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 87.23 \t Steps: 1000\n",
      "\n",
      "Episode 4780: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 86.13 \t Steps: 1000\n",
      "\n",
      "Episode 4790: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 84.25 \t Steps: 1000\n",
      "\n",
      "Episode 4800: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 85.82 \t Steps: 1000\n",
      "\n",
      "Episode 4810: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 83.33 \t Steps: 1000\n",
      "\n",
      "Episode 4820: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 84.40 \t Steps: 1000\n",
      "\n",
      "Episode 4830: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 83.29 \t Steps: 1000\n",
      "\n",
      "Episode 4840: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 83.62 \t Steps: 1000\n",
      "\n",
      "Episode 4850: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 82.41 \t Steps: 1000\n",
      "\n",
      "Episode 4860: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 82.19 \t Steps: 1000\n",
      "\n",
      "Episode 4870: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 81.48 \t Steps: 1000\n",
      "\n",
      "Episode 4880: \tActor Loss: 0.22 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 82.18 \t Steps: 1000\n",
      "\n",
      "Episode 4890: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 80.58 \t Steps: 1000\n",
      "\n",
      "Episode 4900: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 80.71 \t Steps: 1000\n",
      "\n",
      "Episode 4910: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 80.99 \t Steps: 1000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4920: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 80.66 \t Steps: 1000\n",
      "\n",
      "Episode 4930: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 80.50 \t Steps: 1000\n",
      "\n",
      "Episode 4940: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 79.91 \t Steps: 1000\n",
      "\n",
      "Episode 4950: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 78.07 \t Steps: 1000\n",
      "\n",
      "Episode 4960: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 77.90 \t Steps: 1000\n",
      "\n",
      "Episode 4970: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 77.85 \t Steps: 1000\n",
      "\n",
      "Episode 4980: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 77.00 \t Steps: 1000\n",
      "\n",
      "Episode 4990: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 77.47 \t Steps: 1000\n",
      "\n",
      "Episode 5000: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 76.93 \t Steps: 1000\n",
      "\n",
      "Episode 5010: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 76.53 \t Steps: 1000\n",
      "\n",
      "Episode 5020: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 76.36 \t Steps: 1000\n",
      "\n",
      "Episode 5030: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 75.69 \t Steps: 1000\n",
      "\n",
      "Episode 5040: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 75.57 \t Steps: 1000\n",
      "\n",
      "Episode 5050: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 72.44 \t Steps: 1000\n",
      "\n",
      "Episode 5060: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 72.94 \t Steps: 1000\n",
      "\n",
      "Episode 5070: \tActor Loss: 0.22 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.28 \t Steps: 1000\n",
      "\n",
      "Episode 5080: \tActor Loss: 0.23 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.74 \t Steps: 1000\n",
      "\n",
      "Episode 5090: \tActor Loss: 0.23 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.61 \t Steps: 1000\n",
      "\n",
      "Episode 5100: \tActor Loss: 0.23 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.28 \t Steps: 1000\n",
      "\n",
      "Episode 5110: \tActor Loss: 0.23 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 71.65 \t Steps: 1000\n",
      "\n",
      "Episode 5120: \tActor Loss: 0.24 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 74.85 \t Steps: 1000\n",
      "\n",
      "Episode 5130: \tActor Loss: 0.24 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 74.16 \t Steps: 1000\n",
      "\n",
      "Episode 5140: \tActor Loss: 0.24 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.49 \t Steps: 1000\n",
      "\n",
      "Episode 5150: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 73.42 \t Steps: 1000\n",
      "\n",
      "Episode 5160: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 72.39 \t Steps: 1000\n",
      "\n",
      "Episode 5170: \tActor Loss: 0.26 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 72.31 \t Steps: 1000\n",
      "\n",
      "Episode 5180: \tActor Loss: 0.26 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 72.85 \t Steps: 1000\n",
      "\n",
      "Episode 5190: \tActor Loss: 0.26 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 71.32 \t Steps: 1000\n",
      "\n",
      "Episode 5200: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 71.41 \t Steps: 1000\n",
      "\n",
      "Episode 5210: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 71.93 \t Steps: 1000\n",
      "\n",
      "Episode 5220: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 70.47 \t Steps: 1000\n",
      "\n",
      "Episode 5230: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 71.41 \t Steps: 1000\n",
      "\n",
      "Episode 5240: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 66.19 \t Steps: 1000\n",
      "\n",
      "Episode 5250: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 66.75 \t Steps: 1000\n",
      "\n",
      "Episode 5260: \tActor Loss: 0.27 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 69.80 \t Steps: 1000\n",
      "\n",
      "Episode 5270: \tActor Loss: 0.26 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 68.11 \t Steps: 1000\n",
      "\n",
      "Episode 5280: \tActor Loss: 0.26 \tCritic Loss: 0.03 \n",
      "\t\tAvg Score [100eps]: 68.04 \t Steps: 1000\n",
      "\n",
      "Episode 5290: \tActor Loss: 0.26 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 66.92 \t Steps: 1000\n",
      "\n",
      "Episode 5300: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 64.49 \t Steps: 1000\n",
      "\n",
      "Episode 5310: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 66.34 \t Steps: 1000\n",
      "\n",
      "Episode 5320: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 64.43 \t Steps: 1000\n",
      "\n",
      "Episode 5330: \tActor Loss: 0.25 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 62.82 \t Steps: 1000\n",
      "\n",
      "Episode 5340: \tActor Loss: 0.24 \tCritic Loss: 0.02 \n",
      "\t\tAvg Score [100eps]: 64.26 \t Steps: 1000\n",
      "\n",
      "Episode 5350: \tActor Loss: 0.24 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 62.06 \t Steps: 1000\n",
      "\n",
      "Episode 5360: \tActor Loss: 0.24 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 63.26 \t Steps: 1000\n",
      "\n",
      "Episode 5370: \tActor Loss: 0.24 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 63.64 \t Steps: 1000\n",
      "\n",
      "Episode 5380: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 62.87 \t Steps: 1000\n",
      "\n",
      "Episode 5390: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 62.18 \t Steps: 1000\n",
      "\n",
      "Episode 5400: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 61.58 \t Steps: 1000\n",
      "\n",
      "Episode 5410: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 60.71 \t Steps: 1000\n",
      "\n",
      "Episode 5420: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 59.91 \t Steps: 1000\n",
      "\n",
      "Episode 5430: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 62.35 \t Steps: 1000\n",
      "\n",
      "Episode 5440: \tActor Loss: 0.23 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 60.82 \t Steps: 1000\n",
      "\n",
      "Episode 5450: \tActor Loss: 0.22 \tCritic Loss: 0.01 \n",
      "\t\tAvg Score [100eps]: 60.79 \t Steps: 1000\n",
      "\n",
      "Episode 5454\t Score [This Eps]: 60.31 \t Steps: 1000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0b268680db73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Detach everything to ensure no backprop to these old experiences stored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# Increase starting Learning Rate\n",
    "# Results: \n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 4096       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.lr = 1.5e-4\n",
    "params.num_steps_collect_data = 4096\n",
    "params.batch_size = 2048\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-10--19:07:50 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.04 \tCritic Loss: 0.13 \n",
      "\t\tAvg Score [100eps]: 54.81 \t Steps: 8191\n",
      "\n",
      "Episode 20: \tActor Loss: 0.06 \tCritic Loss: 0.73 1\n",
      "\t\tAvg Score [100eps]: 256.00 \t Steps: 8191\n",
      "\n",
      "Episode 30: \tActor Loss: 0.11 \tCritic Loss: 2.06 1\n",
      "\t\tAvg Score [100eps]: 368.24 \t Steps: 8191\n",
      "\n",
      "Episode 33\t Score [This Eps]: 398.35 \t Steps: 8191NaN next_states Found! Skipping this episode.\n",
      "Episode 40: \tActor Loss: 0.15 \tCritic Loss: 2.67 1\n",
      "\t\tAvg Score [100eps]: 490.86 \t Steps: 8191\n",
      "\n",
      "Episode 50: \tActor Loss: 0.17 \tCritic Loss: 2.90 1\n",
      "\t\tAvg Score [100eps]: 589.38 \t Steps: 8191\n",
      "\n",
      "NaN Reward Found! Skipping this episode.\n",
      "Episode 60: \tActor Loss: 0.18 \tCritic Loss: 2.76 1\n",
      "\t\tAvg Score [100eps]: 620.48 \t Steps: 8191\n",
      "\n",
      "Episode 70: \tActor Loss: 0.19 \tCritic Loss: 2.56 1\n",
      "\t\tAvg Score [100eps]: 636.69 \t Steps: 8191\n",
      "\n",
      "Episode 80: \tActor Loss: 0.19 \tCritic Loss: 2.41 1\n",
      "\t\tAvg Score [100eps]: 713.18 \t Steps: 8191\n",
      "\n",
      "Episode 86\t Score [This Eps]: 807.13 \t Steps: 8191NaN next_states Found! Skipping this episode.\n",
      "Episode 90: \tActor Loss: 0.19 \tCritic Loss: 2.31 1\n",
      "\t\tAvg Score [100eps]: 874.46 \t Steps: 8191\n",
      "\n",
      "Episode 100: \tActor Loss: 0.20 \tCritic Loss: 2.21 1\n",
      "\t\tAvg Score [100eps]: 932.49 \t Steps: 8191\n",
      "\n",
      "Episode 110: \tActor Loss: 0.21 \tCritic Loss: 2.27 1\n",
      "\t\tAvg Score [100eps]: 910.13 \t Steps: 8191\n",
      "\n",
      "Episode 120: \tActor Loss: 0.23 \tCritic Loss: 2.34 11\n",
      "\t\tAvg Score [100eps]: 988.71 \t Steps: 8191\n",
      "\n",
      "Episode 130: \tActor Loss: 0.22 \tCritic Loss: 2.10 91\n",
      "\t\tAvg Score [100eps]: 1102.11 \t Steps: 8191\n",
      "\n",
      "Episode 140: \tActor Loss: 0.21 \tCritic Loss: 1.76 00\n",
      "\t\tAvg Score [100eps]: 1126.08 \t Steps: 1000\n",
      "\n",
      "Episode 150: \tActor Loss: 0.20 \tCritic Loss: 1.52 11\n",
      "\t\tAvg Score [100eps]: 955.96 \t Steps: 8191\n",
      "\n",
      "Episode 160: \tActor Loss: 0.20 \tCritic Loss: 1.45 91\n",
      "\t\tAvg Score [100eps]: 1142.80 \t Steps: 8191\n",
      "\n",
      "Episode 170: \tActor Loss: 0.18 \tCritic Loss: 1.44 91\n",
      "\t\tAvg Score [100eps]: 1082.08 \t Steps: 8191\n",
      "\n",
      "Episode 180: \tActor Loss: 0.18 \tCritic Loss: 1.50 91\n",
      "\t\tAvg Score [100eps]: 1063.13 \t Steps: 8191\n",
      "\n",
      "Episode 190: \tActor Loss: 0.18 \tCritic Loss: 1.54 91\n",
      "\t\tAvg Score [100eps]: 1204.97 \t Steps: 8191\n",
      "\n",
      "Episode 200: \tActor Loss: 0.18 \tCritic Loss: 1.62 91\n",
      "\t\tAvg Score [100eps]: 1204.63 \t Steps: 8191\n",
      "\n",
      "Episode 210: \tActor Loss: 0.18 \tCritic Loss: 1.71 00\n",
      "\t\tAvg Score [100eps]: 1312.43 \t Steps: 1000\n",
      "\n",
      "Episode 220: \tActor Loss: 0.17 \tCritic Loss: 1.84 91\n",
      "\t\tAvg Score [100eps]: 1382.65 \t Steps: 8191\n",
      "\n",
      "Episode 230: \tActor Loss: 0.19 \tCritic Loss: 1.93 91\n",
      "\t\tAvg Score [100eps]: 1316.92 \t Steps: 8191\n",
      "\n",
      "Episode 240: \tActor Loss: 0.19 \tCritic Loss: 2.06 91\n",
      "\t\tAvg Score [100eps]: 1437.46 \t Steps: 8191\n",
      "\n",
      "Episode 250: \tActor Loss: 0.49 \tCritic Loss: 2.18 91\n",
      "\t\tAvg Score [100eps]: 1256.18 \t Steps: 8191\n",
      "\n",
      "Episode 260: \tActor Loss: 0.48 \tCritic Loss: 2.34 91\n",
      "\t\tAvg Score [100eps]: 1367.49 \t Steps: 8191\n",
      "\n",
      "Episode 270: \tActor Loss: 0.48 \tCritic Loss: 2.59 00\n",
      "\t\tAvg Score [100eps]: 1390.92 \t Steps: 1000\n",
      "\n",
      "Episode 280: \tActor Loss: 0.47 \tCritic Loss: 2.71 91\n",
      "\t\tAvg Score [100eps]: 1347.15 \t Steps: 8191\n",
      "\n",
      "Episode 290: \tActor Loss: 0.46 \tCritic Loss: 2.81 00\n",
      "\t\tAvg Score [100eps]: 1450.40 \t Steps: 1000\n",
      "\n",
      "Episode 300: \tActor Loss: 0.45 \tCritic Loss: 2.93 91\n",
      "\t\tAvg Score [100eps]: 1372.54 \t Steps: 8191\n",
      "\n",
      "Episode 310: \tActor Loss: 0.43 \tCritic Loss: 3.04 91\n",
      "\t\tAvg Score [100eps]: 1487.57 \t Steps: 8191\n",
      "\n",
      "Episode 320: \tActor Loss: 0.46 \tCritic Loss: 3.11 91\n",
      "\t\tAvg Score [100eps]: 1502.15 \t Steps: 8191\n",
      "\n",
      "Episode 330: \tActor Loss: 0.44 \tCritic Loss: 3.22 00\n",
      "\t\tAvg Score [100eps]: 1513.84 \t Steps: 1000\n",
      "\n",
      "Episode 340: \tActor Loss: 0.44 \tCritic Loss: 3.29 91\n",
      "\t\tAvg Score [100eps]: 1464.96 \t Steps: 8191\n",
      "\n",
      "Episode 350: \tActor Loss: 0.14 \tCritic Loss: 3.32 00\n",
      "\t\tAvg Score [100eps]: 1524.72 \t Steps: 1000\n",
      "\n",
      "Episode 360: \tActor Loss: 0.14 \tCritic Loss: 3.38 91\n",
      "\t\tAvg Score [100eps]: 1485.62 \t Steps: 8191\n",
      "\n",
      "Episode 370: \tActor Loss: 0.14 \tCritic Loss: 3.30 00\n",
      "\t\tAvg Score [100eps]: 1506.68 \t Steps: 1000\n",
      "\n",
      "Episode 380: \tActor Loss: 0.14 \tCritic Loss: 3.29 91\n",
      "\t\tAvg Score [100eps]: 1566.12 \t Steps: 8191\n",
      "\n",
      "Episode 390: \tActor Loss: 0.14 \tCritic Loss: 3.36 00\n",
      "\t\tAvg Score [100eps]: 1620.59 \t Steps: 1000\n",
      "\n",
      "Episode 400: \tActor Loss: 0.14 \tCritic Loss: 3.34 91\n",
      "\t\tAvg Score [100eps]: 1581.22 \t Steps: 8191\n",
      "\n",
      "Episode 410: \tActor Loss: 0.13 \tCritic Loss: 3.37 00\n",
      "\t\tAvg Score [100eps]: 1618.94 \t Steps: 1000\n",
      "\n",
      "Episode 420: \tActor Loss: 0.11 \tCritic Loss: 3.39 00\n",
      "\t\tAvg Score [100eps]: 1665.51 \t Steps: 1000\n",
      "\n",
      "Episode 430: \tActor Loss: 0.11 \tCritic Loss: 3.41 91\n",
      "\t\tAvg Score [100eps]: 1617.17 \t Steps: 8191\n",
      "\n",
      "Episode 440: \tActor Loss: 0.11 \tCritic Loss: 3.39 91\n",
      "\t\tAvg Score [100eps]: 1688.24 \t Steps: 8191\n",
      "\n",
      "Episode 450: \tActor Loss: 0.11 \tCritic Loss: 3.39 00\n",
      "\t\tAvg Score [100eps]: 1703.38 \t Steps: 1000\n",
      "\n",
      "Episode 460: \tActor Loss: 0.11 \tCritic Loss: 3.38 91\n",
      "\t\tAvg Score [100eps]: 1746.93 \t Steps: 8191\n",
      "\n",
      "Episode 470: \tActor Loss: 0.11 \tCritic Loss: 3.41 91\n",
      "\t\tAvg Score [100eps]: 1747.87 \t Steps: 8191\n",
      "\n",
      "Episode 480: \tActor Loss: 0.11 \tCritic Loss: 3.46 91\n",
      "\t\tAvg Score [100eps]: 1735.92 \t Steps: 8191\n",
      "\n",
      "Episode 490: \tActor Loss: 0.11 \tCritic Loss: 3.42 00\n",
      "\t\tAvg Score [100eps]: 1749.53 \t Steps: 1000\n",
      "\n",
      "Episode 500: \tActor Loss: 0.12 \tCritic Loss: 3.46 00\n",
      "\t\tAvg Score [100eps]: 1767.55 \t Steps: 1000\n",
      "\n",
      "Episode 510: \tActor Loss: 0.12 \tCritic Loss: 3.41 00\n",
      "\t\tAvg Score [100eps]: 1760.85 \t Steps: 1000\n",
      "\n",
      "Episode 520: \tActor Loss: 0.11 \tCritic Loss: 3.37 91\n",
      "\t\tAvg Score [100eps]: 1789.10 \t Steps: 8191\n",
      "\n",
      "Episode 530: \tActor Loss: 0.11 \tCritic Loss: 3.34 91\n",
      "\t\tAvg Score [100eps]: 1717.61 \t Steps: 8191\n",
      "\n",
      "Episode 540: \tActor Loss: 0.10 \tCritic Loss: 3.35 00\n",
      "\t\tAvg Score [100eps]: 1784.68 \t Steps: 1000\n",
      "\n",
      "Episode 550: \tActor Loss: 0.11 \tCritic Loss: 3.40 00\n",
      "\t\tAvg Score [100eps]: 1820.72 \t Steps: 1000\n",
      "\n",
      "Episode 560: \tActor Loss: 0.11 \tCritic Loss: 3.41 91\n",
      "\t\tAvg Score [100eps]: 1808.45 \t Steps: 8191\n",
      "\n",
      "Episode 570: \tActor Loss: 0.11 \tCritic Loss: 3.41 00\n",
      "\t\tAvg Score [100eps]: 1834.77 \t Steps: 1000\n",
      "\n",
      "Episode 580: \tActor Loss: 0.11 \tCritic Loss: 3.38 00\n",
      "\t\tAvg Score [100eps]: 1866.37 \t Steps: 1000\n",
      "\n",
      "Episode 590: \tActor Loss: 0.12 \tCritic Loss: 3.38 00\n",
      "\t\tAvg Score [100eps]: 1847.18 \t Steps: 1000\n",
      "\n",
      "Episode 600: \tActor Loss: 0.12 \tCritic Loss: 3.41 91\n",
      "\t\tAvg Score [100eps]: 1786.60 \t Steps: 8191\n",
      "\n",
      "Episode 610: \tActor Loss: 0.12 \tCritic Loss: 3.40 00\n",
      "\t\tAvg Score [100eps]: 1866.31 \t Steps: 1000\n",
      "\n",
      "Episode 620: \tActor Loss: 0.12 \tCritic Loss: 3.42 91\n",
      "\t\tAvg Score [100eps]: 1892.15 \t Steps: 8191\n",
      "\n",
      "Episode 630: \tActor Loss: 0.12 \tCritic Loss: 3.48 91\n",
      "\t\tAvg Score [100eps]: 1863.79 \t Steps: 8191\n",
      "\n",
      "Episode 640: \tActor Loss: 0.13 \tCritic Loss: 3.50 91\n",
      "\t\tAvg Score [100eps]: 1794.17 \t Steps: 8191\n",
      "\n",
      "Episode 650: \tActor Loss: 0.13 \tCritic Loss: 3.48 00\n",
      "\t\tAvg Score [100eps]: 1855.41 \t Steps: 1000\n",
      "\n",
      "Episode 660: \tActor Loss: 0.13 \tCritic Loss: 3.48 00\n",
      "\t\tAvg Score [100eps]: 1915.57 \t Steps: 1000\n",
      "\n",
      "Episode 670: \tActor Loss: 0.13 \tCritic Loss: 3.49 00\n",
      "\t\tAvg Score [100eps]: 1908.37 \t Steps: 1000\n",
      "\n",
      "Episode 680: \tActor Loss: 0.13 \tCritic Loss: 3.49 91\n",
      "\t\tAvg Score [100eps]: 1956.75 \t Steps: 8191\n",
      "\n",
      "Episode 690: \tActor Loss: 0.12 \tCritic Loss: 3.47 91\n",
      "\t\tAvg Score [100eps]: 1902.26 \t Steps: 8191\n",
      "\n",
      "Episode 700: \tActor Loss: 0.13 \tCritic Loss: 3.44 00\n",
      "\t\tAvg Score [100eps]: 1979.60 \t Steps: 1000\n",
      "\n",
      "Episode 710: \tActor Loss: 0.13 \tCritic Loss: 3.48 91\n",
      "\t\tAvg Score [100eps]: 2067.45 \t Steps: 8191\n",
      "\n",
      "Episode 720: \tActor Loss: 0.13 \tCritic Loss: 3.49 00\n",
      "\t\tAvg Score [100eps]: 2044.39 \t Steps: 1000\n",
      "\n",
      "Episode 730: \tActor Loss: 0.13 \tCritic Loss: 3.48 00\n",
      "\t\tAvg Score [100eps]: 2057.20 \t Steps: 1000\n",
      "\n",
      "Episode 740: \tActor Loss: 0.14 \tCritic Loss: 3.49 00\n",
      "\t\tAvg Score [100eps]: 1985.72 \t Steps: 1000\n",
      "\n",
      "Episode 750: \tActor Loss: 0.14 \tCritic Loss: 3.44 00\n",
      "\t\tAvg Score [100eps]: 2077.90 \t Steps: 1000\n",
      "\n",
      "Episode 760: \tActor Loss: 0.14 \tCritic Loss: 3.39 91\n",
      "\t\tAvg Score [100eps]: 2063.31 \t Steps: 8191\n",
      "\n",
      "Episode 770: \tActor Loss: 0.15 \tCritic Loss: 3.39 91\n",
      "\t\tAvg Score [100eps]: 1874.75 \t Steps: 8191\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 780: \tActor Loss: 0.16 \tCritic Loss: 3.49 00\n",
      "\t\tAvg Score [100eps]: 2047.70 \t Steps: 1000\n",
      "\n",
      "Episode 790: \tActor Loss: 0.16 \tCritic Loss: 3.56 00\n",
      "\t\tAvg Score [100eps]: 2074.18 \t Steps: 1000\n",
      "\n",
      "Episode 800: \tActor Loss: 0.16 \tCritic Loss: 3.59 00\n",
      "\t\tAvg Score [100eps]: 2116.26 \t Steps: 1000\n",
      "\n",
      "Episode 810: \tActor Loss: 0.16 \tCritic Loss: 3.68 00\n",
      "\t\tAvg Score [100eps]: 2102.80 \t Steps: 1000\n",
      "\n",
      "Episode 820: \tActor Loss: 0.16 \tCritic Loss: 3.77 00\n",
      "\t\tAvg Score [100eps]: 2181.00 \t Steps: 1000\n",
      "\n",
      "Episode 830: \tActor Loss: 0.20 \tCritic Loss: 3.79 91\n",
      "\t\tAvg Score [100eps]: 2105.13 \t Steps: 8191\n",
      "\n",
      "Episode 840: \tActor Loss: 0.20 \tCritic Loss: 3.79 91\n",
      "\t\tAvg Score [100eps]: 2027.07 \t Steps: 8191\n",
      "\n",
      "Episode 850: \tActor Loss: 0.21 \tCritic Loss: 3.92 00\n",
      "\t\tAvg Score [100eps]: 2057.28 \t Steps: 1000\n",
      "\n",
      "Episode 860: \tActor Loss: 0.21 \tCritic Loss: 3.89 00\n",
      "\t\tAvg Score [100eps]: 2167.94 \t Steps: 1000\n",
      "\n",
      "Episode 870: \tActor Loss: 0.21 \tCritic Loss: 3.98 91\n",
      "\t\tAvg Score [100eps]: 1084.10 \t Steps: 8191\n",
      "\n",
      "Episode 878\t Score [This Eps]: 197.54 \t Steps: 8191NaN next_states Found! Skipping this episode.\n",
      "Episode 880: \tActor Loss: 0.22 \tCritic Loss: 4.12 1\n",
      "\t\tAvg Score [100eps]: 182.79 \t Steps: 8191\n",
      "\n",
      "NaN next_states Found! Skipping this episode.\n",
      "Episode 890: \tActor Loss: 0.25 \tCritic Loss: 4.31 91\n",
      "\t\tAvg Score [100eps]: 1627.49 \t Steps: 8191\n",
      "\n",
      "Episode 900: \tActor Loss: 0.27 \tCritic Loss: 4.54 10\n",
      "\t\tAvg Score [100eps]: 780.86 \t Steps: 8191\n",
      "\n",
      "Episode 910: \tActor Loss: 0.27 \tCritic Loss: 4.35 0\n",
      "\t\tAvg Score [100eps]: 978.49 \t Steps: 1000\n",
      "\n",
      "Episode 920: \tActor Loss: 0.27 \tCritic Loss: 4.15 00\n",
      "\t\tAvg Score [100eps]: 1013.89 \t Steps: 1000\n",
      "\n",
      "Episode 930: \tActor Loss: 0.27 \tCritic Loss: 4.06 91\n",
      "\t\tAvg Score [100eps]: 1295.17 \t Steps: 8191\n",
      "\n",
      "Episode 940: \tActor Loss: 0.25 \tCritic Loss: 3.95 91\n",
      "\t\tAvg Score [100eps]: 1452.57 \t Steps: 8191\n",
      "\n",
      "Episode 950: \tActor Loss: 0.24 \tCritic Loss: 3.73 91\n",
      "\t\tAvg Score [100eps]: 1532.50 \t Steps: 8191\n",
      "\n",
      "Episode 960: \tActor Loss: 0.25 \tCritic Loss: 3.65 00\n",
      "\t\tAvg Score [100eps]: 1675.26 \t Steps: 1000\n",
      "\n",
      "Episode 970: \tActor Loss: 0.24 \tCritic Loss: 3.52 91\n",
      "\t\tAvg Score [100eps]: 1731.09 \t Steps: 8191\n",
      "\n",
      "Episode 980: \tActor Loss: 0.23 \tCritic Loss: 3.12 00\n",
      "\t\tAvg Score [100eps]: 1806.16 \t Steps: 1000\n",
      "\n",
      "Episode 990: \tActor Loss: 0.22 \tCritic Loss: 2.82 91\n",
      "\t\tAvg Score [100eps]: 1277.75 \t Steps: 8191\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.21 \tCritic Loss: 2.51 91\n",
      "\t\tAvg Score [100eps]: 1639.79 \t Steps: 8191\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.21 \tCritic Loss: 2.50 00\n",
      "\t\tAvg Score [100eps]: 1771.15 \t Steps: 1000\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.22 \tCritic Loss: 2.59 91\n",
      "\t\tAvg Score [100eps]: 1203.77 \t Steps: 8191\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.24 \tCritic Loss: 2.64 10\n",
      "\t\tAvg Score [100eps]: 803.00 \t Steps: 8191\n",
      "\n",
      "Episode 1040: \tActor Loss: 0.25 \tCritic Loss: 2.66 1\n",
      "\t\tAvg Score [100eps]: 515.35 \t Steps: 8191\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.25 \tCritic Loss: 2.54 1\n",
      "\t\tAvg Score [100eps]: 553.19 \t Steps: 8191\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.26 \tCritic Loss: 2.43 1\n",
      "\t\tAvg Score [100eps]: 693.60 \t Steps: 8191\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.27 \tCritic Loss: 2.34 1\n",
      "\t\tAvg Score [100eps]: 995.13 \t Steps: 8191\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.28 \tCritic Loss: 2.33 00\n",
      "\t\tAvg Score [100eps]: 1040.54 \t Steps: 1000\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.29 \tCritic Loss: 2.24 91\n",
      "\t\tAvg Score [100eps]: 1312.91 \t Steps: 8191\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.29 \tCritic Loss: 2.19 00\n",
      "\t\tAvg Score [100eps]: 1538.16 \t Steps: 1000\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.30 \tCritic Loss: 2.19 00\n",
      "\t\tAvg Score [100eps]: 1743.23 \t Steps: 1000\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.30 \tCritic Loss: 2.13 00\n",
      "\t\tAvg Score [100eps]: 1551.99 \t Steps: 1000\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.29 \tCritic Loss: 2.03 91\n",
      "\t\tAvg Score [100eps]: 1582.35 \t Steps: 8191\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.28 \tCritic Loss: 2.04 00\n",
      "\t\tAvg Score [100eps]: 1655.90 \t Steps: 1000\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.29 \tCritic Loss: 2.23 11\n",
      "\t\tAvg Score [100eps]: 984.13 \t Steps: 8191\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.29 \tCritic Loss: 2.35 11\n",
      "\t\tAvg Score [100eps]: 887.31 \t Steps: 8191\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.30 \tCritic Loss: 2.50 00\n",
      "\t\tAvg Score [100eps]: 1441.66 \t Steps: 1000\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.30 \tCritic Loss: 2.58 00\n",
      "\t\tAvg Score [100eps]: 1462.98 \t Steps: 1000\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.30 \tCritic Loss: 2.67 91\n",
      "\t\tAvg Score [100eps]: 1551.91 \t Steps: 8191\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.30 \tCritic Loss: 2.74 00\n",
      "\t\tAvg Score [100eps]: 1220.10 \t Steps: 1000\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.32 \tCritic Loss: 2.80 00\n",
      "\t\tAvg Score [100eps]: 1148.38 \t Steps: 1000\n",
      "\n",
      "Episode 1216\t Score [This Eps]: 581.88 \t Steps: 8191NaN next_states Found! Skipping this episode.\n",
      "Episode 1220: \tActor Loss: 0.32 \tCritic Loss: 2.79 1\n",
      "\t\tAvg Score [100eps]: 810.49 \t Steps: 8191\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.33 \tCritic Loss: 2.75 00\n",
      "\t\tAvg Score [100eps]: 1060.24 \t Steps: 1000\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.33 \tCritic Loss: 2.70 91\n",
      "\t\tAvg Score [100eps]: 1044.07 \t Steps: 8191\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.33 \tCritic Loss: 2.57 91\n",
      "\t\tAvg Score [100eps]: 1122.60 \t Steps: 8191\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.34 \tCritic Loss: 2.56 91\n",
      "\t\tAvg Score [100eps]: 1045.44 \t Steps: 8191\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.35 \tCritic Loss: 2.58 91\n",
      "\t\tAvg Score [100eps]: 1404.90 \t Steps: 8191\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.34 \tCritic Loss: 2.56 91\n",
      "\t\tAvg Score [100eps]: 1607.94 \t Steps: 8191\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.35 \tCritic Loss: 2.59 91\n",
      "\t\tAvg Score [100eps]: 1220.06 \t Steps: 8191\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.35 \tCritic Loss: 2.60 91\n",
      "\t\tAvg Score [100eps]: 1226.32 \t Steps: 8191\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.33 \tCritic Loss: 2.53 91\n",
      "\t\tAvg Score [100eps]: 1223.35 \t Steps: 8191\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.33 \tCritic Loss: 2.58 91\n",
      "\t\tAvg Score [100eps]: 1058.21 \t Steps: 8191\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.33 \tCritic Loss: 2.67 91\n",
      "\t\tAvg Score [100eps]: 1271.55 \t Steps: 8191\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.34 \tCritic Loss: 2.71 91\n",
      "\t\tAvg Score [100eps]: 1450.15 \t Steps: 8191\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.34 \tCritic Loss: 2.76 11\n",
      "\t\tAvg Score [100eps]: 569.20 \t Steps: 8191\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.34 \tCritic Loss: 2.75 00\n",
      "\t\tAvg Score [100eps]: 1081.15 \t Steps: 1000\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.34 \tCritic Loss: 2.61 11\n",
      "\t\tAvg Score [100eps]: 752.00 \t Steps: 8191\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.34 \tCritic Loss: 2.50 1\n",
      "\t\tAvg Score [100eps]: 946.63 \t Steps: 8191\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.34 \tCritic Loss: 2.37 1\n",
      "\t\tAvg Score [100eps]: 528.91 \t Steps: 8191\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.34 \tCritic Loss: 2.28 1\n",
      "\t\tAvg Score [100eps]: 398.25 \t Steps: 8191\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.34 \tCritic Loss: 2.22 1\n",
      "\t\tAvg Score [100eps]: 730.49 \t Steps: 8191\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.35 \tCritic Loss: 2.09 1\n",
      "\t\tAvg Score [100eps]: 486.93 \t Steps: 8191\n",
      "\n",
      "Episode 1423\t Score [This Eps]: 612.21 \t Steps: 8191NaN next_states Found! Skipping this episode.\n",
      "Episode 1430: \tActor Loss: 0.35 \tCritic Loss: 1.97 1\n",
      "\t\tAvg Score [100eps]: 948.67 \t Steps: 8191\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.34 \tCritic Loss: 1.99 91\n",
      "\t\tAvg Score [100eps]: 1046.82 \t Steps: 8191\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.34 \tCritic Loss: 2.03 91\n",
      "\t\tAvg Score [100eps]: 1003.28 \t Steps: 8191\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.87 \tCritic Loss: 2.00 1\n",
      "\t\tAvg Score [100eps]: 925.90 \t Steps: 8191\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.85 \tCritic Loss: 2.00 10\n",
      "\t\tAvg Score [100eps]: 915.36 \t Steps: 8191\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.85 \tCritic Loss: 1.97 11\n",
      "\t\tAvg Score [100eps]: 994.68 \t Steps: 8191\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.86 \tCritic Loss: 2.01 01\n",
      "\t\tAvg Score [100eps]: 867.38 \t Steps: 1000\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.86 \tCritic Loss: 2.05 10\n",
      "\t\tAvg Score [100eps]: 990.89 \t Steps: 8191\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.86 \tCritic Loss: 2.04 00\n",
      "\t\tAvg Score [100eps]: 886.68 \t Steps: 1000\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.86 \tCritic Loss: 2.09 0\n",
      "\t\tAvg Score [100eps]: 786.17 \t Steps: 1000\n",
      "\n",
      "Episode 1530: \tActor Loss: 0.86 \tCritic Loss: 2.12 0\n",
      "\t\tAvg Score [100eps]: 732.79 \t Steps: 1000\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.87 \tCritic Loss: 2.05 0\n",
      "\t\tAvg Score [100eps]: 702.41 \t Steps: 1000\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.87 \tCritic Loss: 2.00 1\n",
      "\t\tAvg Score [100eps]: 686.07 \t Steps: 8191\n",
      "\n",
      "Episode 1560: \tActor Loss: 0.35 \tCritic Loss: 1.99 0\n",
      "\t\tAvg Score [100eps]: 556.11 \t Steps: 1000\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.40 \tCritic Loss: 2.01 1\n",
      "\t\tAvg Score [100eps]: 522.91 \t Steps: 8191\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.40 \tCritic Loss: 1.98 0\n",
      "\t\tAvg Score [100eps]: 536.07 \t Steps: 1000\n",
      "\n",
      "Episode 1590: \tActor Loss: 0.40 \tCritic Loss: 1.92 0\n",
      "\t\tAvg Score [100eps]: 523.36 \t Steps: 1000\n",
      "\n",
      "Episode 1600: \tActor Loss: 0.40 \tCritic Loss: 1.81 0\n",
      "\t\tAvg Score [100eps]: 468.30 \t Steps: 1000\n",
      "\n",
      "Episode 1610: \tActor Loss: 0.41 \tCritic Loss: 1.70 1\n",
      "\t\tAvg Score [100eps]: 421.19 \t Steps: 8191\n",
      "\n",
      "Episode 1620: \tActor Loss: 0.42 \tCritic Loss: 1.58 0\n",
      "\t\tAvg Score [100eps]: 413.20 \t Steps: 1000\n",
      "\n",
      "Episode 1630: \tActor Loss: 0.42 \tCritic Loss: 1.43 0\n",
      "\t\tAvg Score [100eps]: 458.44 \t Steps: 1000\n",
      "\n",
      "Episode 1640: \tActor Loss: 0.42 \tCritic Loss: 1.30 0\n",
      "\t\tAvg Score [100eps]: 468.47 \t Steps: 1000\n",
      "\n",
      "Episode 1650: \tActor Loss: 0.42 \tCritic Loss: 1.13 0\n",
      "\t\tAvg Score [100eps]: 445.21 \t Steps: 1000\n",
      "\n",
      "Episode 1660: \tActor Loss: 0.43 \tCritic Loss: 1.00 0\n",
      "\t\tAvg Score [100eps]: 421.48 \t Steps: 1000\n",
      "\n",
      "Episode 1670: \tActor Loss: 0.41 \tCritic Loss: 0.89 0\n",
      "\t\tAvg Score [100eps]: 428.03 \t Steps: 1000\n",
      "\n",
      "Episode 1680: \tActor Loss: 0.41 \tCritic Loss: 0.83 0\n",
      "\t\tAvg Score [100eps]: 387.69 \t Steps: 1000\n",
      "\n",
      "Episode 1690: \tActor Loss: 0.41 \tCritic Loss: 0.76 0\n",
      "\t\tAvg Score [100eps]: 384.20 \t Steps: 1000\n",
      "\n",
      "Episode 1700: \tActor Loss: 0.42 \tCritic Loss: 0.68 0\n",
      "\t\tAvg Score [100eps]: 365.70 \t Steps: 1000\n",
      "\n",
      "Episode 1710: \tActor Loss: 0.41 \tCritic Loss: 0.62 0\n",
      "\t\tAvg Score [100eps]: 350.38 \t Steps: 1000\n",
      "\n",
      "Episode 1720: \tActor Loss: 0.41 \tCritic Loss: 0.58 0\n",
      "\t\tAvg Score [100eps]: 351.52 \t Steps: 1000\n",
      "\n",
      "Episode 1730: \tActor Loss: 0.41 \tCritic Loss: 0.54 0\n",
      "\t\tAvg Score [100eps]: 297.49 \t Steps: 1000\n",
      "\n",
      "Episode 1740: \tActor Loss: 0.41 \tCritic Loss: 0.51 0\n",
      "\t\tAvg Score [100eps]: 299.24 \t Steps: 1000\n",
      "\n",
      "Episode 1750: \tActor Loss: 0.41 \tCritic Loss: 0.49 0\n",
      "\t\tAvg Score [100eps]: 315.73 \t Steps: 1000\n",
      "\n",
      "Episode 1760: \tActor Loss: 0.43 \tCritic Loss: 0.46 0\n",
      "\t\tAvg Score [100eps]: 345.52 \t Steps: 1000\n",
      "\n",
      "Episode 1770: \tActor Loss: 0.40 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 354.54 \t Steps: 1000\n",
      "\n",
      "Episode 1780: \tActor Loss: 0.40 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 339.98 \t Steps: 1000\n",
      "\n",
      "Episode 1790: \tActor Loss: 0.40 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 323.08 \t Steps: 1000\n",
      "\n",
      "Episode 1800: \tActor Loss: 0.39 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 298.57 \t Steps: 1000\n",
      "\n",
      "Episode 1810: \tActor Loss: 0.39 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 316.71 \t Steps: 1000\n",
      "\n",
      "Episode 1820: \tActor Loss: 0.39 \tCritic Loss: 0.44 0\n",
      "\t\tAvg Score [100eps]: 335.96 \t Steps: 1000\n",
      "\n",
      "Episode 1830: \tActor Loss: 0.39 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 308.17 \t Steps: 1000\n",
      "\n",
      "Episode 1840: \tActor Loss: 0.39 \tCritic Loss: 0.45 0\n",
      "\t\tAvg Score [100eps]: 310.87 \t Steps: 1000\n",
      "\n",
      "Episode 1850: \tActor Loss: 0.39 \tCritic Loss: 0.45 1\n",
      "\t\tAvg Score [100eps]: 313.67 \t Steps: 8191\n",
      "\n",
      "Episode 1860: \tActor Loss: 0.36 \tCritic Loss: 0.46 0\n",
      "\t\tAvg Score [100eps]: 311.16 \t Steps: 1000\n",
      "\n",
      "Episode 1870: \tActor Loss: 0.36 \tCritic Loss: 0.47 0\n",
      "\t\tAvg Score [100eps]: 353.48 \t Steps: 1000\n",
      "\n",
      "Episode 1880: \tActor Loss: 0.36 \tCritic Loss: 0.46 0\n",
      "\t\tAvg Score [100eps]: 352.68 \t Steps: 1000\n",
      "\n",
      "Episode 1890: \tActor Loss: 0.36 \tCritic Loss: 0.47 0\n",
      "\t\tAvg Score [100eps]: 373.39 \t Steps: 1000\n",
      "\n",
      "Episode 1900: \tActor Loss: 0.36 \tCritic Loss: 0.48 0\n",
      "\t\tAvg Score [100eps]: 358.76 \t Steps: 1000\n",
      "\n",
      "Episode 1910: \tActor Loss: 0.36 \tCritic Loss: 0.49 0\n",
      "\t\tAvg Score [100eps]: 347.81 \t Steps: 1000\n",
      "\n",
      "Episode 1920: \tActor Loss: 0.36 \tCritic Loss: 0.50 0\n",
      "\t\tAvg Score [100eps]: 353.24 \t Steps: 1000\n",
      "\n",
      "Episode 1930: \tActor Loss: 0.35 \tCritic Loss: 0.51 0\n",
      "\t\tAvg Score [100eps]: 373.26 \t Steps: 1000\n",
      "\n",
      "Episode 1935\t Score [This Eps]: 362.53 \t Steps: 1000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e4f2efe913aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c11e12c69666>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Detach everything to ensure no backprop to these old experiences stored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# Increase starting Learning Rate\n",
    "# Results: \n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 8192       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.lr = 1e-4\n",
    "params.num_steps_collect_data = 8192\n",
    "params.batch_size = 2048\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-11--22:26:13 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.18 87\n",
      "\t\tAvg Score [100eps]: 102.31 \t Steps: 12287\n",
      "\n",
      "Episode 20: \tActor Loss: 0.59 \tCritic Loss: 1.36 87\n",
      "\t\tAvg Score [100eps]: 420.92 \t Steps: 12287\n",
      "\n",
      "Episode 30: \tActor Loss: 0.47 \tCritic Loss: 1.77 87\n",
      "\t\tAvg Score [100eps]: 512.33 \t Steps: 12287\n",
      "\n",
      "Episode 40: \tActor Loss: 0.43 \tCritic Loss: 1.70 87\n",
      "\t\tAvg Score [100eps]: 655.65 \t Steps: 12287\n",
      "\n",
      "Episode 50: \tActor Loss: 0.41 \tCritic Loss: 1.57 87\n",
      "\t\tAvg Score [100eps]: 725.55 \t Steps: 12287\n",
      "\n",
      "Episode 60: \tActor Loss: 0.41 \tCritic Loss: 1.51 87\n",
      "\t\tAvg Score [100eps]: 948.90 \t Steps: 12287\n",
      "\n",
      "Episode 70: \tActor Loss: 0.38 \tCritic Loss: 1.46 87\n",
      "\t\tAvg Score [100eps]: 846.71 \t Steps: 12287\n",
      "\n",
      "Episode 80: \tActor Loss: 0.35 \tCritic Loss: 1.42 287\n",
      "\t\tAvg Score [100eps]: 1037.40 \t Steps: 12287\n",
      "\n",
      "Episode 90: \tActor Loss: 0.32 \tCritic Loss: 1.42 287\n",
      "\t\tAvg Score [100eps]: 1122.43 \t Steps: 12287\n",
      "\n",
      "Episode 100: \tActor Loss: 0.30 \tCritic Loss: 1.42 287\n",
      "\t\tAvg Score [100eps]: 1066.22 \t Steps: 12287\n",
      "\n",
      "Episode 110: \tActor Loss: 0.31 \tCritic Loss: 1.56 287\n",
      "\t\tAvg Score [100eps]: 1132.93 \t Steps: 12287\n",
      "\n",
      "Episode 111\t Score [This Eps]: 1311.03 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 120: \tActor Loss: 0.22 \tCritic Loss: 1.51 287\n",
      "\t\tAvg Score [100eps]: 1368.71 \t Steps: 12287\n",
      "\n",
      "Episode 130: \tActor Loss: 0.22 \tCritic Loss: 1.41 287\n",
      "\t\tAvg Score [100eps]: 1346.84 \t Steps: 12287\n",
      "\n",
      "Episode 140: \tActor Loss: 0.21 \tCritic Loss: 1.46 287\n",
      "\t\tAvg Score [100eps]: 1464.10 \t Steps: 12287\n",
      "\n",
      "Episode 150: \tActor Loss: 0.19 \tCritic Loss: 1.56 287\n",
      "\t\tAvg Score [100eps]: 1493.13 \t Steps: 12287\n",
      "\n",
      "Episode 160: \tActor Loss: 0.15 \tCritic Loss: 1.65 287\n",
      "\t\tAvg Score [100eps]: 1624.50 \t Steps: 12287\n",
      "\n",
      "Episode 170: \tActor Loss: 0.15 \tCritic Loss: 1.76 287\n",
      "\t\tAvg Score [100eps]: 1677.95 \t Steps: 12287\n",
      "\n",
      "Episode 180: \tActor Loss: 0.14 \tCritic Loss: 1.94 287\n",
      "\t\tAvg Score [100eps]: 1617.17 \t Steps: 12287\n",
      "\n",
      "Episode 190: \tActor Loss: 0.14 \tCritic Loss: 2.15 287\n",
      "\t\tAvg Score [100eps]: 1573.41 \t Steps: 12287\n",
      "\n",
      "Episode 200: \tActor Loss: 0.14 \tCritic Loss: 2.43 007\n",
      "\t\tAvg Score [100eps]: 1819.01 \t Steps: 1000\n",
      "\n",
      "Episode 210: \tActor Loss: 0.13 \tCritic Loss: 2.71 007\n",
      "\t\tAvg Score [100eps]: 1822.95 \t Steps: 1000\n",
      "\n",
      "Episode 220: \tActor Loss: 0.13 \tCritic Loss: 2.94 287\n",
      "\t\tAvg Score [100eps]: 1787.70 \t Steps: 12287\n",
      "\n",
      "Episode 230: \tActor Loss: 0.11 \tCritic Loss: 3.21 287\n",
      "\t\tAvg Score [100eps]: 1754.96 \t Steps: 12287\n",
      "\n",
      "Episode 240: \tActor Loss: 0.11 \tCritic Loss: 3.46 007\n",
      "\t\tAvg Score [100eps]: 1857.71 \t Steps: 1000\n",
      "\n",
      "Episode 250: \tActor Loss: 0.10 \tCritic Loss: 3.70 007\n",
      "\t\tAvg Score [100eps]: 1933.37 \t Steps: 1000\n",
      "\n",
      "Episode 260: \tActor Loss: 0.10 \tCritic Loss: 3.96 007\n",
      "\t\tAvg Score [100eps]: 1967.71 \t Steps: 1000\n",
      "\n",
      "Episode 270: \tActor Loss: 0.10 \tCritic Loss: 4.19 287\n",
      "\t\tAvg Score [100eps]: 1957.36 \t Steps: 12287\n",
      "\n",
      "Episode 280: \tActor Loss: 0.10 \tCritic Loss: 4.39 287\n",
      "\t\tAvg Score [100eps]: 1901.34 \t Steps: 12287\n",
      "\n",
      "Episode 290: \tActor Loss: 0.10 \tCritic Loss: 4.48 287\n",
      "\t\tAvg Score [100eps]: 1954.17 \t Steps: 12287\n",
      "\n",
      "Episode 300: \tActor Loss: 0.09 \tCritic Loss: 4.49 287\n",
      "\t\tAvg Score [100eps]: 1993.80 \t Steps: 12287\n",
      "\n",
      "Episode 310: \tActor Loss: 0.09 \tCritic Loss: 4.52 287\n",
      "\t\tAvg Score [100eps]: 1926.24 \t Steps: 12287\n",
      "\n",
      "Episode 320: \tActor Loss: 0.09 \tCritic Loss: 4.58 287\n",
      "\t\tAvg Score [100eps]: 1932.27 \t Steps: 12287\n",
      "\n",
      "Episode 330: \tActor Loss: 0.09 \tCritic Loss: 4.59 287\n",
      "\t\tAvg Score [100eps]: 1969.84 \t Steps: 12287\n",
      "\n",
      "Episode 340: \tActor Loss: 0.09 \tCritic Loss: 4.57 287\n",
      "\t\tAvg Score [100eps]: 2044.46 \t Steps: 12287\n",
      "\n",
      "Episode 350: \tActor Loss: 0.09 \tCritic Loss: 4.57 287\n",
      "\t\tAvg Score [100eps]: 2036.10 \t Steps: 12287\n",
      "\n",
      "Episode 360: \tActor Loss: 0.09 \tCritic Loss: 4.55 007\n",
      "\t\tAvg Score [100eps]: 1983.88 \t Steps: 1000\n",
      "\n",
      "Episode 370: \tActor Loss: 0.09 \tCritic Loss: 4.55 007\n",
      "\t\tAvg Score [100eps]: 2071.88 \t Steps: 1000\n",
      "\n",
      "Episode 380: \tActor Loss: 0.11 \tCritic Loss: 4.54 287\n",
      "\t\tAvg Score [100eps]: 2084.22 \t Steps: 12287\n",
      "\n",
      "Episode 390: \tActor Loss: 0.11 \tCritic Loss: 4.65 287\n",
      "\t\tAvg Score [100eps]: 2101.30 \t Steps: 12287\n",
      "\n",
      "Episode 400: \tActor Loss: 0.11 \tCritic Loss: 4.74 287\n",
      "\t\tAvg Score [100eps]: 2164.83 \t Steps: 12287\n",
      "\n",
      "Episode 410: \tActor Loss: 0.11 \tCritic Loss: 4.78 287\n",
      "\t\tAvg Score [100eps]: 2221.71 \t Steps: 12287\n",
      "\n",
      "Episode 420: \tActor Loss: 0.12 \tCritic Loss: 4.77 007\n",
      "\t\tAvg Score [100eps]: 2198.13 \t Steps: 1000\n",
      "\n",
      "Episode 428\t Score [This Eps]: 2112.87 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 430: \tActor Loss: 0.12 \tCritic Loss: 4.83 287\n",
      "\t\tAvg Score [100eps]: 2133.22 \t Steps: 12287\n",
      "\n",
      "Episode 440: \tActor Loss: 0.12 \tCritic Loss: 4.92 007\n",
      "\t\tAvg Score [100eps]: 2172.82 \t Steps: 1000\n",
      "\n",
      "Episode 450: \tActor Loss: 0.12 \tCritic Loss: 5.10 287\n",
      "\t\tAvg Score [100eps]: 2134.29 \t Steps: 12287\n",
      "\n",
      "Episode 460: \tActor Loss: 0.12 \tCritic Loss: 5.16 287\n",
      "\t\tAvg Score [100eps]: 2237.54 \t Steps: 12287\n",
      "\n",
      "Episode 470: \tActor Loss: 0.12 \tCritic Loss: 5.21 007\n",
      "\t\tAvg Score [100eps]: 2318.53 \t Steps: 1000\n",
      "\n",
      "Episode 480: \tActor Loss: 0.10 \tCritic Loss: 5.24 287\n",
      "\t\tAvg Score [100eps]: 2317.31 \t Steps: 12287\n",
      "\n",
      "Episode 490: \tActor Loss: 0.10 \tCritic Loss: 5.18 007\n",
      "\t\tAvg Score [100eps]: 2322.78 \t Steps: 1000\n",
      "\n",
      "Episode 500: \tActor Loss: 0.11 \tCritic Loss: 5.12 287\n",
      "\t\tAvg Score [100eps]: 2358.08 \t Steps: 12287\n",
      "\n",
      "Episode 509\t Score [This Eps]: 2219.37 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 520: \tActor Loss: 0.11 \tCritic Loss: 5.19 007\n",
      "\t\tAvg Score [100eps]: 2242.54 \t Steps: 1000\n",
      "\n",
      "Episode 530: \tActor Loss: 0.10 \tCritic Loss: 5.25 287\n",
      "\t\tAvg Score [100eps]: 2279.69 \t Steps: 12287\n",
      "\n",
      "Episode 540: \tActor Loss: 0.11 \tCritic Loss: 5.24 287\n",
      "\t\tAvg Score [100eps]: 2363.93 \t Steps: 12287\n",
      "\n",
      "Episode 550: \tActor Loss: 0.11 \tCritic Loss: 5.11 287\n",
      "\t\tAvg Score [100eps]: 2412.86 \t Steps: 12287\n",
      "\n",
      "Episode 560: \tActor Loss: 0.11 \tCritic Loss: 5.12 287\n",
      "\t\tAvg Score [100eps]: 2378.76 \t Steps: 12287\n",
      "\n",
      "Episode 570: \tActor Loss: 0.11 \tCritic Loss: 5.13 287\n",
      "\t\tAvg Score [100eps]: 2491.97 \t Steps: 12287\n",
      "\n",
      "Episode 580: \tActor Loss: 0.11 \tCritic Loss: 5.14 287\n",
      "\t\tAvg Score [100eps]: 2531.71 \t Steps: 12287\n",
      "\n",
      "Episode 590: \tActor Loss: 0.11 \tCritic Loss: 5.19 007\n",
      "\t\tAvg Score [100eps]: 2553.30 \t Steps: 1000\n",
      "\n",
      "Episode 600: \tActor Loss: 0.10 \tCritic Loss: 5.27 287\n",
      "\t\tAvg Score [100eps]: 2506.58 \t Steps: 12287\n",
      "\n",
      "Episode 610: \tActor Loss: 0.10 \tCritic Loss: 5.31 007\n",
      "\t\tAvg Score [100eps]: 2633.06 \t Steps: 1000\n",
      "\n",
      "Episode 620: \tActor Loss: 0.10 \tCritic Loss: 5.32 007\n",
      "\t\tAvg Score [100eps]: 2560.55 \t Steps: 1000\n",
      "\n",
      "Episode 630: \tActor Loss: 0.10 \tCritic Loss: 5.33 287\n",
      "\t\tAvg Score [100eps]: 2567.66 \t Steps: 12287\n",
      "\n",
      "Episode 640: \tActor Loss: 0.10 \tCritic Loss: 5.35 287\n",
      "\t\tAvg Score [100eps]: 2625.93 \t Steps: 12287\n",
      "\n",
      "Episode 650: \tActor Loss: 0.10 \tCritic Loss: 5.41 007\n",
      "\t\tAvg Score [100eps]: 2676.13 \t Steps: 1000\n",
      "\n",
      "Episode 660: \tActor Loss: 0.10 \tCritic Loss: 5.41 287\n",
      "\t\tAvg Score [100eps]: 2686.59 \t Steps: 12287\n",
      "\n",
      "Episode 670: \tActor Loss: 0.11 \tCritic Loss: 5.44 287\n",
      "\t\tAvg Score [100eps]: 2675.33 \t Steps: 12287\n",
      "\n",
      "Episode 680: \tActor Loss: 0.11 \tCritic Loss: 5.43 287\n",
      "\t\tAvg Score [100eps]: 2618.09 \t Steps: 12287\n",
      "\n",
      "Episode 690: \tActor Loss: 0.11 \tCritic Loss: 5.40 007\n",
      "\t\tAvg Score [100eps]: 2667.13 \t Steps: 1000\n",
      "\n",
      "Episode 700: \tActor Loss: 0.11 \tCritic Loss: 5.32 007\n",
      "\t\tAvg Score [100eps]: 2661.62 \t Steps: 1000\n",
      "\n",
      "Episode 710: \tActor Loss: 0.11 \tCritic Loss: 5.28 007\n",
      "\t\tAvg Score [100eps]: 2676.64 \t Steps: 1000\n",
      "\n",
      "Episode 720: \tActor Loss: 0.12 \tCritic Loss: 5.26 007\n",
      "\t\tAvg Score [100eps]: 2793.61 \t Steps: 1000\n",
      "\n",
      "Episode 730: \tActor Loss: 0.12 \tCritic Loss: 5.19 287\n",
      "\t\tAvg Score [100eps]: 2729.29 \t Steps: 12287\n",
      "\n",
      "Episode 740: \tActor Loss: 0.13 \tCritic Loss: 5.13 287\n",
      "\t\tAvg Score [100eps]: 2738.15 \t Steps: 12287\n",
      "\n",
      "Episode 750: \tActor Loss: 0.13 \tCritic Loss: 5.05 287\n",
      "\t\tAvg Score [100eps]: 2693.54 \t Steps: 12287\n",
      "\n",
      "Episode 760: \tActor Loss: 0.13 \tCritic Loss: 5.00 287\n",
      "\t\tAvg Score [100eps]: 2851.90 \t Steps: 12287\n",
      "\n",
      "Episode 770: \tActor Loss: 0.16 \tCritic Loss: 4.96 287\n",
      "\t\tAvg Score [100eps]: 2666.63 \t Steps: 12287\n",
      "\n",
      "Episode 780: \tActor Loss: 0.16 \tCritic Loss: 4.98 007\n",
      "\t\tAvg Score [100eps]: 2825.30 \t Steps: 1000\n",
      "\n",
      "Episode 790: \tActor Loss: 0.17 \tCritic Loss: 5.05 007\n",
      "\t\tAvg Score [100eps]: 2857.29 \t Steps: 1000\n",
      "\n",
      "Episode 800: \tActor Loss: 0.17 \tCritic Loss: 5.14 007\n",
      "\t\tAvg Score [100eps]: 2910.53 \t Steps: 1000\n",
      "\n",
      "Episode 810: \tActor Loss: 0.17 \tCritic Loss: 5.23 287\n",
      "\t\tAvg Score [100eps]: 2875.50 \t Steps: 12287\n",
      "\n",
      "Episode 820: \tActor Loss: 0.16 \tCritic Loss: 5.29 007\n",
      "\t\tAvg Score [100eps]: 2866.52 \t Steps: 1000\n",
      "\n",
      "Episode 830: \tActor Loss: 0.17 \tCritic Loss: 5.37 287\n",
      "\t\tAvg Score [100eps]: 2850.28 \t Steps: 12287\n",
      "\n",
      "Episode 840: \tActor Loss: 0.18 \tCritic Loss: 5.43 287\n",
      "\t\tAvg Score [100eps]: 2710.75 \t Steps: 12287\n",
      "\n",
      "Episode 850: \tActor Loss: 0.18 \tCritic Loss: 5.53 287\n",
      "\t\tAvg Score [100eps]: 2738.90 \t Steps: 12287\n",
      "\n",
      "Episode 860: \tActor Loss: 0.18 \tCritic Loss: 5.59 287\n",
      "\t\tAvg Score [100eps]: 2790.14 \t Steps: 12287\n",
      "\n",
      "Episode 870: \tActor Loss: 0.16 \tCritic Loss: 5.64 287\n",
      "\t\tAvg Score [100eps]: 2835.67 \t Steps: 12287\n",
      "\n",
      "Episode 880: \tActor Loss: 0.16 \tCritic Loss: 5.64 287\n",
      "\t\tAvg Score [100eps]: 2800.58 \t Steps: 12287\n",
      "\n",
      "Episode 890: \tActor Loss: 0.18 \tCritic Loss: 5.78 877\n",
      "\t\tAvg Score [100eps]: 244.43 \t Steps: 12287\n",
      "\n",
      "NaN next_states Found! Skipping this episode.\n",
      "Episode 899\t Score [This Eps]: 195.27 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 902\t Score [This Eps]: 206.16 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 905\t Score [This Eps]: 148.45 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 907\t Score [This Eps]: 193.46 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 910: \tActor Loss: 0.20 \tCritic Loss: 9.78 87\n",
      "\t\tAvg Score [100eps]: 378.77 \t Steps: 12287\n",
      "\n",
      "Episode 917\t Score [This Eps]: 489.11 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "NaN next_states Found! Skipping this episode.\n",
      "Episode 920: \tActor Loss: 0.20 \tCritic Loss: 9.59 87\n",
      "\t\tAvg Score [100eps]: 488.61 \t Steps: 12287\n",
      "\n",
      "Episode 930: \tActor Loss: 0.21 \tCritic Loss: 9.33 87\n",
      "\t\tAvg Score [100eps]: 620.64 \t Steps: 12287\n",
      "\n",
      "Episode 932\t Score [This Eps]: 654.78 \t Steps: 12287"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# Increase starting Learning Rate\n",
    "# Results: \n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 12288       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "params.lr = 1e-4\n",
    "params.num_steps_collect_data = 12288\n",
    "params.batch_size = 2048\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-18--00:48:47 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.05 \tCritic Loss: 0.21 \n",
      "\t\tAvg Score [100eps]: 99.23 \t Steps: 1000\n",
      "\n",
      "Episode 20: \tActor Loss: 0.21 \tCritic Loss: 1.12 87\n",
      "\t\tAvg Score [100eps]: 387.98 \t Steps: 12287\n",
      "\n",
      "Episode 30: \tActor Loss: 0.23 \tCritic Loss: 1.69 87\n",
      "\t\tAvg Score [100eps]: 604.25 \t Steps: 12287\n",
      "\n",
      "Episode 40: \tActor Loss: 0.24 \tCritic Loss: 1.62 87\n",
      "\t\tAvg Score [100eps]: 666.36 \t Steps: 12287\n",
      "\n",
      "Episode 50: \tActor Loss: 0.42 \tCritic Loss: 1.56 87\n",
      "\t\tAvg Score [100eps]: 791.16 \t Steps: 12287\n",
      "\n",
      "Episode 60: \tActor Loss: 0.38 \tCritic Loss: 1.47 87\n",
      "\t\tAvg Score [100eps]: 903.29 \t Steps: 12287\n",
      "\n",
      "Episode 70: \tActor Loss: 0.36 \tCritic Loss: 1.42 287\n",
      "\t\tAvg Score [100eps]: 1011.16 \t Steps: 12287\n",
      "\n",
      "Episode 80: \tActor Loss: 0.34 \tCritic Loss: 1.40 877\n",
      "\t\tAvg Score [100eps]: 975.92 \t Steps: 12287\n",
      "\n",
      "Episode 90: \tActor Loss: 0.32 \tCritic Loss: 1.40 287\n",
      "\t\tAvg Score [100eps]: 1164.74 \t Steps: 12287\n",
      "\n",
      "Episode 100: \tActor Loss: 0.32 \tCritic Loss: 1.40 287\n",
      "\t\tAvg Score [100eps]: 1206.12 \t Steps: 12287\n",
      "\n",
      "Episode 110: \tActor Loss: 0.33 \tCritic Loss: 1.54 287\n",
      "\t\tAvg Score [100eps]: 1245.96 \t Steps: 12287\n",
      "\n",
      "Episode 112\t Score [This Eps]: 1227.33 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 120: \tActor Loss: 0.31 \tCritic Loss: 1.52 287\n",
      "\t\tAvg Score [100eps]: 1327.35 \t Steps: 12287\n",
      "\n",
      "Episode 130: \tActor Loss: 0.30 \tCritic Loss: 1.42 287\n",
      "\t\tAvg Score [100eps]: 1457.81 \t Steps: 12287\n",
      "\n",
      "Episode 138\t Score [This Eps]: 1451.78 \t Steps: 12287NaN next_states Found! Skipping this episode.\n",
      "Episode 140: \tActor Loss: 0.29 \tCritic Loss: 1.48 00\n",
      "\t\tAvg Score [100eps]: 1500.96 \t Steps: 1000\n",
      "\n",
      "Episode 150: \tActor Loss: 0.18 \tCritic Loss: 1.67 007\n",
      "\t\tAvg Score [100eps]: 1617.94 \t Steps: 1000\n",
      "\n",
      "Episode 160: \tActor Loss: 0.17 \tCritic Loss: 1.94 287\n",
      "\t\tAvg Score [100eps]: 1711.99 \t Steps: 12287\n",
      "\n",
      "Episode 170: \tActor Loss: 0.16 \tCritic Loss: 2.23 007\n",
      "\t\tAvg Score [100eps]: 1711.97 \t Steps: 1000\n",
      "\n",
      "Episode 180: \tActor Loss: 0.14 \tCritic Loss: 2.52 287\n",
      "\t\tAvg Score [100eps]: 1755.74 \t Steps: 12287\n",
      "\n",
      "Episode 190: \tActor Loss: 0.13 \tCritic Loss: 2.79 007\n",
      "\t\tAvg Score [100eps]: 1776.24 \t Steps: 1000\n",
      "\n",
      "Episode 200: \tActor Loss: 0.11 \tCritic Loss: 3.07 287\n",
      "\t\tAvg Score [100eps]: 1780.76 \t Steps: 12287\n",
      "\n",
      "Episode 210: \tActor Loss: 0.10 \tCritic Loss: 3.41 007\n",
      "\t\tAvg Score [100eps]: 1853.26 \t Steps: 1000\n",
      "\n",
      "Episode 220: \tActor Loss: 0.10 \tCritic Loss: 3.74 287\n",
      "\t\tAvg Score [100eps]: 1880.13 \t Steps: 12287\n",
      "\n",
      "Episode 230: \tActor Loss: 0.09 \tCritic Loss: 4.06 007\n",
      "\t\tAvg Score [100eps]: 1907.40 \t Steps: 1000\n",
      "\n",
      "Episode 240: \tActor Loss: 0.09 \tCritic Loss: 4.34 287\n",
      "\t\tAvg Score [100eps]: 1810.29 \t Steps: 12287\n",
      "\n",
      "Episode 250: \tActor Loss: 0.09 \tCritic Loss: 4.52 287\n",
      "\t\tAvg Score [100eps]: 1848.55 \t Steps: 12287\n",
      "\n",
      "Episode 260: \tActor Loss: 0.08 \tCritic Loss: 4.62 287\n",
      "\t\tAvg Score [100eps]: 1965.52 \t Steps: 12287\n",
      "\n",
      "Episode 270: \tActor Loss: 0.09 \tCritic Loss: 4.74 287\n",
      "\t\tAvg Score [100eps]: 1953.03 \t Steps: 12287\n",
      "\n",
      "Episode 280: \tActor Loss: 0.09 \tCritic Loss: 4.91 287\n",
      "\t\tAvg Score [100eps]: 2016.58 \t Steps: 12287\n",
      "\n",
      "Episode 290: \tActor Loss: 0.09 \tCritic Loss: 5.10 007\n",
      "\t\tAvg Score [100eps]: 2070.86 \t Steps: 1000\n",
      "\n",
      "Episode 300: \tActor Loss: 0.09 \tCritic Loss: 5.24 287\n",
      "\t\tAvg Score [100eps]: 2055.54 \t Steps: 12287\n",
      "\n",
      "Episode 310: \tActor Loss: 0.09 \tCritic Loss: 5.36 287\n",
      "\t\tAvg Score [100eps]: 2266.38 \t Steps: 12287\n",
      "\n",
      "Episode 320: \tActor Loss: 0.08 \tCritic Loss: 5.47 287\n",
      "\t\tAvg Score [100eps]: 2281.57 \t Steps: 12287\n",
      "\n",
      "Episode 330: \tActor Loss: 0.08 \tCritic Loss: 5.64 007\n",
      "\t\tAvg Score [100eps]: 2355.22 \t Steps: 1000\n",
      "\n",
      "Episode 340: \tActor Loss: 0.08 \tCritic Loss: 5.76 007\n",
      "\t\tAvg Score [100eps]: 2316.21 \t Steps: 1000\n",
      "\n",
      "Episode 350: \tActor Loss: 0.07 \tCritic Loss: 5.94 287\n",
      "\t\tAvg Score [100eps]: 2404.91 \t Steps: 12287\n",
      "\n",
      "Episode 360: \tActor Loss: 0.07 \tCritic Loss: 6.10 287\n",
      "\t\tAvg Score [100eps]: 2460.84 \t Steps: 12287\n",
      "\n",
      "Episode 370: \tActor Loss: 0.07 \tCritic Loss: 6.25 287\n",
      "\t\tAvg Score [100eps]: 2479.82 \t Steps: 12287\n",
      "\n",
      "Episode 380: \tActor Loss: 0.10 \tCritic Loss: 6.34 287\n",
      "\t\tAvg Score [100eps]: 2511.55 \t Steps: 12287\n",
      "\n",
      "\n",
      "Environment solved in 380 episodes!\tAverage Score: 2511.55\n",
      "=====  =====\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAINING DURATION: 0 days, 10 hours, 37 minutes and 28 seconds\n",
      "***TRAINING STOPPED AT 2022-05-18--11:26:15 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.228633048500487,\n",
       " 18.2400571974312,\n",
       " 24.426406205771926,\n",
       " 32.114061766864396,\n",
       " 33.867889540622784,\n",
       " 47.08185033435089,\n",
       " 54.167440284388725,\n",
       " 77.18986785085536,\n",
       " 92.22983648030315,\n",
       " 99.22707708837866,\n",
       " 125.40842171340584,\n",
       " 156.54453393317206,\n",
       " 207.45800414092315,\n",
       " 259.7891941688425,\n",
       " 295.39381791518247,\n",
       " 305.8545136635646,\n",
       " 314.5883460867545,\n",
       " 361.2121475716651,\n",
       " 357.89009277331354,\n",
       " 387.97947297153473,\n",
       " 413.6871236642619,\n",
       " 456.59463547520454,\n",
       " 442.6844489344547,\n",
       " 489.6083101134561,\n",
       " 464.2861266209092,\n",
       " 482.30296573986067,\n",
       " 532.6328981057089,\n",
       " 559.0751754086122,\n",
       " 584.4922287626797,\n",
       " 604.2494776579458,\n",
       " 607.4389519320265,\n",
       " 644.4733045543428,\n",
       " 638.763207841852,\n",
       " 651.3402172196679,\n",
       " 652.0868699570746,\n",
       " 701.6065872943705,\n",
       " 652.0409366027952,\n",
       " 634.8897413625405,\n",
       " 666.2061302200658,\n",
       " 666.3577879690519,\n",
       " 677.4928146288544,\n",
       " 693.936379568025,\n",
       " 747.6300698652351,\n",
       " 713.4604572404464,\n",
       " 748.1226031283196,\n",
       " 810.0025660614785,\n",
       " 798.8040839688213,\n",
       " 834.6446635873941,\n",
       " 810.9427482020761,\n",
       " 791.1580052096956,\n",
       " 839.1510038139298,\n",
       " 899.3676615241112,\n",
       " 858.3767466101236,\n",
       " 901.7162096593343,\n",
       " 908.8911379248789,\n",
       " 853.0711043333076,\n",
       " 816.0357208924298,\n",
       " 888.6448356741062,\n",
       " 908.6777064590389,\n",
       " 903.2865352040949,\n",
       " 838.5091553831427,\n",
       " 899.9060046438873,\n",
       " 857.2823024633806,\n",
       " 925.658266314147,\n",
       " 898.3101211241353,\n",
       " 897.5723055160081,\n",
       " 863.5534995814343,\n",
       " 883.2782005147985,\n",
       " 960.9471410131222,\n",
       " 1011.1571040207846,\n",
       " 1013.1436691697547,\n",
       " 1038.2255761755118,\n",
       " 1005.8053072812711,\n",
       " 993.7238483159174,\n",
       " 1034.2584986741165,\n",
       " 979.1306011563261,\n",
       " 993.1881148038793,\n",
       " 1026.109597970717,\n",
       " 1060.681900047562,\n",
       " 975.922915552415,\n",
       " 979.1623660641536,\n",
       " 1021.4660717618104,\n",
       " 1067.166012124957,\n",
       " 1092.9318154144123,\n",
       " 1046.675300021083,\n",
       " 1074.0975093496288,\n",
       " 1089.5016902616806,\n",
       " 1109.3501852269144,\n",
       " 1144.2687057816238,\n",
       " 1164.737725497919,\n",
       " 1132.4873883803584,\n",
       " 1091.195157835742,\n",
       " 1133.0377916441066,\n",
       " 1208.3534805194556,\n",
       " 1247.289379821429,\n",
       " 1139.4310317622032,\n",
       " 1144.8170947804394,\n",
       " 1120.892786014867,\n",
       " 1171.4018486516213,\n",
       " 1206.11794689978,\n",
       " 1103.1503155239857,\n",
       " 1126.6881213642982,\n",
       " 1191.8378350556245,\n",
       " 1166.3589686350035,\n",
       " 1220.3394408103218,\n",
       " 1192.808359958646,\n",
       " 1227.5250391054328,\n",
       " 1180.2712511795432,\n",
       " 1198.959281867626,\n",
       " 1245.9587275795172,\n",
       " 1315.0697923921327,\n",
       " 1227.3281314976002,\n",
       " 1295.71571126458,\n",
       " 1298.5597538312757,\n",
       " 1285.9406544365106,\n",
       " 1300.305484697651,\n",
       " 1317.633532966529,\n",
       " 1297.4027612372256,\n",
       " 1327.3534782000863,\n",
       " 1312.9803848699387,\n",
       " 1346.8692365932138,\n",
       " 1396.988475525682,\n",
       " 1394.8600255593867,\n",
       " 1422.8092669556522,\n",
       " 1292.4009609115053,\n",
       " 1331.0962521219276,\n",
       " 1293.9320014841546,\n",
       " 1313.5024005570938,\n",
       " 1457.8109937008423,\n",
       " 1352.2803409548221,\n",
       " 1392.918389013752,\n",
       " 1414.4367242870574,\n",
       " 1457.662156406577,\n",
       " 1407.8186139089476,\n",
       " 1574.0479719812329,\n",
       " 1499.4228173744166,\n",
       " 1451.784956399994,\n",
       " 1500.9598920202698,\n",
       " 1496.1958583596838,\n",
       " 1548.3627980507165,\n",
       " 1444.127403471095,\n",
       " 1581.1458472924423,\n",
       " 1523.5778759777675,\n",
       " 1550.746111523878,\n",
       " 1485.6819974008529,\n",
       " 1586.8128602945735,\n",
       " 1618.5936973250612,\n",
       " 1617.9360006627114,\n",
       " 1622.1004237415782,\n",
       " 1597.851724299509,\n",
       " 1678.1087633120246,\n",
       " 1705.6414038352855,\n",
       " 1702.386831310615,\n",
       " 1620.2978483121085,\n",
       " 1615.907239380381,\n",
       " 1616.789496607955,\n",
       " 1647.208970122952,\n",
       " 1711.9871243715659,\n",
       " 1712.0694346159837,\n",
       " 1722.577842042317,\n",
       " 1736.1442598527542,\n",
       " 1707.7085225741705,\n",
       " 1728.5562157440559,\n",
       " 1742.308853961574,\n",
       " 1684.2506146314774,\n",
       " 1687.4152677978332,\n",
       " 1707.4403223598085,\n",
       " 1711.9666136242763,\n",
       " 1717.9164908360865,\n",
       " 1709.4865316232201,\n",
       " 1735.8108327029972,\n",
       " 1737.6151660396997,\n",
       " 1754.6133565445164,\n",
       " 1773.0731661560153,\n",
       " 1778.682156972217,\n",
       " 1776.910351911334,\n",
       " 1787.296138612576,\n",
       " 1755.743767361939,\n",
       " 1721.2500719397012,\n",
       " 1767.133815374407,\n",
       " 1826.1419130315119,\n",
       " 1806.1881696087307,\n",
       " 1805.2575106646725,\n",
       " 1811.6254613627773,\n",
       " 1779.9274094321706,\n",
       " 1772.21436881367,\n",
       " 1779.0521605210658,\n",
       " 1776.2394486160856,\n",
       " 1803.3348977850937,\n",
       " 1810.028609700133,\n",
       " 1785.3206520389695,\n",
       " 1785.6113698973204,\n",
       " 1798.797284911978,\n",
       " 1762.2934157444513,\n",
       " 1733.3180732393196,\n",
       " 1766.9441199672735,\n",
       " 1730.6664104893152,\n",
       " 1780.762341562634,\n",
       " 1787.8163022583303,\n",
       " 1802.1872820262872,\n",
       " 1767.0800071310346,\n",
       " 1777.3853163088672,\n",
       " 1788.1463444849617,\n",
       " 1887.191440299116,\n",
       " 1889.5865837170359,\n",
       " 1819.2937254876701,\n",
       " 1846.4694778265477,\n",
       " 1853.263225102853,\n",
       " 1862.8673680733004,\n",
       " 1866.8123694551177,\n",
       " 1888.120525447335,\n",
       " 1892.497676416291,\n",
       " 1891.5610810505877,\n",
       " 1862.5423761267098,\n",
       " 1890.871049959045,\n",
       " 1915.667036075024,\n",
       " 1896.5497384184534,\n",
       " 1880.1308729448472,\n",
       " 1886.0087716857017,\n",
       " 1898.6309702592157,\n",
       " 1845.4491654047783,\n",
       " 1863.3439797304798,\n",
       " 1942.1694253728865,\n",
       " 1918.2533787490568,\n",
       " 1944.4646950255194,\n",
       " 1885.2229119099397,\n",
       " 1878.18681517025,\n",
       " 1907.398441697075,\n",
       " 1852.3889875410077,\n",
       " 1904.6900554741871,\n",
       " 1890.224891685671,\n",
       " 1905.640445209397,\n",
       " 1949.3897336181021,\n",
       " 1845.026416757838,\n",
       " 1868.3698323164601,\n",
       " 1885.4985487391846,\n",
       " 1833.9915030175773,\n",
       " 1810.2899115034518,\n",
       " 1886.7931603785325,\n",
       " 1913.4368980965764,\n",
       " 1877.8154410689137,\n",
       " 1940.4435487853502,\n",
       " 1873.4291974648554,\n",
       " 1812.0537159183993,\n",
       " 1888.1938520265883,\n",
       " 1909.3760409896402,\n",
       " 1933.8399635977437,\n",
       " 1848.5539607093972,\n",
       " 1925.2316434511124,\n",
       " 1947.550480206418,\n",
       " 1910.3852198995323,\n",
       " 1945.7297509140196,\n",
       " 1961.037926830789,\n",
       " 1908.3379551410326,\n",
       " 1945.359163646819,\n",
       " 1950.7320785023971,\n",
       " 1964.1585267304863,\n",
       " 1965.5214407844917,\n",
       " 1972.1629560737108,\n",
       " 1897.5081676480615,\n",
       " 1887.116466674488,\n",
       " 1857.1275922330283,\n",
       " 1948.1584639607813,\n",
       " 1870.845584698224,\n",
       " 1868.7830945502408,\n",
       " 1966.9075659257965,\n",
       " 1924.6984876257786,\n",
       " 1953.0336343233148,\n",
       " 2005.174317764407,\n",
       " 2038.0897939519723,\n",
       " 2043.3775322990864,\n",
       " 2068.7064646021554,\n",
       " 2069.0816130137955,\n",
       " 2090.3490617015214,\n",
       " 2058.7769020978176,\n",
       " 2015.8783696054086,\n",
       " 2048.518208361957,\n",
       " 2016.5813216493325,\n",
       " 2010.7536479641847,\n",
       " 2023.9395493677025,\n",
       " 2014.3352156460658,\n",
       " 1924.2297837230494,\n",
       " 2027.027199352137,\n",
       " 2036.5175532879168,\n",
       " 2033.8983328560855,\n",
       " 2104.9389590902465,\n",
       " 2026.0852011763748,\n",
       " 2070.8619476118474,\n",
       " 2127.6467462959445,\n",
       " 2122.177345440062,\n",
       " 2093.7413823512175,\n",
       " 2121.5406957061773,\n",
       " 2023.4768629897433,\n",
       " 2038.0325410084217,\n",
       " 2109.5563320645783,\n",
       " 2126.773051354932,\n",
       " 2156.0505365356594,\n",
       " 2055.5402302838,\n",
       " 2119.294771578051,\n",
       " 2100.814010170787,\n",
       " 2115.2718135150894,\n",
       " 2081.2690427577636,\n",
       " 2121.5469781783877,\n",
       " 2176.6822191989004,\n",
       " 2218.228341610143,\n",
       " 2208.8328793616965,\n",
       " 2177.847353358455,\n",
       " 2266.3782188791038,\n",
       " 2182.250062245936,\n",
       " 2208.5267106401175,\n",
       " 2237.1688812167267,\n",
       " 2258.4092102160957,\n",
       " 2179.7369723948464,\n",
       " 2221.4550300797914,\n",
       " 2339.154179669069,\n",
       " 2331.325797587526,\n",
       " 2325.0529390771735,\n",
       " 2281.5660612596594,\n",
       " 2281.22795279423,\n",
       " 2274.407966887739,\n",
       " 2242.360340272654,\n",
       " 2288.157864157432,\n",
       " 2269.566438192206,\n",
       " 2300.4641775306895,\n",
       " 2310.4682724212457,\n",
       " 2333.6467233396065,\n",
       " 2337.077786166121,\n",
       " 2355.2198425550223,\n",
       " 2341.19470394732,\n",
       " 2343.7612184391496,\n",
       " 2195.097286301092,\n",
       " 2157.7614045734936,\n",
       " 2312.9933134142425,\n",
       " 2307.677580182266,\n",
       " 2310.2807288127883,\n",
       " 2370.548544306547,\n",
       " 2314.074122528529,\n",
       " 2316.20936130977,\n",
       " 2335.1776385692206,\n",
       " 2367.552193319281,\n",
       " 2374.7087131965486,\n",
       " 2391.3223392655095,\n",
       " 2400.603824431258,\n",
       " 2420.542700011558,\n",
       " 2426.4948070358437,\n",
       " 2438.220763848955,\n",
       " 2375.025378590287,\n",
       " 2404.912974692043,\n",
       " 2404.161935286601,\n",
       " 2411.377251175805,\n",
       " 2455.1325711741833,\n",
       " 2452.4003203109164,\n",
       " 2446.373807603973,\n",
       " 2464.9058299050666,\n",
       " 2467.6764817746775,\n",
       " 2428.0396927704755,\n",
       " 2448.409207779933,\n",
       " 2460.8409059329388,\n",
       " 2335.2922923299157,\n",
       " 2385.055145223369,\n",
       " 2404.143539079847,\n",
       " 2384.4352821241414,\n",
       " 2386.286999072405,\n",
       " 2391.528459462626,\n",
       " 2450.860064810747,\n",
       " 2448.68454601733,\n",
       " 2506.7497942365985,\n",
       " 2479.8203934375288,\n",
       " 2462.794845099533,\n",
       " 2425.679967752723,\n",
       " 2478.8460348835447,\n",
       " 2478.7182511690353,\n",
       " 2476.3132773742823,\n",
       " 2495.9318461216008,\n",
       " 2483.2778350560648,\n",
       " 2510.185154243661,\n",
       " 2465.6448041100193,\n",
       " 2511.5522065722707]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# Increase starting Learning Rate\n",
    "# Results: \n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=1500\n",
    "params.max_t = 12288       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 5\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = True\n",
    "params.target_score = 2500.0\n",
    "params.plot_stats = True                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/final_alt'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/final_alt'\n",
    "params.lr = 1e-4\n",
    "params.num_steps_collect_data = 12288\n",
    "params.batch_size = 2048\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  1\n",
      "BATCH_SIZE:  2048\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.999\n",
      "BETA_MIN:  0.001\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.9975\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.95\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "Mean Score: 2515.952315195605\n",
      "Max Score: 3085.1343869902194\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "params = Params()\n",
    "logger = Logger(params)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "agent.ppo_ac_net.actor.load_state_dict(torch.load('weights/saved/checkpoint_actor_ep770.pth'))\n",
    "agent.ppo_ac_net.critic.load_state_dict(torch.load('weights/saved/checkpoint_critic_ep770.pth'))\n",
    "max_t = 3000\n",
    "score = np.zeros(len(env_info.agents))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "states = env_info.vector_observations                # get the current state\n",
    "score = 0                                              # initialize the score\n",
    "for i in range(max_t):\n",
    "    # Perform actions from each agent's policy network (clipped actions [0, -1])\n",
    "    actions, _, _, _ = agent.act(states, std_scale=1e-8) \n",
    "    env_info = env.step(actions)[brain_name]         # send the action to the environment \n",
    "    next_states = env_info.vector_observations       # get the next state\n",
    "    rewards = env_info.rewards                       # get the reward\n",
    "    dones = env_info.local_done                      # see if episode has finished\n",
    "    states = next_states                             # roll over the state to next time step\n",
    "    \n",
    "    # update the score\n",
    "    states = next_states\n",
    "    score += np.array(rewards)             \n",
    "    for i in range(len(dones)):\n",
    "        if dones[i]:\n",
    "            logger.log_score(score[i])\n",
    "            score[i] = 0\n",
    "    \n",
    "    # exit loop if episode finished (NOTE: Agents auto-restart upon done)\n",
    "    #if all(dones):                                   \n",
    "    #    break\n",
    "    \n",
    "print(\"Mean Score: {}\".format(np.nanmean(logger.scores_deque)))\n",
    "print(\"Max Score: {}\".format(np.max(logger.scores_deque)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd_gpu",
   "language": "python",
   "name": "drlnd_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
