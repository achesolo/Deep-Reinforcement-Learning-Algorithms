{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'scripts/')  # TODO: insert at 1, 0 is the script path (or '' in REPL)\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import shutil\n",
    "import os\n",
    "import pprint \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ppo_agent import PPO_Agent\n",
    "from params import Params\n",
    "from logger import Logger\n",
    "from CustomSummaryWriter import CustomSummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time related Utilities\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def get_time(format):\n",
    "    utc_now = pytz.utc.localize(datetime.utcnow())\n",
    "    pst_now = utc_now.astimezone(pytz.timezone(\"Asia/Singapore\"))   # Set to your own timezone: pytz.all_timezones\n",
    "    return pst_now.strftime(format)\n",
    "\n",
    "def total_train_duration(start_time, end_time):\n",
    "    duration = end_time - start_time              # For build-in functions\n",
    "    duration_in_s = duration.total_seconds()      # Total number of seconds between dates\n",
    "    days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)\n",
    "    hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours\n",
    "    minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes\n",
    "    seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds\n",
    "    print(\"TOTAL TRAINING DURATION: %d days, %d hours, %d minutes and %d seconds\" % (days[0], hours[0], minutes[0], seconds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARN: SLOWS DOWN TRAINING ALOT..\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe', worker_id=101)\n",
    "# env = UnityEnvironment(file_name='Crawler_Windows_x86_64/Crawler.exe', no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n",
      "Size of each action: 20\n",
      "There are 12 agents. Each observes a state with length: 129\n",
      "The state for the first agent looks like: [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.25000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  1.78813934e-07  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093168e-01 -1.42857209e-01 -6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339906e+00 -1.42857209e-01\n",
      " -1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093347e-01 -1.42857209e-01 -6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339953e+00 -1.42857209e-01\n",
      " -1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.06093168e-01 -1.42857209e-01  6.06078804e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.33339906e+00 -1.42857209e-01\n",
      "  1.33341408e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.06093347e-01 -1.42857209e-01  6.06078625e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.33339953e+00 -1.42857209e-01\n",
      "  1.33341372e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "# states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "# scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "# while True:\n",
    "#     actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#     actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#     next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#     rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     dones = env_info.local_done                        # see if episode finished\n",
    "#     scores += env_info.rewards                         # update the score (for each agent)\n",
    "#     states = next_states                               # roll over states to next time step\n",
    "#     if np.any(dones):                                  # exit loop if episode finished\n",
    "#         break\n",
    "# print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "\n",
    "While training is taking place, statistics on agent performance are available from Tensorboard. To launch it use:\n",
    "```python\n",
    "cd <PROJECT_DIR>\n",
    "tensorboard --logdir=runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  1\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ppo(params=Params(), logger=Logger()):\n",
    "\n",
    "    print (\"***STARTED TRAINING AT {} \\n\".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "    start_time  = datetime.now() \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    action_size = brain.vector_action_space_size\n",
    "    state_size = env_info.vector_observations.shape[1]\n",
    "    logger.initialize(agent, state_size, action_size)\n",
    "    \n",
    "#     try:\n",
    "    start_eps = params.eps_to_resume_from if not params.restart_training else 1        \n",
    "    for i_episode in range(start_eps, params.n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "        states = env_info.vector_observations              # get the current state\n",
    "        score = np.zeros(len(env_info.agents))\n",
    "        hasNaN = False\n",
    "\n",
    "        for t in range(params.max_t):                             \n",
    "\n",
    "            # REPORT NAN STATES\n",
    "            if np.isnan(states).any():\n",
    "                print('\\nNaN found in states. Skipping this episode.')\n",
    "                hasNaN = True\n",
    "                break\n",
    "\n",
    "            # Perform actions from each agent's policy network (clipped actions [0, -1])  \n",
    "            actions, log_probs, _, values = agent.act(states, agent.std_scale)\n",
    "            env_info = env.step(actions)[brain_name]      \n",
    "            next_states, rewards, dones = env_info.vector_observations, env_info.rewards, env_info.local_done\n",
    "\n",
    "            # REPORT NAN ACTIONS\n",
    "            if np.isnan(next_states).any():\n",
    "                print(\"NaN next_states Found! Skipping this episode.\")\n",
    "                hasNaN = True\n",
    "                break\n",
    "                \n",
    "            if np.isnan(actions).any():\n",
    "                print('NaN found in actions. Skipping this episode.')\n",
    "                hasNaN = True\n",
    "                break\n",
    "\n",
    "            if np.isnan(rewards).any():\n",
    "                print(\"NaN Reward Found! Skipping this episode.\")\n",
    "                hasNaN = True\n",
    "                break\n",
    "\n",
    "            # Only collect and learn from subset of data from episode (representative enough)\n",
    "            if t < params.num_steps_collect_data:\n",
    "                agent.step(states, actions, rewards, log_probs, values, dones)\n",
    "                last_states = next_states\n",
    "                \n",
    "            # Allow crawler to keep resetting if fall (score -> 0)\n",
    "            # Continue to accumulate score over entire duration max_t to maxmimize observable score\n",
    "            states = next_states\n",
    "            score += np.array(rewards)             \n",
    "            for i in range(len(dones)):\n",
    "                if dones[i]:\n",
    "                    logger.log_score(score[i])\n",
    "                    score[i] = 0\n",
    "            \n",
    "            # Break if all agents are done (auto @ step=1000)\n",
    "            if all(dones):   # any()\n",
    "                break \n",
    "            \n",
    "        if not hasNaN:\n",
    "            # Learn from episode (add last state if using GAE)\n",
    "            agent.add_last_state(last_states)\n",
    "            agent.learn()\n",
    "\n",
    "            # Print crucial results for progress tracking\n",
    "            logger.log_stats(i_episode, agent.actor_loss, agent.critic_loss, agent.entropy_loss)\n",
    "            print('\\rEpisode {}\\t Score [This Eps]: {:.2f} \\t Steps: {}'.format(i_episode, logger.scores_list[-1], t), end=\"\")\n",
    "\n",
    "            if i_episode % params.save_every == 0:\n",
    "                logger.save_weights(i_episode)\n",
    "\n",
    "            if i_episode % params.print_every == 0:\n",
    "                print('\\rEpisode {}: \\tActor Loss: {:.2f} \\tCritic Loss: {:.2f} \\n\\t\\tAvg Score [100eps]: {:.2f} \\t Steps: {}\\n'\n",
    "                      .format(i_episode, np.mean(logger.actor_loss_deque), np.mean(logger.critic_loss_deque), np.mean(logger.scores_deque), t))\n",
    "\n",
    "                if np.mean(logger.scores_deque) >= params.target_score:\n",
    "                    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'\n",
    "                          .format(i_episode, np.mean(logger.scores_deque)))\n",
    "                    if params.terminate_on_target_score:\n",
    "                        break\n",
    "\n",
    "    # Plot graphs & save final weights\n",
    "    logger.save_weights(i_episode)\n",
    "    if params.plot_stats:\n",
    "        logger.plot_stats()\n",
    "    logger.log_overall_perf_tb()\n",
    "    total_train_duration(start_time=start_time, end_time=datetime.now())\n",
    "    print (\"***TRAINING STOPPED AT {} \".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "\n",
    "#     # Catch any exceptions (Esp with keyboard interrupts)\n",
    "#     except BaseException as error:\n",
    "#         print('\\n\\n==== An exception occurred: {}'.format(error))\n",
    "#         #logger.print_weights()\n",
    "#         logger.save_weights(i_episode)\n",
    "#         if params.plot_stats:\n",
    "#             logger.plot_stats()\n",
    "#         logger.log_overall_perf_tb()\n",
    "#         total_train_duration(start_time=start_time, end_time=datetime.now())\n",
    "#         print (\"***TRAINING STOPPED AT {} \".format(get_time('%Y-%m-%d--%H:%M:%S')))\n",
    "    \n",
    "    return logger.scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--13:59:41 \n",
      "\n",
      "9.95e-05\n",
      "\r",
      "Episode 1\t Score [This Eps]: 0.96 \t Steps: 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scripts\\logger.py:63: RuntimeWarning: Mean of empty slice\n",
      "  self.critic_loss_list.append(critic_loss)\n",
      "scripts\\logger.py:69: RuntimeWarning: Mean of empty slice\n",
      "  self.tb.add_scalar(f\"{self.agent_ns}/Critic Loss\", critic_loss, episode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.90025e-05\n",
      "Episode 2: \tActor Loss: 0.08 \tCritic Loss: 0.12 \n",
      "\t\tRunning Avg Score [100eps]: nan \t Steps: 20\n",
      "\n",
      "9.85074875e-05\n",
      "Episode 3\t Score [This Eps]: 1.03 \t Steps: 209.80149500625e-05\n",
      "Episode 4: \tActor Loss: 0.09 \tCritic Loss: 0.13 \n",
      "\t\tRunning Avg Score [100eps]: nan \t Steps: 20\n",
      "\n",
      "9.75248753121875e-05\n",
      "Episode 5\t Score [This Eps]: 1.00 \t Steps: 209.703725093562657e-05\n",
      "Episode 6: \tActor Loss: 0.10 \tCritic Loss: 0.12 \n",
      "\t\tRunning Avg Score [100eps]: nan \t Steps: 20\n",
      "\n",
      "9.655206468094843e-05\n",
      "Episode 7\t Score [This Eps]: 0.88 \t Steps: 209.606930435754369e-05\n",
      "Episode 8: \tActor Loss: 0.12 \tCritic Loss: 0.11 \n",
      "\t\tRunning Avg Score [100eps]: nan \t Steps: 20\n",
      "\n",
      "9.558895783575598e-05\n",
      "Episode 9\t Score [This Eps]: 0.81 \t Steps: 209.51110130465772e-05\n",
      "Episode 10: \tActor Loss: 0.12 \tCritic Loss: 0.10 \n",
      "\t\tRunning Avg Score [100eps]: nan \t Steps: 20\n",
      "\n",
      "=====  =====\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAINING DURATION: 0 days, 0 hours, 0 minutes and 1 seconds\n",
      "***TRAINING STOPPED AT 2022-05-03--13:59:43 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\derek\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# QUICK TEST\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10\n",
    "params.max_t = 20\n",
    "params.print_every = 2\n",
    "params.save_every = 2\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "logger = Logger(params)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graph(logger):\n",
    "    \n",
    "    score_arr  = np.array(logger.scores_list)\n",
    "    score_arr[score_arr < 0] = 0\n",
    "    _, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    # Scores\n",
    "    axs[0].plot(np.arange(1, len(logger.scores_list)+1), score_arr)\n",
    "    axs[0].set(xlabel='Episode #', ylabel='Score')\n",
    "    axs[0].set_title('Rewards')\n",
    "        \n",
    "    # Actor Loss\n",
    "    axs[1].plot(np.arange(1, len(logger.actor_loss_list)+1), logger.actor_loss_list)\n",
    "    axs[1].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[1].set_title('Actor Loss')\n",
    "    \n",
    "    # Critic Loss\n",
    "    axs[2].plot(np.arange(1, len(logger.critic_loss_list)+1), logger.critic_loss_list)\n",
    "    axs[2].set(xlabel='Episode #', ylabel='Loss')\n",
    "    axs[2].set_title('Critic Loss')\n",
    "    plt.show()\n",
    "    \n",
    "plot_graph(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "LR (Joint):  0.0001\n",
      "GAMMA:  0.95\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-04-17--19:14:46 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.69 \n",
      "\t\tAverage Score: 45.22\n",
      "\n",
      "Episode 20: \tActor Loss: 0.04 \tCritic Loss: 0.82 \n",
      "\t\tAverage Score: 56.29\n",
      "\n",
      "Episode 30: \tActor Loss: 0.31 \tCritic Loss: 3.38 \n",
      "\t\tAverage Score: 117.90\n",
      "\n",
      "Episode 40: \tActor Loss: 0.30 \tCritic Loss: 15.91 \n",
      "\t\tAverage Score: 285.59\n",
      "\n",
      "Episode 50: \tActor Loss: 0.27 \tCritic Loss: 25.89 \n",
      "\t\tAverage Score: 368.85\n",
      "\n",
      "Episode 60: \tActor Loss: 0.48 \tCritic Loss: 40.11 \n",
      "\t\tAverage Score: 421.72\n",
      "\n",
      "Episode 70: \tActor Loss: 0.36 \tCritic Loss: 29.64 \n",
      "\t\tAverage Score: 400.96\n",
      "\n",
      "Episode 80: \tActor Loss: 0.24 \tCritic Loss: 19.94 \n",
      "\t\tAverage Score: 406.81\n",
      "\n",
      "Episode 90: \tActor Loss: 0.27 \tCritic Loss: 26.22 \n",
      "\t\tAverage Score: 398.77\n",
      "\n",
      "Episode 100: \tActor Loss: 0.29 \tCritic Loss: 12.70 \n",
      "\t\tAverage Score: 296.49\n",
      "\n",
      "Episode 110: \tActor Loss: 0.31 \tCritic Loss: 53.75 \n",
      "\t\tAverage Score: 595.12\n",
      "\n",
      "Episode 120: \tActor Loss: 0.13 \tCritic Loss: 45.11 \n",
      "\t\tAverage Score: 585.65\n",
      "\n",
      "Episode 130: \tActor Loss: 0.10 \tCritic Loss: 35.13 \n",
      "\t\tAverage Score: 567.49\n",
      "\n",
      "Episode 140: \tActor Loss: 0.16 \tCritic Loss: 33.70 \n",
      "\t\tAverage Score: 596.77\n",
      "\n",
      "Episode 150: \tActor Loss: 0.23 \tCritic Loss: 23.72 \n",
      "\t\tAverage Score: 563.54\n",
      "\n",
      "Episode 160: \tActor Loss: 0.25 \tCritic Loss: 22.06 \n",
      "\t\tAverage Score: 518.78\n",
      "\n",
      "Episode 170: \tActor Loss: 0.16 \tCritic Loss: 18.35 \n",
      "\t\tAverage Score: 625.29\n",
      "\n",
      "Episode 180: \tActor Loss: 0.10 \tCritic Loss: 12.38 \n",
      "\t\tAverage Score: 635.01\n",
      "\n",
      "Episode 190: \tActor Loss: 0.13 \tCritic Loss: 8.61 \n",
      "\t\tAverage Score: 616.16\n",
      "\n",
      "Episode 200: \tActor Loss: 0.20 \tCritic Loss: 13.48 \n",
      "\t\tAverage Score: 589.00\n",
      "\n",
      "Episode 210: \tActor Loss: 0.19 \tCritic Loss: 16.07 \n",
      "\t\tAverage Score: 608.90\n",
      "\n",
      "Episode 220: \tActor Loss: 0.17 \tCritic Loss: 15.25 \n",
      "\t\tAverage Score: 626.18\n",
      "\n",
      "Episode 230: \tActor Loss: 0.14 \tCritic Loss: 12.71 \n",
      "\t\tAverage Score: 685.26\n",
      "\n",
      "Episode 240: \tActor Loss: 0.18 \tCritic Loss: 8.35 \n",
      "\t\tAverage Score: 609.94\n",
      "\n",
      "Episode 250: \tActor Loss: 0.15 \tCritic Loss: 3.40 \n",
      "\t\tAverage Score: 653.07\n",
      "\n",
      "Episode 260: \tActor Loss: 0.12 \tCritic Loss: 2.95 \n",
      "\t\tAverage Score: 697.99\n",
      "\n",
      "Episode 270: \tActor Loss: 0.14 \tCritic Loss: 7.34 \n",
      "\t\tAverage Score: 738.86\n",
      "\n",
      "Episode 280: \tActor Loss: 0.28 \tCritic Loss: 79.65 \n",
      "\t\tAverage Score: 408.76\n",
      "\n",
      "Episode 290: \tActor Loss: 0.21 \tCritic Loss: 4.82 \n",
      "\t\tAverage Score: 597.68\n",
      "\n",
      "Episode 300: \tActor Loss: 0.24 \tCritic Loss: 7.11 \n",
      "\t\tAverage Score: 572.89\n",
      "\n",
      "Episode 310: \tActor Loss: 0.20 \tCritic Loss: 6.43 \n",
      "\t\tAverage Score: 662.22\n",
      "\n",
      "Episode 320: \tActor Loss: 0.21 \tCritic Loss: 11.44 \n",
      "\t\tAverage Score: 706.91\n",
      "\n",
      "Episode 330: \tActor Loss: 0.17 \tCritic Loss: 9.64 \n",
      "\t\tAverage Score: 782.81\n",
      "\n",
      "Episode 340: \tActor Loss: 0.21 \tCritic Loss: 8.32 \n",
      "\t\tAverage Score: 797.08\n",
      "\n",
      "Episode 350: \tActor Loss: 0.18 \tCritic Loss: 7.26 \n",
      "\t\tAverage Score: 851.36\n",
      "\n",
      "Episode 360: \tActor Loss: 0.20 \tCritic Loss: 6.38 \n",
      "\t\tAverage Score: 866.74\n",
      "\n",
      "Episode 370: \tActor Loss: 0.18 \tCritic Loss: 6.24 \n",
      "\t\tAverage Score: 942.06\n",
      "\n",
      "Episode 380: \tActor Loss: 0.18 \tCritic Loss: 4.92 \n",
      "\t\tAverage Score: 932.10\n",
      "\n",
      "Episode 390: \tActor Loss: 0.18 \tCritic Loss: 5.93 \n",
      "\t\tAverage Score: 955.51\n",
      "\n",
      "Episode 400: \tActor Loss: 0.22 \tCritic Loss: 3.89 \n",
      "\t\tAverage Score: 896.65\n",
      "\n",
      "Episode 410: \tActor Loss: 0.23 \tCritic Loss: 7.13 \n",
      "\t\tAverage Score: 873.97\n",
      "\n",
      "Episode 420: \tActor Loss: 0.26 \tCritic Loss: 8.20 \n",
      "\t\tAverage Score: 953.02\n",
      "\n",
      "Episode 430: \tActor Loss: 0.21 \tCritic Loss: 7.79 \n",
      "\t\tAverage Score: 1061.13\n",
      "\n",
      "Episode 440: \tActor Loss: 0.48 \tCritic Loss: 36.55 \n",
      "\t\tAverage Score: 546.71\n",
      "\n",
      "Episode 450: \tActor Loss: 0.73 \tCritic Loss: 51.58 \n",
      "\t\tAverage Score: 135.94\n",
      "\n",
      "Episode 460: \tActor Loss: 1.18 \tCritic Loss: 44.84 \n",
      "\t\tAverage Score: -3.29\n",
      "\n",
      "Episode 470: \tActor Loss: 0.39 \tCritic Loss: 9.85 \n",
      "\t\tAverage Score: 13.01\n",
      "\n",
      "Episode 480: \tActor Loss: 0.46 \tCritic Loss: 12.36 \n",
      "\t\tAverage Score: 4.86\n",
      "\n",
      "Episode 490: \tActor Loss: 0.38 \tCritic Loss: 4.67 \n",
      "\t\tAverage Score: -13.58\n",
      "\n",
      "Episode 500: \tActor Loss: 0.43 \tCritic Loss: 2.69 \n",
      "\t\tAverage Score: 1.04\n",
      "\n",
      "Episode 510: \tActor Loss: 0.39 \tCritic Loss: 5.40 \n",
      "\t\tAverage Score: -15.44\n",
      "\n",
      "Episode 520: \tActor Loss: 0.36 \tCritic Loss: 1.72 \n",
      "\t\tAverage Score: 43.60\n",
      "\n",
      "Episode 530: \tActor Loss: 0.38 \tCritic Loss: 1.84 \n",
      "\t\tAverage Score: 39.36\n",
      "\n",
      "Episode 540: \tActor Loss: 0.39 \tCritic Loss: 1.73 \n",
      "\t\tAverage Score: 55.42\n",
      "\n",
      "Episode 550: \tActor Loss: 0.36 \tCritic Loss: 1.63 \n",
      "\t\tAverage Score: 26.94\n",
      "\n",
      "Episode 560: \tActor Loss: 0.37 \tCritic Loss: 1.84 \n",
      "\t\tAverage Score: 33.59\n",
      "\n",
      "Episode 570: \tActor Loss: 0.37 \tCritic Loss: 1.75 \n",
      "\t\tAverage Score: 20.07\n",
      "\n",
      "Episode 580: \tActor Loss: 0.39 \tCritic Loss: 1.25 \n",
      "\t\tAverage Score: 14.74\n",
      "\n",
      "Episode 590: \tActor Loss: 0.36 \tCritic Loss: 1.04 \n",
      "\t\tAverage Score: 19.26\n",
      "\n",
      "Episode 600: \tActor Loss: 0.36 \tCritic Loss: 0.87 \n",
      "\t\tAverage Score: 25.29\n",
      "\n",
      "Episode 610: \tActor Loss: 0.37 \tCritic Loss: 0.93 \n",
      "\t\tAverage Score: 24.28\n",
      "\n",
      "Episode 620: \tActor Loss: 0.36 \tCritic Loss: 0.91 \n",
      "\t\tAverage Score: 20.08\n",
      "\n",
      "Episode 630: \tActor Loss: 0.38 \tCritic Loss: 1.33 \n",
      "\t\tAverage Score: 21.66\n",
      "\n",
      "Episode 640: \tActor Loss: 0.36 \tCritic Loss: 1.11 \n",
      "\t\tAverage Score: 42.53\n",
      "\n",
      "Episode 650: \tActor Loss: 0.36 \tCritic Loss: 0.96 \n",
      "\t\tAverage Score: 37.97\n",
      "\n",
      "Episode 660: \tActor Loss: 0.36 \tCritic Loss: 0.98 \n",
      "\t\tAverage Score: 27.59\n",
      "\n",
      "Episode 670: \tActor Loss: 0.37 \tCritic Loss: 0.93 \n",
      "\t\tAverage Score: 33.43\n",
      "\n",
      "Episode 680: \tActor Loss: 0.35 \tCritic Loss: 0.88 \n",
      "\t\tAverage Score: 30.12\n",
      "\n",
      "Episode 690: \tActor Loss: 0.34 \tCritic Loss: 0.79 \n",
      "\t\tAverage Score: 28.96\n",
      "\n",
      "Episode 700: \tActor Loss: 0.36 \tCritic Loss: 0.85 \n",
      "\t\tAverage Score: 30.13\n",
      "\n",
      "Episode 710: \tActor Loss: 0.37 \tCritic Loss: 0.71 \n",
      "\t\tAverage Score: 31.15\n",
      "\n",
      "Episode 720: \tActor Loss: 0.37 \tCritic Loss: 0.63 \n",
      "\t\tAverage Score: 30.29\n",
      "\n",
      "Episode 730: \tActor Loss: 0.39 \tCritic Loss: 0.80 \n",
      "\t\tAverage Score: 27.38\n",
      "\n",
      "Episode 740: \tActor Loss: 0.38 \tCritic Loss: 0.62 \n",
      "\t\tAverage Score: 29.89\n",
      "\n",
      "Episode 750: \tActor Loss: 0.38 \tCritic Loss: 0.72 \n",
      "\t\tAverage Score: 28.68\n",
      "\n",
      "Episode 760: \tActor Loss: 0.38 \tCritic Loss: 0.62 \n",
      "\t\tAverage Score: 27.08\n",
      "\n",
      "Episode 770: \tActor Loss: 0.38 \tCritic Loss: 0.66 \n",
      "\t\tAverage Score: 28.34\n",
      "\n",
      "Episode 780: \tActor Loss: 0.37 \tCritic Loss: 0.80 \n",
      "\t\tAverage Score: 28.94\n",
      "\n",
      "Episode 790: \tActor Loss: 0.37 \tCritic Loss: 0.62 \n",
      "\t\tAverage Score: 55.25\n",
      "\n",
      "Episode 800: \tActor Loss: 0.36 \tCritic Loss: 0.55 \n",
      "\t\tAverage Score: 53.12\n",
      "\n",
      "Episode 810: \tActor Loss: 0.37 \tCritic Loss: 1.68 \n",
      "\t\tAverage Score: 31.99\n",
      "\n",
      "Episode 820: \tActor Loss: 0.36 \tCritic Loss: 1.48 \n",
      "\t\tAverage Score: 24.58\n",
      "\n",
      "Episode 830: \tActor Loss: 0.36 \tCritic Loss: 1.28 \n",
      "\t\tAverage Score: 22.06\n",
      "\n",
      "Episode 840: \tActor Loss: 0.36 \tCritic Loss: 1.17 \n",
      "\t\tAverage Score: 22.91\n",
      "\n",
      "Episode 850: \tActor Loss: 0.35 \tCritic Loss: 1.02 \n",
      "\t\tAverage Score: 24.04\n",
      "\n",
      "Episode 860: \tActor Loss: 0.35 \tCritic Loss: 1.08 \n",
      "\t\tAverage Score: 23.81\n",
      "\n",
      "Episode 870: \tActor Loss: 0.36 \tCritic Loss: 0.99 \n",
      "\t\tAverage Score: 23.79\n",
      "\n",
      "Episode 880: \tActor Loss: 0.37 \tCritic Loss: 0.99 \n",
      "\t\tAverage Score: 24.99\n",
      "\n",
      "Episode 890: \tActor Loss: 0.37 \tCritic Loss: 0.99 \n",
      "\t\tAverage Score: 24.58\n",
      "\n",
      "Episode 900: \tActor Loss: 0.35 \tCritic Loss: 0.89 \n",
      "\t\tAverage Score: 24.33\n",
      "\n",
      "Episode 910: \tActor Loss: 0.33 \tCritic Loss: 0.74 \n",
      "\t\tAverage Score: 26.80\n",
      "\n",
      "Episode 920: \tActor Loss: 0.35 \tCritic Loss: 1.72 \n",
      "\t\tAverage Score: 20.91\n",
      "\n",
      "Episode 930: \tActor Loss: 0.39 \tCritic Loss: 4.99 \n",
      "\t\tAverage Score: 14.46\n",
      "\n",
      "Episode 940: \tActor Loss: 0.40 \tCritic Loss: 6.19 \n",
      "\t\tAverage Score: 7.52\n",
      "\n",
      "Episode 950: \tActor Loss: 0.40 \tCritic Loss: 7.12 \n",
      "\t\tAverage Score: -1.21\n",
      "\n",
      "Episode 960: \tActor Loss: 0.40 \tCritic Loss: 5.26 \n",
      "\t\tAverage Score: 6.54\n",
      "\n",
      "Episode 970: \tActor Loss: 0.39 \tCritic Loss: 4.50 \n",
      "\t\tAverage Score: 12.92\n",
      "\n",
      "Episode 980: \tActor Loss: 0.41 \tCritic Loss: 7.23 \n",
      "\t\tAverage Score: -3.67\n",
      "\n",
      "Episode 990: \tActor Loss: 0.40 \tCritic Loss: 4.50 \n",
      "\t\tAverage Score: 7.91\n",
      "\n",
      "Episode 1000: \tActor Loss: 0.39 \tCritic Loss: 4.82 \n",
      "\t\tAverage Score: 7.22\n",
      "\n",
      "Episode 1010: \tActor Loss: 0.39 \tCritic Loss: 5.99 \n",
      "\t\tAverage Score: 0.20\n",
      "\n",
      "Episode 1020: \tActor Loss: 0.37 \tCritic Loss: 2.32 \n",
      "\t\tAverage Score: 16.15\n",
      "\n",
      "Episode 1030: \tActor Loss: 0.35 \tCritic Loss: 1.04 \n",
      "\t\tAverage Score: 21.80\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1040: \tActor Loss: 0.35 \tCritic Loss: 0.49 \n",
      "\t\tAverage Score: 32.58\n",
      "\n",
      "Episode 1050: \tActor Loss: 0.36 \tCritic Loss: 0.18 \n",
      "\t\tAverage Score: 43.62\n",
      "\n",
      "Episode 1060: \tActor Loss: 0.35 \tCritic Loss: 0.20 \n",
      "\t\tAverage Score: 40.55\n",
      "\n",
      "Episode 1070: \tActor Loss: 0.38 \tCritic Loss: 0.34 \n",
      "\t\tAverage Score: 40.63\n",
      "\n",
      "Episode 1080: \tActor Loss: 0.36 \tCritic Loss: 0.27 \n",
      "\t\tAverage Score: 40.64\n",
      "\n",
      "Episode 1090: \tActor Loss: 0.35 \tCritic Loss: 0.19 \n",
      "\t\tAverage Score: 41.19\n",
      "\n",
      "Episode 1100: \tActor Loss: 0.38 \tCritic Loss: 0.19 \n",
      "\t\tAverage Score: 40.19\n",
      "\n",
      "Episode 1110: \tActor Loss: 0.37 \tCritic Loss: 0.35 \n",
      "\t\tAverage Score: 36.64\n",
      "\n",
      "Episode 1120: \tActor Loss: 0.39 \tCritic Loss: 0.61 \n",
      "\t\tAverage Score: 38.70\n",
      "\n",
      "Episode 1130: \tActor Loss: 0.33 \tCritic Loss: 0.28 \n",
      "\t\tAverage Score: 38.36\n",
      "\n",
      "Episode 1140: \tActor Loss: 0.33 \tCritic Loss: 0.17 \n",
      "\t\tAverage Score: 38.94\n",
      "\n",
      "Episode 1150: \tActor Loss: 0.33 \tCritic Loss: 0.23 \n",
      "\t\tAverage Score: 38.10\n",
      "\n",
      "Episode 1160: \tActor Loss: 0.34 \tCritic Loss: 0.27 \n",
      "\t\tAverage Score: 40.17\n",
      "\n",
      "Episode 1170: \tActor Loss: 0.31 \tCritic Loss: 0.18 \n",
      "\t\tAverage Score: 38.47\n",
      "\n",
      "Episode 1180: \tActor Loss: 0.30 \tCritic Loss: 0.22 \n",
      "\t\tAverage Score: 38.95\n",
      "\n",
      "Episode 1190: \tActor Loss: 0.31 \tCritic Loss: 0.16 \n",
      "\t\tAverage Score: 41.21\n",
      "\n",
      "Episode 1200: \tActor Loss: 0.27 \tCritic Loss: 0.18 \n",
      "\t\tAverage Score: 41.72\n",
      "\n",
      "Episode 1210: \tActor Loss: 0.30 \tCritic Loss: 0.27 \n",
      "\t\tAverage Score: 39.96\n",
      "\n",
      "Episode 1220: \tActor Loss: 0.32 \tCritic Loss: 0.11 \n",
      "\t\tAverage Score: 45.04\n",
      "\n",
      "Episode 1230: \tActor Loss: 0.30 \tCritic Loss: 0.07 \n",
      "\t\tAverage Score: 45.72\n",
      "\n",
      "Episode 1240: \tActor Loss: 0.32 \tCritic Loss: 0.10 \n",
      "\t\tAverage Score: 45.80\n",
      "\n",
      "Episode 1250: \tActor Loss: 0.30 \tCritic Loss: 0.14 \n",
      "\t\tAverage Score: 43.71\n",
      "\n",
      "Episode 1260: \tActor Loss: 0.30 \tCritic Loss: 0.08 \n",
      "\t\tAverage Score: 44.47\n",
      "\n",
      "Episode 1270: \tActor Loss: 0.28 \tCritic Loss: 0.05 \n",
      "\t\tAverage Score: 46.91\n",
      "\n",
      "Episode 1280: \tActor Loss: 0.26 \tCritic Loss: 0.04 \n",
      "\t\tAverage Score: 47.93\n",
      "\n",
      "Episode 1290: \tActor Loss: 0.32 \tCritic Loss: 0.03 \n",
      "\t\tAverage Score: 46.78\n",
      "\n",
      "Episode 1300: \tActor Loss: 0.29 \tCritic Loss: 0.03 \n",
      "\t\tAverage Score: 46.02\n",
      "\n",
      "Episode 1310: \tActor Loss: 0.35 \tCritic Loss: 0.05 \n",
      "\t\tAverage Score: 44.48\n",
      "\n",
      "Episode 1320: \tActor Loss: 0.28 \tCritic Loss: 0.03 \n",
      "\t\tAverage Score: 45.43\n",
      "\n",
      "Episode 1330: \tActor Loss: 0.28 \tCritic Loss: 1.93 \n",
      "\t\tAverage Score: 41.70\n",
      "\n",
      "Episode 1340: \tActor Loss: 0.30 \tCritic Loss: 0.35 \n",
      "\t\tAverage Score: 44.13\n",
      "\n",
      "Episode 1350: \tActor Loss: 0.27 \tCritic Loss: 0.33 \n",
      "\t\tAverage Score: 56.91\n",
      "\n",
      "Episode 1360: \tActor Loss: 0.23 \tCritic Loss: 0.39 \n",
      "\t\tAverage Score: 49.19\n",
      "\n",
      "Episode 1370: \tActor Loss: 0.25 \tCritic Loss: 0.31 \n",
      "\t\tAverage Score: 46.21\n",
      "\n",
      "Episode 1380: \tActor Loss: 0.24 \tCritic Loss: 0.23 \n",
      "\t\tAverage Score: 48.44\n",
      "\n",
      "Episode 1390: \tActor Loss: 0.24 \tCritic Loss: 0.40 \n",
      "\t\tAverage Score: 46.66\n",
      "\n",
      "Episode 1400: \tActor Loss: 0.22 \tCritic Loss: 0.19 \n",
      "\t\tAverage Score: 45.17\n",
      "\n",
      "Episode 1410: \tActor Loss: 0.23 \tCritic Loss: 0.32 \n",
      "\t\tAverage Score: 47.86\n",
      "\n",
      "Episode 1420: \tActor Loss: 0.26 \tCritic Loss: 0.50 \n",
      "\t\tAverage Score: 45.42\n",
      "\n",
      "Episode 1430: \tActor Loss: 0.22 \tCritic Loss: 0.23 \n",
      "\t\tAverage Score: 45.40\n",
      "\n",
      "Episode 1440: \tActor Loss: 0.23 \tCritic Loss: 0.12 \n",
      "\t\tAverage Score: 48.53\n",
      "\n",
      "Episode 1450: \tActor Loss: 0.23 \tCritic Loss: 0.21 \n",
      "\t\tAverage Score: 44.18\n",
      "\n",
      "Episode 1460: \tActor Loss: 0.25 \tCritic Loss: 0.13 \n",
      "\t\tAverage Score: 45.15\n",
      "\n",
      "Episode 1470: \tActor Loss: 0.22 \tCritic Loss: 0.09 \n",
      "\t\tAverage Score: 47.50\n",
      "\n",
      "Episode 1480: \tActor Loss: 0.24 \tCritic Loss: 0.18 \n",
      "\t\tAverage Score: 46.57\n",
      "\n",
      "Episode 1490: \tActor Loss: 0.23 \tCritic Loss: 0.14 \n",
      "\t\tAverage Score: 44.93\n",
      "\n",
      "Episode 1500: \tActor Loss: 0.21 \tCritic Loss: 0.18 \n",
      "\t\tAverage Score: 44.16\n",
      "\n",
      "Episode 1510: \tActor Loss: 0.24 \tCritic Loss: 0.19 \n",
      "\t\tAverage Score: 43.92\n",
      "\n",
      "Episode 1520: \tActor Loss: 0.22 \tCritic Loss: 0.23 \n",
      "\t\tAverage Score: 47.18\n",
      "\n",
      "Episode 1530: \tActor Loss: 0.24 \tCritic Loss: 0.13 \n",
      "\t\tAverage Score: 44.99\n",
      "\n",
      "Episode 1540: \tActor Loss: 0.19 \tCritic Loss: 0.05 \n",
      "\t\tAverage Score: 45.49\n",
      "\n",
      "Episode 1550: \tActor Loss: 0.25 \tCritic Loss: 0.15 \n",
      "\t\tAverage Score: 41.01\n",
      "\n",
      "Episode 1560: \tActor Loss: 0.24 \tCritic Loss: 0.03 \n",
      "\t\tAverage Score: 45.35\n",
      "\n",
      "Episode 1570: \tActor Loss: 0.29 \tCritic Loss: 0.05 \n",
      "\t\tAverage Score: 49.62\n",
      "\n",
      "Episode 1580: \tActor Loss: 0.29 \tCritic Loss: 0.07 \n",
      "\t\tAverage Score: 49.86\n",
      "\n",
      "Episode 1590: \tActor Loss: 0.26 \tCritic Loss: 0.10 \n",
      "\t\tAverage Score: 51.11\n",
      "\n",
      "Episode 1600: \tActor Loss: 0.27 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 48.46\n",
      "\n",
      "Episode 1610: \tActor Loss: 0.33 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 48.20\n",
      "\n",
      "Episode 1620: \tActor Loss: 0.34 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.59\n",
      "\n",
      "Episode 1630: \tActor Loss: 0.32 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.56\n",
      "\n",
      "Episode 1640: \tActor Loss: 0.32 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.53\n",
      "\n",
      "Episode 1650: \tActor Loss: 0.34 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.48\n",
      "\n",
      "Episode 1660: \tActor Loss: 0.32 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.70\n",
      "\n",
      "Episode 1670: \tActor Loss: 0.30 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 47.87\n",
      "\n",
      "Episode 1680: \tActor Loss: 0.30 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 48.34\n",
      "\n",
      "Episode 1690: \tActor Loss: 0.27 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 46.92\n",
      "\n",
      "Episode 1700: \tActor Loss: 0.26 \tCritic Loss: 0.00 \n",
      "\t\tAverage Score: 46.51\n",
      "\n",
      "Episode 1705\\ Score: 46.68"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 900       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "LR (Joint):  0.0001\n",
      "GAMMA:  0.95\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--01:02:31 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.71 \n",
      "\t\tAverage Score: 50.88 \t Steps: 1002\n",
      "\n",
      "Episode 20: \tActor Loss: 0.04 \tCritic Loss: 0.80 \n",
      "\t\tAverage Score: 63.09 \t Steps: 1002\n",
      "\n",
      "Episode 30: \tActor Loss: 0.11 \tCritic Loss: 1.64 \n",
      "\t\tAverage Score: 104.85 \t Steps: 1002\n",
      "\n",
      "Episode 40: \tActor Loss: 0.34 \tCritic Loss: 1.93 \n",
      "\t\tAverage Score: 1107.62 \t Steps: 10000\n",
      "\n",
      "Episode 45\t Score: 2148.18 \t Steps: 10000\n",
      "\n",
      "==== An exception occurred: \n",
      "=====  =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a1f136299eeb>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"\"\"Returns actions for given state as per current policy.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e22bc124d270>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-a1f136299eeb>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_episode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_stats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_overall_perf_tb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mtotal_train_duration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\logger.py\u001b[0m in \u001b[0;36mplot_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=====\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"=====\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# # Scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[0;32m   1289\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m                        gridspec_kw=gridspec_kw)\n\u001b[0m\u001b[0;32m   1291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         return (self.add_gridspec(nrows, ncols, figure=self, **gridspec_kw)\n\u001b[0;32m   1523\u001b[0m                 .subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[1;32m-> 1524\u001b[1;33m                           subplot_kw=subplot_kw))\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sharey\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 axarr[row, col] = figure.add_subplot(\n\u001b[1;32m--> 337\u001b[1;33m                     self[row, col], **subplot_kw)\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;31m# turn off redundant tick labeling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1400\u001b[0m                     \u001b[1;31m# more similar to add_axes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1402\u001b[1;33m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;31m# add a layout box to this, for both the full axis, and the poss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# of the axis.  We need both because the axes may become smaller\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterization_zorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# funcs used to format x and y - fall back on major formatters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mcla\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[1;34m(self, clippath, transform)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[0mmartist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajorTicks\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m             \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[1;34m(self, clippath, transform)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# docstring inherited\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mmartist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[1;34m(self, path, transform)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m                 self.clipbox = TransformedBbox(Bbox.unit(),\n\u001b[1;32m--> 754\u001b[1;33m                                                path.get_transform())\n\u001b[0m\u001b[0;32m    755\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clippath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mget_transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;34m\"\"\"Return the `~.transforms.Transform` applied to the `Patch`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_patch_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_data_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mget_patch_transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_patch_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_patch_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rect_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m_update_patch_transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_extents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m         \u001b[0mrot_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m         \u001b[0mrot_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate_deg_around\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBboxTransformTo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mrot_trans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mrotate_deg_around\u001b[1;34m(self, x, y, degrees)\u001b[0m\n\u001b[0;32m   1965\u001b[0m         \u001b[1;31m# Cast to float to avoid wraparound issues with uint8's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate_deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mrotate_deg\u001b[1;34m(self, degrees)\u001b[0m\n\u001b[0;32m   1943\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m         \"\"\"\n\u001b[1;32m-> 1945\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrotate_around\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mrotate\u001b[1;34m(self, theta)\u001b[0m\n\u001b[0;32m   1931\u001b[0m         rotate_mtx = np.array([[a, -b, 0.0], [b, a, 0.0], [0.0, 0.0, 1.0]],\n\u001b[0;32m   1932\u001b[0m                               float)\n\u001b[1;32m-> 1933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1934\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: DON'T RESET SCORES WHEN AGENT IS 'DONE'\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 10000       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "LR (Joint):  0.0001\n",
      "GAMMA:  0.95\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--11:35:38 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.33 teps: 1003\n",
      "\t\tRunning Avg Score [100eps]: 49.61 \t Steps: 1003\n",
      "\n",
      "Episode 20: \tActor Loss: 0.05 \tCritic Loss: 0.34 teps: 1003\n",
      "\t\tRunning Avg Score [100eps]: 59.53 \t Steps: 1003\n",
      "\n",
      "Episode 30: \tActor Loss: 0.09 \tCritic Loss: 0.50 teps: 100000\n",
      "\t\tRunning Avg Score [100eps]: 56.11 \t Steps: 10000\n",
      "\n",
      "Episode 40: \tActor Loss: 0.21 \tCritic Loss: 1.15 Steps: 1003\n",
      "\t\tRunning Avg Score [100eps]: 140.65 \t Steps: 1003\n",
      "\n",
      "Episode 50: \tActor Loss: 0.23 \tCritic Loss: 3.21 Steps: 10030\n",
      "\t\tRunning Avg Score [100eps]: 371.18 \t Steps: 1003\n",
      "\n",
      "Episode 60: \tActor Loss: 0.22 \tCritic Loss: 4.03 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 462.80 \t Steps: 10000\n",
      "\n",
      "Episode 70: \tActor Loss: 0.21 \tCritic Loss: 5.34 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 480.66 \t Steps: 10000\n",
      "\n",
      "Episode 80: \tActor Loss: 0.21 \tCritic Loss: 5.80 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 400.72 \t Steps: 10000\n",
      "\n",
      "Episode 90: \tActor Loss: 0.20 \tCritic Loss: 6.74 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 512.20 \t Steps: 10000\n",
      "\n",
      "Episode 100: \tActor Loss: 0.19 \tCritic Loss: 7.64 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 558.41 \t Steps: 10000\n",
      "\n",
      "Episode 110: \tActor Loss: 0.20 \tCritic Loss: 8.68 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 578.12 \t Steps: 10000\n",
      "\n",
      "Episode 120: \tActor Loss: 0.22 \tCritic Loss: 9.54 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 221.12 \t Steps: 10000\n",
      "\n",
      "Episode 130: \tActor Loss: 0.31 \tCritic Loss: 9.81 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 438.28 \t Steps: 10000\n",
      "\n",
      "Episode 140: \tActor Loss: 0.27 \tCritic Loss: 10.28 teps: 10030\n",
      "\t\tRunning Avg Score [100eps]: 547.61 \t Steps: 1003\n",
      "\n",
      "Episode 150: \tActor Loss: 0.25 \tCritic Loss: 9.97 Steps: 10030\n",
      "\t\tRunning Avg Score [100eps]: 569.70 \t Steps: 1003\n",
      "\n",
      "Episode 160: \tActor Loss: 0.24 \tCritic Loss: 9.52 Steps: 10030\n",
      "\t\tRunning Avg Score [100eps]: 564.27 \t Steps: 1003\n",
      "\n",
      "Episode 170: \tActor Loss: 0.24 \tCritic Loss: 8.72 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 610.17 \t Steps: 10000\n",
      "\n",
      "Episode 180: \tActor Loss: 0.24 \tCritic Loss: 8.34 Steps: 10000\n",
      "\t\tRunning Avg Score [100eps]: 538.86 \t Steps: 10000\n",
      "\n",
      "Episode 186\t Running Avg Score [100eps]: 556.66 \t Steps: 10000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-324704d5fa93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-c1c8774e0361>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, resampled_action, std_scale)\u001b[0m\n\u001b[0;32m    158\u001b[0m         dist = torch.distributions.Normal(action_mean, F.hardtanh(self.std,\n\u001b[0;32m    159\u001b[0m                                                                   \u001b[0mmin_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                                                                   max_val=0.5*std_scale))\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;31m# sample from the prob distribution just generated again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresampled_action\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\distributions\\normal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# skip checking lazily-constructed args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\distributions\\constraints.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_bound\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 10000       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--14:28:04 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.33 \n",
      "\t\tAvg Score [100eps]: 49.97 \t Steps: 1002\n",
      "\n",
      "Episode 20: \tActor Loss: 0.05 \tCritic Loss: 0.34 \n",
      "\t\tAvg Score [100eps]: 57.54 \t Steps: 1002\n",
      "\n",
      "Episode 30: \tActor Loss: 0.09 \tCritic Loss: 0.46 9\n",
      "\t\tAvg Score [100eps]: 104.41 \t Steps: 9999\n",
      "\n",
      "Episode 40: \tActor Loss: 0.14 \tCritic Loss: 0.70 2\n",
      "\t\tAvg Score [100eps]: 67.98 \t Steps: 1002\n",
      "\n",
      "Episode 44\t Score [This Eps]: 144.32 \t Steps: 9999NaN next_states Found! Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "Episode 50: \tActor Loss: 0.15 \tCritic Loss: 0.83 9\n",
      "\t\tAvg Score [100eps]: 216.67 \t Steps: 9999\n",
      "\n",
      "Episode 60: \tActor Loss: 0.17 \tCritic Loss: 1.14 9\n",
      "\t\tAvg Score [100eps]: 312.39 \t Steps: 9999\n",
      "\n",
      "Episode 70: \tActor Loss: 0.19 \tCritic Loss: 2.01 9\n",
      "\t\tAvg Score [100eps]: 141.44 \t Steps: 9999\n",
      "\n",
      "Episode 80: \tActor Loss: 0.19 \tCritic Loss: 3.65 9\n",
      "\t\tAvg Score [100eps]: 515.58 \t Steps: 9999\n",
      "\n",
      "Episode 90: \tActor Loss: 0.19 \tCritic Loss: 5.77 2\n",
      "\t\tAvg Score [100eps]: 532.07 \t Steps: 1002\n",
      "\n",
      "Episode 100: \tActor Loss: 0.19 \tCritic Loss: 7.60 9\n",
      "\t\tAvg Score [100eps]: 561.39 \t Steps: 9999\n",
      "\n",
      "Episode 110: \tActor Loss: 0.19 \tCritic Loss: 9.73 2\n",
      "\t\tAvg Score [100eps]: 541.86 \t Steps: 1002\n",
      "\n",
      "Episode 120: \tActor Loss: 0.20 \tCritic Loss: 11.19 \n",
      "\t\tAvg Score [100eps]: 498.95 \t Steps: 1002\n",
      "\n",
      "Episode 130: \tActor Loss: 0.20 \tCritic Loss: 12.68 \n",
      "\t\tAvg Score [100eps]: 522.74 \t Steps: 9999\n",
      "\n",
      "Episode 140: \tActor Loss: 0.19 \tCritic Loss: 14.04 \n",
      "\t\tAvg Score [100eps]: 419.31 \t Steps: 1002\n",
      "\n",
      "Episode 150: \tActor Loss: 0.21 \tCritic Loss: 14.88 \n",
      "\t\tAvg Score [100eps]: 85.50 \t Steps: 1002\n",
      "\n",
      "Episode 160: \tActor Loss: 0.21 \tCritic Loss: 15.07 \n",
      "\t\tAvg Score [100eps]: 258.28 \t Steps: 1002\n",
      "\n",
      "Episode 170: \tActor Loss: 0.22 \tCritic Loss: 14.71 \n",
      "\t\tAvg Score [100eps]: 17.67 \t Steps: 9999\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1e04aa2608ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-c53f3a19b957>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Detach everything to ensure no backprop to these old experiences stored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 10000       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.1\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.0\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-03--18:42:50 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 16.67 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.05 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 25.56 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.06 \tCritic Loss: 0.25 \n",
      "\t\tAvg Score [100eps]: 40.25 \t Steps: 2047\n",
      "\n",
      "Episode 40: \tActor Loss: 0.06 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 53.84 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.07 \tCritic Loss: 0.32 \n",
      "\t\tAvg Score [100eps]: 83.67 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.07 \tCritic Loss: 0.48 7\n",
      "\t\tAvg Score [100eps]: 119.49 \t Steps: 2047\n",
      "\n",
      "Episode 70: \tActor Loss: 0.10 \tCritic Loss: 0.70 7\n",
      "\t\tAvg Score [100eps]: 121.49 \t Steps: 2047\n",
      "\n",
      "Episode 80: \tActor Loss: 0.10 \tCritic Loss: 0.79 7\n",
      "\t\tAvg Score [100eps]: 141.55 \t Steps: 2047\n",
      "\n",
      "Episode 90: \tActor Loss: 0.10 \tCritic Loss: 0.88 2\n",
      "\t\tAvg Score [100eps]: 155.02 \t Steps: 1002\n",
      "\n",
      "Episode 100: \tActor Loss: 0.10 \tCritic Loss: 0.95 7\n",
      "\t\tAvg Score [100eps]: 167.20 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.10 \tCritic Loss: 1.13 7\n",
      "\t\tAvg Score [100eps]: 189.66 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.11 \tCritic Loss: 1.32 7\n",
      "\t\tAvg Score [100eps]: 189.91 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.12 \tCritic Loss: 1.48 7\n",
      "\t\tAvg Score [100eps]: 228.75 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.13 \tCritic Loss: 1.75 7\n",
      "\t\tAvg Score [100eps]: 221.35 \t Steps: 2047\n",
      "\n",
      "Episode 150: \tActor Loss: 0.13 \tCritic Loss: 1.86 7\n",
      "\t\tAvg Score [100eps]: 220.74 \t Steps: 2047\n",
      "\n",
      "Episode 160: \tActor Loss: 0.13 \tCritic Loss: 2.34 2\n",
      "\t\tAvg Score [100eps]: 278.68 \t Steps: 1002\n",
      "\n",
      "Episode 170: \tActor Loss: 0.13 \tCritic Loss: 2.35 7\n",
      "\t\tAvg Score [100eps]: 224.74 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.13 \tCritic Loss: 2.67 7\n",
      "\t\tAvg Score [100eps]: 332.94 \t Steps: 2047\n",
      "\n",
      "Episode 190: \tActor Loss: 0.14 \tCritic Loss: 3.32 7\n",
      "\t\tAvg Score [100eps]: 462.00 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.15 \tCritic Loss: 4.19 7\n",
      "\t\tAvg Score [100eps]: 512.58 \t Steps: 2047\n",
      "\n",
      "Episode 210: \tActor Loss: 0.14 \tCritic Loss: 5.16 7\n",
      "\t\tAvg Score [100eps]: 522.13 \t Steps: 2047\n",
      "\n",
      "Episode 220: \tActor Loss: 0.14 \tCritic Loss: 6.05 2\n",
      "\t\tAvg Score [100eps]: 538.64 \t Steps: 1002\n",
      "\n",
      "Episode 230: \tActor Loss: 0.14 \tCritic Loss: 7.02 7\n",
      "\t\tAvg Score [100eps]: 565.91 \t Steps: 2047\n",
      "\n",
      "Episode 232\t Score [This Eps]: 580.47 \t Steps: 2047NaN next_states Found! Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "Episode 240: \tActor Loss: 0.13 \tCritic Loss: 7.52 2\n",
      "\t\tAvg Score [100eps]: 589.37 \t Steps: 1002\n",
      "\n",
      "Episode 250: \tActor Loss: 0.14 \tCritic Loss: 8.54 7\n",
      "\t\tAvg Score [100eps]: 505.49 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.13 \tCritic Loss: 9.19 2\n",
      "\t\tAvg Score [100eps]: 632.91 \t Steps: 1002\n",
      "\n",
      "Episode 270: \tActor Loss: 0.13 \tCritic Loss: 9.28 2\n",
      "\t\tAvg Score [100eps]: 370.80 \t Steps: 1002\n",
      "\n",
      "Episode 280: \tActor Loss: 0.13 \tCritic Loss: 9.87 2\n",
      "\t\tAvg Score [100eps]: 689.65 \t Steps: 1002\n",
      "\n",
      "Episode 290: \tActor Loss: 0.13 \tCritic Loss: 10.12 \n",
      "\t\tAvg Score [100eps]: 625.61 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.12 \tCritic Loss: 10.11 \n",
      "\t\tAvg Score [100eps]: 703.00 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.12 \tCritic Loss: 9.91 7\n",
      "\t\tAvg Score [100eps]: 720.35 \t Steps: 2047\n",
      "\n",
      "Episode 320: \tActor Loss: 0.12 \tCritic Loss: 9.80 7\n",
      "\t\tAvg Score [100eps]: 800.06 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.13 \tCritic Loss: 10.24 \n",
      "\t\tAvg Score [100eps]: 829.16 \t Steps: 1002\n",
      "\n",
      "Episode 340: \tActor Loss: 0.13 \tCritic Loss: 10.61 \n",
      "\t\tAvg Score [100eps]: 848.33 \t Steps: 1002\n",
      "\n",
      "Episode 350: \tActor Loss: 0.12 \tCritic Loss: 11.05 \n",
      "\t\tAvg Score [100eps]: 847.59 \t Steps: 1002\n",
      "\n",
      "Episode 360: \tActor Loss: 0.12 \tCritic Loss: 11.29 \n",
      "\t\tAvg Score [100eps]: 855.72 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.11 \tCritic Loss: 12.55 \n",
      "\t\tAvg Score [100eps]: 887.86 \t Steps: 1002\n",
      "\n",
      "Episode 380: \tActor Loss: 0.11 \tCritic Loss: 12.90 \n",
      "\t\tAvg Score [100eps]: 854.57 \t Steps: 2047\n",
      "\n",
      "Episode 390: \tActor Loss: 0.11 \tCritic Loss: 13.28 \n",
      "\t\tAvg Score [100eps]: 864.49 \t Steps: 1002\n",
      "\n",
      "Episode 400: \tActor Loss: 0.11 \tCritic Loss: 13.00 \n",
      "\t\tAvg Score [100eps]: 661.30 \t Steps: 1002\n",
      "\n",
      "Episode 410: \tActor Loss: 0.12 \tCritic Loss: 12.23 \n",
      "\t\tAvg Score [100eps]: 537.45 \t Steps: 1002\n",
      "\n",
      "Episode 420: \tActor Loss: 0.13 \tCritic Loss: 11.40 \n",
      "\t\tAvg Score [100eps]: 689.51 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.15 \tCritic Loss: 10.59 \n",
      "\t\tAvg Score [100eps]: 776.51 \t Steps: 2047\n",
      "\n",
      "Episode 440: \tActor Loss: 0.16 \tCritic Loss: 9.95 7\n",
      "\t\tAvg Score [100eps]: 731.61 \t Steps: 2047\n",
      "\n",
      "Episode 450: \tActor Loss: 0.17 \tCritic Loss: 9.29 7\n",
      "\t\tAvg Score [100eps]: 772.78 \t Steps: 2047\n",
      "\n",
      "Episode 460: \tActor Loss: 0.18 \tCritic Loss: 9.00 7\n",
      "\t\tAvg Score [100eps]: 848.92 \t Steps: 2047\n",
      "\n",
      "Episode 470: \tActor Loss: 0.19 \tCritic Loss: 8.48 7\n",
      "\t\tAvg Score [100eps]: 741.57 \t Steps: 2047\n",
      "\n",
      "Episode 480: \tActor Loss: 0.20 \tCritic Loss: 8.01 7\n",
      "\t\tAvg Score [100eps]: 818.94 \t Steps: 2047\n",
      "\n",
      "Episode 490: \tActor Loss: 0.21 \tCritic Loss: 7.67 7\n",
      "\t\tAvg Score [100eps]: 870.38 \t Steps: 2047\n",
      "\n",
      "Episode 500: \tActor Loss: 0.21 \tCritic Loss: 8.03 7\n",
      "\t\tAvg Score [100eps]: 881.02 \t Steps: 2047\n",
      "\n",
      "Episode 510: \tActor Loss: 0.22 \tCritic Loss: 8.84 2\n",
      "\t\tAvg Score [100eps]: 906.73 \t Steps: 1002\n",
      "\n",
      "Episode 520: \tActor Loss: 0.22 \tCritic Loss: 9.21 7\n",
      "\t\tAvg Score [100eps]: 860.08 \t Steps: 2047\n",
      "\n",
      "Episode 530: \tActor Loss: 0.23 \tCritic Loss: 8.72 2\n",
      "\t\tAvg Score [100eps]: 683.69 \t Steps: 1002\n",
      "\n",
      "Episode 540: \tActor Loss: 0.24 \tCritic Loss: 8.15 7\n",
      "\t\tAvg Score [100eps]: 396.15 \t Steps: 2047\n",
      "\n",
      "Episode 550: \tActor Loss: 0.25 \tCritic Loss: 7.33 7\n",
      "\t\tAvg Score [100eps]: 483.04 \t Steps: 2047\n",
      "\n",
      "Episode 560: \tActor Loss: 0.26 \tCritic Loss: 6.20 7\n",
      "\t\tAvg Score [100eps]: 478.04 \t Steps: 2047\n",
      "\n",
      "Episode 570: \tActor Loss: 0.27 \tCritic Loss: 5.20 7\n",
      "\t\tAvg Score [100eps]: 472.78 \t Steps: 2047\n",
      "\n",
      "Episode 580: \tActor Loss: 0.28 \tCritic Loss: 4.38 2\n",
      "\t\tAvg Score [100eps]: 480.22 \t Steps: 1002\n",
      "\n",
      "Episode 590: \tActor Loss: 0.29 \tCritic Loss: 3.39 7\n",
      "\t\tAvg Score [100eps]: 507.63 \t Steps: 2047\n",
      "\n",
      "Episode 600: \tActor Loss: 0.31 \tCritic Loss: 2.39 2\n",
      "\t\tAvg Score [100eps]: 550.19 \t Steps: 1002\n",
      "\n",
      "Episode 603\t Score [This Eps]: 565.52 \t Steps: 1002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a0278a43b67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-c53f3a19b957>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, a)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# state network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_3s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_3s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# Q value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# std input: 0.3\n",
    "# std_scale hard_tanh max = 0.5*std_scale\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============  HYPERPARAMS ============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BATCH_SIZE:  1024\n",
      "HIDDEN_SIZES (ACTOR):  (1024, 1024, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (1024, 1024, 512)\n",
      "GAMMA:  0.95\n",
      "LR (Joint):  0.0001\n",
      "LR_DECAY:  0.995\n",
      "LR_MIN:  1e-05\n",
      "BETA:  0.01\n",
      "BETA_DECAY:  0.9975\n",
      "BETA_MIN:  0.0\n",
      "EPS:  0.2\n",
      "EPS_DECAY:  0.995\n",
      "EPS_MIN:  0.05\n",
      "WEIGHT_DECAY:  0.0001\n",
      "USE GAE:  True\n",
      "GAE TAU:  0.99\n",
      "GRAD_CLIP:  1.0\n",
      "===========================================\n",
      "\n",
      "***STARTED TRAINING AT 2022-05-04--00:44:07 \n",
      "\n",
      "Episode 10: \tActor Loss: 0.06 \tCritic Loss: 0.27 \n",
      "\t\tAvg Score [100eps]: 15.61 \t Steps: 2047\n",
      "\n",
      "Episode 20: \tActor Loss: 0.06 \tCritic Loss: 0.26 \n",
      "\t\tAvg Score [100eps]: 35.72 \t Steps: 2047\n",
      "\n",
      "Episode 30: \tActor Loss: 0.08 \tCritic Loss: 0.39 \n",
      "\t\tAvg Score [100eps]: 88.84 \t Steps: 2047\n",
      "\n",
      "Episode 40: \tActor Loss: 0.13 \tCritic Loss: 0.70 7\n",
      "\t\tAvg Score [100eps]: 104.92 \t Steps: 2047\n",
      "\n",
      "Episode 50: \tActor Loss: 0.15 \tCritic Loss: 0.96 7\n",
      "\t\tAvg Score [100eps]: 178.89 \t Steps: 2047\n",
      "\n",
      "Episode 60: \tActor Loss: 0.15 \tCritic Loss: 1.00 2\n",
      "\t\tAvg Score [100eps]: 121.26 \t Steps: 1002\n",
      "\n",
      "Episode 70: \tActor Loss: 0.17 \tCritic Loss: 1.25 7\n",
      "\t\tAvg Score [100eps]: 190.66 \t Steps: 2047\n",
      "\n",
      "Episode 80: \tActor Loss: 0.18 \tCritic Loss: 1.46 7\n",
      "\t\tAvg Score [100eps]: 199.88 \t Steps: 2047\n",
      "\n",
      "Episode 90: \tActor Loss: 0.18 \tCritic Loss: 1.71 7\n",
      "\t\tAvg Score [100eps]: 121.20 \t Steps: 2047\n",
      "\n",
      "Episode 100: \tActor Loss: 0.19 \tCritic Loss: 2.03 7\n",
      "\t\tAvg Score [100eps]: 266.22 \t Steps: 2047\n",
      "\n",
      "Episode 110: \tActor Loss: 0.20 \tCritic Loss: 2.27 7\n",
      "\t\tAvg Score [100eps]: 141.57 \t Steps: 2047\n",
      "\n",
      "Episode 120: \tActor Loss: 0.21 \tCritic Loss: 2.83 7\n",
      "\t\tAvg Score [100eps]: 272.20 \t Steps: 2047\n",
      "\n",
      "Episode 130: \tActor Loss: 0.21 \tCritic Loss: 3.20 7\n",
      "\t\tAvg Score [100eps]: 296.68 \t Steps: 2047\n",
      "\n",
      "Episode 140: \tActor Loss: 0.20 \tCritic Loss: 3.73 2\n",
      "\t\tAvg Score [100eps]: 337.43 \t Steps: 1002\n",
      "\n",
      "Episode 150: \tActor Loss: 0.18 \tCritic Loss: 4.19 7\n",
      "\t\tAvg Score [100eps]: 403.55 \t Steps: 2047\n",
      "\n",
      "Episode 160: \tActor Loss: 0.18 \tCritic Loss: 5.22 7\n",
      "\t\tAvg Score [100eps]: 453.70 \t Steps: 2047\n",
      "\n",
      "Episode 170: \tActor Loss: 0.15 \tCritic Loss: 5.73 7\n",
      "\t\tAvg Score [100eps]: 452.16 \t Steps: 2047\n",
      "\n",
      "Episode 180: \tActor Loss: 0.14 \tCritic Loss: 7.04 2\n",
      "\t\tAvg Score [100eps]: 524.42 \t Steps: 1002\n",
      "\n",
      "Episode 190: \tActor Loss: 0.13 \tCritic Loss: 7.92 7\n",
      "\t\tAvg Score [100eps]: 545.68 \t Steps: 2047\n",
      "\n",
      "Episode 200: \tActor Loss: 0.14 \tCritic Loss: 9.19 7\n",
      "\t\tAvg Score [100eps]: 602.13 \t Steps: 2047\n",
      "\n",
      "Episode 210: \tActor Loss: 0.13 \tCritic Loss: 10.19 \n",
      "\t\tAvg Score [100eps]: 564.23 \t Steps: 1002\n",
      "\n",
      "Episode 220: \tActor Loss: 0.12 \tCritic Loss: 11.22 \n",
      "\t\tAvg Score [100eps]: 637.50 \t Steps: 2047\n",
      "\n",
      "Episode 230: \tActor Loss: 0.12 \tCritic Loss: 12.79 \n",
      "\t\tAvg Score [100eps]: 678.81 \t Steps: 2047\n",
      "\n",
      "Episode 240: \tActor Loss: 0.11 \tCritic Loss: 13.48 \n",
      "\t\tAvg Score [100eps]: 618.18 \t Steps: 1002\n",
      "\n",
      "Episode 250: \tActor Loss: 0.11 \tCritic Loss: 14.11 \n",
      "\t\tAvg Score [100eps]: 542.89 \t Steps: 2047\n",
      "\n",
      "Episode 260: \tActor Loss: 0.11 \tCritic Loss: 14.35 \n",
      "\t\tAvg Score [100eps]: 570.45 \t Steps: 2047\n",
      "\n",
      "Episode 270: \tActor Loss: 0.11 \tCritic Loss: 15.19 \n",
      "\t\tAvg Score [100eps]: 724.56 \t Steps: 2047\n",
      "\n",
      "Episode 280: \tActor Loss: 0.11 \tCritic Loss: 15.21 \n",
      "\t\tAvg Score [100eps]: 636.96 \t Steps: 2047\n",
      "\n",
      "Episode 290: \tActor Loss: 0.12 \tCritic Loss: 15.32 \n",
      "\t\tAvg Score [100eps]: 704.50 \t Steps: 2047\n",
      "\n",
      "Episode 300: \tActor Loss: 0.09 \tCritic Loss: 15.50 \n",
      "\t\tAvg Score [100eps]: 808.44 \t Steps: 2047\n",
      "\n",
      "Episode 310: \tActor Loss: 0.10 \tCritic Loss: 15.97 \n",
      "\t\tAvg Score [100eps]: 857.73 \t Steps: 1002\n",
      "\n",
      "Episode 320: \tActor Loss: 0.10 \tCritic Loss: 16.06 \n",
      "\t\tAvg Score [100eps]: 811.64 \t Steps: 2047\n",
      "\n",
      "Episode 330: \tActor Loss: 0.12 \tCritic Loss: 15.52 \n",
      "\t\tAvg Score [100eps]: 832.65 \t Steps: 2047\n",
      "\n",
      "Episode 340: \tActor Loss: 0.12 \tCritic Loss: 16.17 \n",
      "\t\tAvg Score [100eps]: 877.53 \t Steps: 2047\n",
      "\n",
      "Episode 350: \tActor Loss: 0.12 \tCritic Loss: 16.71 \n",
      "\t\tAvg Score [100eps]: 904.01 \t Steps: 2047\n",
      "\n",
      "Episode 360: \tActor Loss: 0.12 \tCritic Loss: 17.04 \n",
      "\t\tAvg Score [100eps]: 896.85 \t Steps: 2047\n",
      "\n",
      "Episode 370: \tActor Loss: 0.12 \tCritic Loss: 17.17 \n",
      "\t\tAvg Score [100eps]: 904.02 \t Steps: 2047\n",
      "\n",
      "Episode 380: \tActor Loss: 0.12 \tCritic Loss: 17.27 \n",
      "\t\tAvg Score [100eps]: 895.89 \t Steps: 2047\n",
      "\n",
      "Episode 390: \tActor Loss: 0.12 \tCritic Loss: 17.77 \n",
      "\t\tAvg Score [100eps]: 948.80 \t Steps: 2047\n",
      "\n",
      "Episode 400: \tActor Loss: 0.12 \tCritic Loss: 17.54 \n",
      "\t\tAvg Score [100eps]: 963.19 \t Steps: 2047\n",
      "\n",
      "Episode 410: \tActor Loss: 0.13 \tCritic Loss: 17.42 \n",
      "\t\tAvg Score [100eps]: 971.31 \t Steps: 2047\n",
      "\n",
      "Episode 420: \tActor Loss: 0.13 \tCritic Loss: 17.25 \n",
      "\t\tAvg Score [100eps]: 969.66 \t Steps: 2047\n",
      "\n",
      "Episode 430: \tActor Loss: 0.11 \tCritic Loss: 17.12 \n",
      "\t\tAvg Score [100eps]: 934.52 \t Steps: 1002\n",
      "\n",
      "Episode 440: \tActor Loss: 0.13 \tCritic Loss: 16.02 \n",
      "\t\tAvg Score [100eps]: 687.32 \t Steps: 1002\n",
      "\n",
      "Episode 450: \tActor Loss: 0.17 \tCritic Loss: 16.92 \n",
      "\t\tAvg Score [100eps]: 514.66 \t Steps: 1002\n",
      "\n",
      "Episode 460: \tActor Loss: 0.20 \tCritic Loss: 16.82 \n",
      "\t\tAvg Score [100eps]: 301.89 \t Steps: 1002\n",
      "\n",
      "Episode 470: \tActor Loss: 0.22 \tCritic Loss: 16.71 \n",
      "\t\tAvg Score [100eps]: 398.69 \t Steps: 1002\n",
      "\n",
      "Episode 480: \tActor Loss: 0.25 \tCritic Loss: 17.33 \n",
      "\t\tAvg Score [100eps]: 89.67 \t Steps: 1002\n",
      "\n",
      "Episode 490: \tActor Loss: 0.27 \tCritic Loss: 17.41 \n",
      "\t\tAvg Score [100eps]: 183.18 \t Steps: 1002\n",
      "\n",
      "Episode 500: \tActor Loss: 0.29 \tCritic Loss: 17.52 \n",
      "\t\tAvg Score [100eps]: 165.97 \t Steps: 1002\n",
      "\n",
      "Episode 510: \tActor Loss: 0.31 \tCritic Loss: 17.50 \n",
      "\t\tAvg Score [100eps]: 243.02 \t Steps: 1002\n",
      "\n",
      "Episode 520: \tActor Loss: 0.33 \tCritic Loss: 18.19 \n",
      "\t\tAvg Score [100eps]: 71.37 \t Steps: 1002\n",
      "\n",
      "Episode 530: \tActor Loss: 0.35 \tCritic Loss: 17.94 \n",
      "\t\tAvg Score [100eps]: 288.84 \t Steps: 1002\n",
      "\n",
      "Episode 540: \tActor Loss: 0.36 \tCritic Loss: 18.07 \n",
      "\t\tAvg Score [100eps]: 326.22 \t Steps: 1002\n",
      "\n",
      "Episode 550: \tActor Loss: 0.35 \tCritic Loss: 16.06 \n",
      "\t\tAvg Score [100eps]: 356.85 \t Steps: 1002\n",
      "\n",
      "Episode 560: \tActor Loss: 0.40 \tCritic Loss: 15.00 \n",
      "\t\tAvg Score [100eps]: 434.26 \t Steps: 1002\n",
      "\n",
      "Episode 570: \tActor Loss: 0.40 \tCritic Loss: 14.39 \n",
      "\t\tAvg Score [100eps]: 203.50 \t Steps: 1002\n",
      "\n",
      "Episode 580: \tActor Loss: 0.39 \tCritic Loss: 13.49 \n",
      "\t\tAvg Score [100eps]: 214.35 \t Steps: 1002\n",
      "\n",
      "Episode 590: \tActor Loss: 0.40 \tCritic Loss: 12.82 \n",
      "\t\tAvg Score [100eps]: 76.46 \t Steps: 1002\n",
      "\n",
      "Episode 600: \tActor Loss: 0.40 \tCritic Loss: 12.41 \n",
      "\t\tAvg Score [100eps]: 74.73 \t Steps: 1002\n",
      "\n",
      "Episode 610: \tActor Loss: 0.41 \tCritic Loss: 12.10 \n",
      "\t\tAvg Score [100eps]: 169.90 \t Steps: 1002\n",
      "\n",
      "Episode 620: \tActor Loss: 0.41 \tCritic Loss: 11.12 \n",
      "\t\tAvg Score [100eps]: 67.41 \t Steps: 1002\n",
      "\n",
      "Episode 630: \tActor Loss: 0.41 \tCritic Loss: 11.23 \n",
      "\t\tAvg Score [100eps]: 69.07 \t Steps: 1002\n",
      "\n",
      "Episode 640: \tActor Loss: 0.41 \tCritic Loss: 11.17 \n",
      "\t\tAvg Score [100eps]: 62.81 \t Steps: 1002\n",
      "\n",
      "Episode 650: \tActor Loss: 0.41 \tCritic Loss: 11.57 \n",
      "\t\tAvg Score [100eps]: 207.03 \t Steps: 1002\n",
      "\n",
      "Episode 660: \tActor Loss: 0.36 \tCritic Loss: 12.08 \n",
      "\t\tAvg Score [100eps]: 54.33 \t Steps: 1002\n",
      "\n",
      "Episode 670: \tActor Loss: 0.36 \tCritic Loss: 12.00 \n",
      "\t\tAvg Score [100eps]: 70.13 \t Steps: 1002\n",
      "\n",
      "Episode 680: \tActor Loss: 0.36 \tCritic Loss: 11.48 \n",
      "\t\tAvg Score [100eps]: 96.61 \t Steps: 1002\n",
      "\n",
      "Episode 690: \tActor Loss: 0.36 \tCritic Loss: 11.05 \n",
      "\t\tAvg Score [100eps]: 97.68 \t Steps: 1002\n",
      "\n",
      "NaN next_states Found! Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "\n",
      "NaN found in states. Skipping this episode.\n",
      "Episode 700: \tActor Loss: 0.36 \tCritic Loss: 10.64 \n",
      "\t\tAvg Score [100eps]: 230.05 \t Steps: 2047\n",
      "\n",
      "Episode 710: \tActor Loss: 0.36 \tCritic Loss: 10.20 \n",
      "\t\tAvg Score [100eps]: 191.21 \t Steps: 2047\n",
      "\n",
      "Episode 720: \tActor Loss: 0.36 \tCritic Loss: 9.71 2\n",
      "\t\tAvg Score [100eps]: 69.14 \t Steps: 2047\n",
      "\n",
      "Episode 730: \tActor Loss: 0.36 \tCritic Loss: 9.30 2\n",
      "\t\tAvg Score [100eps]: 77.90 \t Steps: 2047\n",
      "\n",
      "Episode 740: \tActor Loss: 0.36 \tCritic Loss: 8.98 \n",
      "\t\tAvg Score [100eps]: 64.43 \t Steps: 2047\n",
      "\n",
      "Episode 750: \tActor Loss: 0.36 \tCritic Loss: 8.66 2\n",
      "\t\tAvg Score [100eps]: 51.42 \t Steps: 2047\n",
      "\n",
      "Episode 753\t Score [This Eps]: 93.42 \t Steps: 10027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-042c5b84d7d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO_Agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mppo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-c53f3a19b957>\u001b[0m in \u001b[0;36mppo\u001b[1;34m(params, logger)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Perform actions from each agent's policy network (clipped actions [0, -1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\ppo_agent.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, std_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# stdev cannot = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppo_ac_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, action, std_scale)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampled_action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl_algorithms_collection\\p2_continuous-control\\PPO_Crawler_MultiAgent_Control_Exercise\\scripts\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s, resampled_action, std_scale)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# state, apply batch norm BEFORE activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_1a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#linear -> batchnorm -> activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_2a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_3a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_3a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drlnd_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mprelu\u001b[1;34m(input, weight)\u001b[0m\n\u001b[0;32m   1497\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# LONGER TEST\n",
    "# NOTE: ACTUALLY DECAYING STD_SCALE PARAM\n",
    "# TEST: Retain score of agent from start till it falls. Avg score accumulated in deque is taken.\n",
    "# DEcaying LR\n",
    "# Increase clipping ratio coeff (eps) to 0.2\n",
    "# Increase eps_min to 0.05\n",
    "##################\n",
    "\n",
    "# Params Override: Initialized in params.py\n",
    "params = Params()\n",
    "params.verbose = True\n",
    "params.random_seed = 0\n",
    "params.n_episodes=10000\n",
    "params.max_t = 2048       # Max steps per eps = 1000\n",
    "params.print_every = 10\n",
    "params.save_every = 20\n",
    "params.log_weights_every = 100\n",
    "params.terminate_on_target_score = False\n",
    "params.plot_stats = True\n",
    "params.lr = 1e-4                  \n",
    "params.checkpoint_actor_weights_dir = 'weights/checkpoint_actor/test'\n",
    "params.checkpoint_critic_weights_dir = 'weights/checkpoint_critic/test'\n",
    "\n",
    "\n",
    "#### MAIN #####\n",
    "tb=CustomSummaryWriter()\n",
    "logger = Logger(params, tb=tb)\n",
    "agent = PPO_Agent(state_size, action_size, params=params)\n",
    "ppo(params, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== HYPERPARAMS ===============\n",
      "DEVICE:  cuda:0\n",
      "RANDOM SEED:  0\n",
      "BUFFER_SIZE:  300000\n",
      "BATCH_SIZE:  128\n",
      "HIDDEN_SIZES (ACTOR):  (512, 512, 512)\n",
      "HIDDEN_SIZES (CRITIC):  (512, 512, 512)\n",
      "GAMMA:  0.99\n",
      "TAU:  0.001\n",
      "LR_ACTOR:  0.0005\n",
      "LR_CRITIC:  0.001\n",
      "WEIGHT_DECAY:  0.0001\n",
      "HARD_UPDATE:  True\n",
      "LEARN_EVERY:  1\n",
      "HARD_WEIGHTS_UPDATE_EVERY:  350\n",
      "N_STEP_BOOTSTRAP:  5\n",
      "VMIN:  -0.01\n",
      "VMAX:  20\n",
      "NUM_ATOMS:  100\n",
      "===========================================\n",
      "\n",
      "Mean Score: 1088.789627775356\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "params = Params()\n",
    "logger = Logger(params)\n",
    "agent = D4PG_Agent(state_size, action_size, params=params)\n",
    "agent.actor_local.load_state_dict(torch.load('weights/saved/refactored_512_512_512_V_20/checkpoint_actor_ep300.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('weights/saved/refactored_512_512_512_V_20/checkpoint_critic_ep300.pth'))\n",
    "max_t = 1000\n",
    "score = np.zeros(len(env_info.agents))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "states = env_info.vector_observations                # get the current state\n",
    "score = 0                                              # initialize the score\n",
    "for i in range(max_t):\n",
    "    # Perform actions from each agent's policy network (clipped actions [0, -1])\n",
    "    actions = [ agent.act(state, add_noise=False) for state in states ]  \n",
    "    actions = np.stack(actions)      \n",
    "    env_info = env.step(actions)[brain_name]  # send the action to the environment \n",
    "    next_states = env_info.vector_observations       # get the next state\n",
    "    rewards = env_info.rewards                       # get the reward\n",
    "    dones = env_info.local_done                      # see if episode has finished\n",
    "    states = next_states                             # roll over the state to next time step\n",
    "    \n",
    "    # update the score\n",
    "    score += np.array(rewards)                       \n",
    "    score = np.where(dones, 0, score)\n",
    "    \n",
    "    # exit loop if episode finished (NOTE: Agents auto-restart upon done)\n",
    "    #if all(dones):                                   \n",
    "    #    break\n",
    "    \n",
    "print(\"Mean Score: {}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd_gpu",
   "language": "python",
   "name": "drlnd_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
